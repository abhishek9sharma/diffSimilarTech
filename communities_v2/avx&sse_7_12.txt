0---------------------------------------------------

scalar,faster,speed,matrix
the question is avx scalar is 2.7x faster than sse when i vectorized it the speed up is 3x matrix size is 128x128 for this question

performance,better,faster,code,papi
as expected the performance got better with both and avx 2 faster than sse 4.2 but when i profiled the code with papi i found out that the total number of misses mainly l1 and l2 increased a lot

version,faster,original
so the avx version does indeed appear to faster than the sse version both for the original implementations and the optimised implementations

faster,smaller,values,fast
now for sse is clearly faster and for the smaller values it s nearlly as fast as avx

1---------------------------------------------------

l1d,cache,faster,cpus,haswell
for small buffers hot in l1d cache avx can copy significantly faster than sse on cpus like haswell where 256b loads stores really do use a 256b data path to l1d cache instead of splitting into two 128b operations

congratulations,back,routine,third,faster,haswell
so congratulations - you can pat yourself on the back your avx routine is indeed about a third faster than the sse routine tested on haswell i7 here

other---------------------------------------------------

faster
i expected avx to be about 1.5x faster than sse

code,thing,version,slower
i have code that does the same thing but the avx version is considerably slower than the sse version

cache,.both,band,limited,datalen,increase,time
buf1 buf2 and buf3 is small enough to located in l1 cache and l2 cache l2 cache 1mb .both of sse and avx is band width limited but with the datalen increase why do the avx need more time than sse

newer,faster,number,function,important,argument,answer
also note that the fact that the avx are a newer than sse doesn t make the avx faster whatever you are planning to use the number of cycles taken by an function is probably more important than the avx vs sse argument for example see this answer

underlying,various,limitations,execution,units,side,instructions,boundary
the underlying reason for this and various other avx limitations is that architecturally avx is little more than two sse execution units side by side - you will notice that virtually no avx instructions operate horizontally across the boundary between the two 128 bit halves of a vector which is particularly annoying in the case of vpalignr

math,libraries,avx2
and simd math libraries for sse and avx however they seem to be more sse than avx2

