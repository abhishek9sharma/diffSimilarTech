performance
furthermore 3des is much slower than aes

performance
furthermore 3des is much slower than aes

performance
should be as fast as 3des aes turned out to be much faster than 3des in software typically 5 to 10 times faster

usability
alternatively zen-cart looks simpler than magento but without some of the flexibility

performance
strlen is fast alloca is fast copying the string up to the first n is fast puts is faster than printf but is is most likely far slower than all three operations mentioned before together

usability
indeed it would be relatively easy to preprocess a bison grammar file but it is easier with jison because you can compute the grammar programmatically and pass it to jison as a json object

performance
if i run ls folder | head in a directory with a lot of files the execution time is about 50 times faster than ls folder | tail

memory
i need to make sure that each of these top mail directory sa44-3 is not larger then 8gb so the script should calculate the size of each top level folder and if its over 8gb create a new one called eg

usability
but my directory structure is more organized its more like app lib mypackage folder

memory
unfortunately the directory also is a git repository and has a .git folder in it which is much bigger than the directory itself

performance
rm -rf directory also works faster for billion of files in one folder

security
i find the best way is to create a cache session folder in your systems directory is more safer i put important things like logs and cache in system rather than application folder

memory
i need to make sure that each of these top mail directory sa44-3 is not larger then 8gb so the script should calculate the size of each top level folder and if its over 8gb create a new one called eg

performance
i ve had to replace lyebox with colorbox which is much faster and seemingly has less problems conflicting with other scripts lightbox fancybox and others wouldn t work for me

performance
perl uses nfa which is slower yet more powerful than the dfa engine sed has

usability
because representation of a given problem with a nfa is far easier than the equivalent dfa

performance
regex is a nfa and is as such in most cases slower than a dfa or hand-written parser

performance
generally speaking dfa is faster but nfa is more compact

performance
perl uses nfa which is slower yet more powerful than the dfa engine sed has

memory
in fact because you are eliminating the redundancy of epsilon transitions many simple dfa s actually get smaller than the nfa they represent but there is simply no way to guarantee that

usability
at the same time the compilation phase for a dfa is typically more complex than for an nfa and dfas don t have all the capabilities of nfas

memory
if it can be practically determinized this give you a dfa that can be exponentially larger than the nfa then by all means do that

usability
as far as when awt may be more useful than swing -

usability
the awt approach seems closer to bare metal but since jdk 6 brought a lot of improvements in swing rendering pipeline i would go the swing java2d approach

usability
swing is relatively similar to awt apart from the fact that swing has more capabilities awt is probably the simplest form to start out with and has most if not all of the tools to complete your project hope this helps

usability
i find that the swing library is easier to use than awt although you do still have to use awt for listeners

usability
it has functionality the same as a canvas but swing is more advanced and has better features than awt

usability
awt is really out of date people have more experience with swing no days and even javafx

performance
swing will save your more time than awt as all the code of components of swing are purely written in java whereas of awt code of components are written in native language that is other than java thus compilation time of awt is more than swing

performance
generally swing is more efficient and advanced than awt

usability
i know you re thinking why did i use awt instead of swing but at the moment i am more comfortable with awt

usability
in swing has more features than the awt components

performance
consider using swing which has much better performance over the old heavyweight awt

performance
its was said that awt is faster than swing as it uses the platform component but due the arrival of faster processor etc ..

usability
use a swing gui not an awt gui since swing is much more powerful and flexible than awt

usability
are there any cases where awt is more useful advised to use than swing or vice-versa

usability
the swing library is much more portable than the awt library

memory
i mean by light weight i thought maybe the swing components occupy less memory than the awt components

usability
the uibezierpath class seems easier to use so how could i get that drawing in a uiimage

reliability
webm is usually more robust than mp4 which can be all over the place

reliability
webm is usually more robust than mp4 which can be all over the place

usability
the mp4 implementation is more widely used and wouldn t require a webm fallback in most browsers

performance
probably webm will load faster than standard mp4 but i am not so familiar with webm format

usability
the mp4 implementation is more widely used and wouldn t require a webm fallback in most browsers

memory
i tried mp4 and webm and sometimes the file size after i convert to mp4 is smaller than webm but it is also sometimes larger than the original file size

performance
also it looks like when i transcode webm to mp4 2.7 is 30 faster than webm

reliability
2 location + reverse geocoding - seems more reliable but requests location services on the device does it work on wifi only tablets and for it to be enabled and requires time to a fetch location b server call to reverse geocode

memory
i have tried connecting the qscrollbars but the maximum of the qplaintextedit is smaller than the qtextedit s

performance
but the plugin gulp-ruby-sass slower than gulp-sass

performance
i ended up using gulp-ruby-sass that while is a bit slower than gulp-sass is rich with features such as loadpath

performance
yet from my point of view texreg is more efficient that stargazer and easier to customize than xtable

memory
you could try using double which is bigger than a long and use only the int part

memory
you can convert your object into double and then into int but you should take care as double value is much bigger than int

performance
double is much slower than int

performance
maybe division between double and int is faster than it between double

memory
4 + 4 since int is smaller size compared to double padding of double size is done

memory
that means a float will be a double and anything smaller than an int will be an int

memory
a normal 3 will be treated as int but in the test function you are retrieving double which are bigger than an int on most platforms and you might end up reading wrong locations which inturn leads to exc_bad_access run time signal being generated

memory
you could try to add some value to the double to make sure it s bigger or smaller than an int can be

memory
in contrast accessing the bits of a double as an int is usually in-practice safe even though it s formally ub because 1 an int is typically smaller or equal in size to double and 2 an int usually does not have any invalid bit patterns

memory
a double is bigger than an int

memory
this imply that result of pow x y converted to int will be truncated because of double arithmetic and exponentiation that will return double value slightly smaller than int

memory
int needs less memory comparing to double numbers

memory
you do explicit type casting to get your result in int because double is a larger data-type than int

performance
if you want the modulus use as it gives an int and would be more efficient than double arithmetic

memory
if you are not storing infinity nowhere and use it just for comparison you can use double infinity which is larger than int and long max value

memory
the double has a bigger mantissa the int bits of the real number

memory
edit actually my solution does not work because double can be very big much bigger than int and also very small like fractions

memory
i don t understand how an int 63823 takes up less space than a double 1.0

performance
even dividing int is slower than multiplying floats or double in some cases

memory
many processors and or compilers implement long double types larger than any int type regardless of name and there are processors with 32 byte pointers

usability
1 int range is much smaller than double and for pow 2 100 that fails

memory
the undefined behaviour as identified in other answers is explained on my intel platform with vc as that the f format specifier expects a double on the stack which is larger than an int so when it retrieves the value it retrieves more bytes than of an int and now assumes the next parameter at a diferent position on the stack causing z to be printed wrong it is not z that is printed

memory
since an int is representing by a non-decimal number 1 and a double is represented by a decimal-number with precision 32 bytes more than that of a float 1.0 we can say that int s are less than or smaller than double s and by that logic int s can be promoted to double s and double s can be demoted to int s

usability
here for what it s worth is a pipes-csv variant which just compresses each parsed row into an unboxed vector of int s by hand this easier than finding double which is what this csv is really storing using readint from the bytestring package.

usability
as for the last question floating point arithmetic particularly double precision is much more complex than int arithmetic so on a reasonably modern pipelined processor each instruction will take longer to execute

usability
also given that double has a wider range what would one return for those out of range int values

performance
this can t help performance either since pow double int is significantly faster than pow double double in general

memory
for platforms where int is larger than double it s obviously false

memory
extra arguments to variatic functions with types smaller than int are promoted to int and passed as such and floating point types smaller than double are promoted to double and passed as such

usability
as for the last question floating point arithmetic particularly double precision is much more complex than int arithmetic so on a reasonably modern pipelined processor each instruction will take longer to execute

memory
you re getting the outofmemory because if you declare int 1000 the memory is allocated immediately additionally double take up more space than ints-an int representation will also save you space

memory
a double variable can hold larger values than an int and is able to store an approximation of the value 4000000000

memory
so if i try to convert a double number bigger than maximum int it crashes instead of returning nil

performance
this can t help performance either since pow double int is significantly faster than pow double double in general

performance
so i asked myself can a double be faster than a int

usability
in general casting from long to int is simpler than from double to int

memory
1 int range is much smaller than double and for pow 2 100 that fails

memory
i don t understand how an int 63823 takes up less space than a double 1.0

memory
another option would be to add a cast not recommended due to the same loss of information the error warns you about - the fractional part will simply be removed from the value and double can hold way larger and smaller values than int

performance
using and at the same time to check equality on a int results in slower code because it takes two comparisons instead of one taking the double amount of time

memory
because a double which f expects probably is larger than an int on your platform

performance
the versions using diff are especially impacted ave_diff with int constants is about 2.5 times faster than the double contants version

memory
a double is 1 typically larger than an int and 2 has some internal structure

memory
for historical reasons you can not pass an int argument of smaller rank than int or a floating type of smaller rank than double to a variadic function

usability
double has range more than a 64-bit int but its precision is less dues to its representation since double is 64-bit as well it can t fit more actual values

performance
int subtractions are 2.5 times faster than double subtractions on my machine

usability
can be false when int range is wider than double uncommon and dx is a rounded value whose next higher representable value to 2 greater

memory
i know that there s another way to check if a double number is bigger than maximum int value but i m curious as why it s happening this way

performance
with it is nub on and comparing big int is slower than comparing double

memory
because a double is larger than an int this accesses the 4 bytes of the original int and an extra 4 bytes on the stack

memory
don t forget that the range of int is much smaller than the range of double

memory
the largest double value is also larger than the largest int so it would have to be a long

performance
if such a hardware unit is present floats double can be faster than int unless there is also hardware int support

memory
you can convert your object into double and then into int but you should take care as double value is much bigger than int

memory
if you tell it the top of the stack has a double and double is bigger than int you ve now just told it to take extra bytes off of the stack which is terrible

memory
int would take up less space than a double

memory
if one of the operands is a double the result of the multiplication would be a double which allows for a much larger range than an int

memory
a double is also probably bigger than an int

performance
and it shouldnt be too surprising that copying a double 3 strings and an int takes more time than copying a single double

memory
it doesn t matter if second member would be int short or whatever - as long as it is smaller than double sizeof struct will be 16

memory
in the third case double precision loss is much smaller than the int and you get something like

memory
i wanted to check if a double value is bigger than maximum int value but because converting function does not return an optional value i am not be able to check by using optional binding

memory
4 + 4 since int is smaller size compared to double padding of double size is done

usability
i am guessing this is because modifying a double is a more complex operation than modifying an int

performance
double is a different data type and generally much slower than int

performance
using and at the same time to check equality on a int results in slower code because it takes two comparisons instead of one taking the double amount of time

memory
1 if your data are int or some data form that takes less space than a double float

performance
int multiplications however are only 1.5 times faster than double multiplications

memory
because double can contain larger numbers than int or long

memory
int or int32 has a much smaller range than double

performance
i m writing a c# class to perform 2d separable convolution using int to obtain better performance than double counterpart

memory
your upccode int is larger than the long data type so i tried it with double which is a float but works

usability
it seems to be that double is much more flexible than int

memory
with the cast that bad stuff is undefined behavior most likely double is bigger than int and it overruns the memory for i

memory
one of long long and double is bigger than 3 int and a multiple of 8

memory
these conversions promote float to double and anything smaller than int to int or unsigned int

usability
it seems to be that double is much more flexible than int

memory
the problem is that the precision of the data type int is smaller as the precision of double the function pow returns double therefore the value of binarychar i will be implizit converted to double and so on.

memory
double is larger than an int hence the overflow

memory
you need to use 2 even if the number of bits in your int type is larger than the precision of a double since the number of used bits in the most significant value might only be 1

memory
in vararg functions such as printf int smaller than int are promoted to int and floats smaller than double are promoted to double

performance
also after the first coercion from a side effect of a benchmark as noted above r will operate on double s and that contains slower manipulations than on int s

memory
furthermore the representation of type double is probably larger than that of type int in your system 8-byte double s and 4-byte int s are common

performance
double is much slower than int

memory
typically a double is 64-bit ieee floating point with roughly 52 bits precision and with range much larger than 64-bit int so magnitude is no problem

performance
on my machine the double swap loop completes 11 times faster than the int swap loop

memory
double is much bigger than int

memory
the double has a bigger mantissa the int bits of the real number

memory
i know that there s another way to check if a double number is bigger than maximum int value but i m curious as why it s happening this way

memory
on many systems int is smaller than double so if that s the case on yours this is very likely to be the cause of your crash

performance
i figured out this was happening because i was storing the wall coordinates in double and although double are certainly more accurate than int they still aren t exact

memory
double is much bigger than int

memory
and since float is typically promoted to double with varargs calls if your int is smaller than your double this will break

memory
i wanted to check if a double value is bigger than maximum int value but because converting function does not return an optional value i am not be able to check by using optional binding

memory
bear in mind that if the double returned is larger or smaller than that which can be held in an int then the program behaviour is undefined

memory
you do explicit type casting to get your result in int because double is a larger data-type than int

memory
when the result of math.pow i j a double is larger than integer.max_value and you cast to an int then the result is integer.max_value

memory
this will work as long as the double is not bigger than what can fit in an int

performance
because all int s can be upcast to a double without loss and the pow function on a double is no less efficient that that on an int

performance
the difference is that int are still faster than double because it takes very few clock cycles to do arithmetic operations on int

performance
incrementing the value might be a special case but it s possible that on your machine incrementing double is slower than incrementing int

memory
i understand that the compiler isn t happy because a double might be larger than an int can hold but this particular control is guaranteed to be a value from 1 to 10 so i know that it will be okay

performance
often using int math is faster than double

memory
typically an int will use less memory than a double that is why one doesn t just use the largest possible datatype

memory
this is the reason for which if you use printf to print floats you don t need to say lf int the format strings and f is enough lf is needed for scanf however because that function stores a result and a float can be smaller than a double

memory
int takes less space than double on ram

memory
since sizeof int is very probably smaller than sizeof double this is going to lead to horror

memory
the math.round double a method returns a long which is a larger type than int

memory
int can hold a smaller range than double

performance
byte takes less memory than double and int and provides better performance than bigger datatypes especially better than double

memory
clearly calling int x on a double is asking for trouble since double can store bigger numbers than int

usability
finally you might want to look into uicollectionview which provides a lot more visual flexibility than uitableview and can be seen as a sort of generalization of the latter

reliability
i use firefox with firebug and yslow and think it s more reliable than pagespeed

reliability
i ve used both robospice is more robust but ion is easier on the eyes

performance
using printf isn t faster than cout but scanf is a little faster than cin 0.04s + - 0.05

performance
scanf is faster than cin printf is faster than cout etc

performance
at the beginning the insert performance of innodb is almost 50 times slower than myisam and tokudb is 40 times slower than myisam

performance
from my personal use i experienced about 5 - 10 times less disk usage due to tokudb s compression and it s much much faster than myisam or innodb

reliability
because fink is reputedly more stable than macports and has many more packages

reliability
because fink is reputedly more stable than macports and has many more packages

reliability
since i have seen many reports of the macports package manager being less reliable than the fink package manager i would suggest installing fink and then simply doing

memory
i want all of the images to fit inside the width of the text area which will change dynamically with the window size and i want them all to be the same height meaning of course that landscape images take up more horizontal space than portrait ones etc

usability
you have this issue because height in landscape mode is lower then in portrait

usability
now my doubt is when i rotate it to portrait mode from landscape mode since the width of the textblocks present inside the itemtemplate of listbox is already defined when i rotate the it to portrait i am not able to see all the data present it cuts off since the width of the portrait mode is less when compared to landscape mode

memory
in portrait the spacing is decent but in landscape mode i feel like the graphs should be bigger and take up more space than in portrait mode which is simply not possible with the tab bar and navigation bar

usability
you have this issue because height in landscape mode is lower then in portrait

memory
i guess you are able to see the complete layout in portrait just because portrait layout is having more space and your complete layout is fitting well but landscape is having lesser space

memory
topbar portrait height is bigger than topbar landscape height everywhere except iphone 6 plus

memory
because in landscape your height is smaller than in portrait you need to have a value smaller than 1.0

usability
its because the height of the screen in portrait mode is more when compared to height of the screen in landscape mode

memory
as landscape has lesser space than portrait you are able to view only top scrollview so only that portion would be scrollable

memory
but the only thing i get is that the activity is still in landscape but the rectangle now is smaller with the portrait dimensions and the camera becomes weird because the image is rotated 90 degrees and moves down when i move the phone left and up when moving the phone right

memory
i had an outlet of a viewgraph which was a subclass of uiview in which i drew some graphics.in landscape mode the size of the viewgraph is larger than in portrait mode

memory
your imageview in landscape is smaller than portrait

memory
topbar portrait height is bigger than topbar landscape height everywhere except iphone 6 plus

memory
obviously i want in portrait view the content area of this iframe to be smaller than in landscape

usability
if you switch between portrait and landscape when viewing this on an ipad3 you ll need to refresh the browser window between switches you can see that portrait mode is choppier than landscape

usability
the amount of spacing to the right of the uiview when in portrait mode is greater than i want for landscape mode and the distance from the bottom is less than i want for landscape mode

memory
you are using the screen size to generate your placeholder image and the width of the screen in landscape is bigger than portrait

memory
my problem with this is that the calculation works fine in the portrait mode but as soon as i switch to landscape mode the distance between bottom and button is bigger than in portrait mode

performance
most likely hashcode will be faster unless for whatever reason calling hashcode + equals once is much slower than calling compareto log n times

performance
most likely hashcode will be faster unless for whatever reason calling hashcode + equals once is much slower than calling compareto log n times

memory
we can call its compareto method to decide whether it is bigger than equals to or less than any int

usability
localization it s easier to translation text than images

performance
on i386 the dyld stub is much faster than the powerpc equivalent so we didnâ t bother doing extra work to bypass it

performance
plus the overhead of doing it is extremely costly- hive queries against hbase are on my cluster at least an order of magnitude slower than against plain hdfs files

memory
2 you probably want a namedtuple - i m pretty sure they re lighter than dictionary and you can access properties using dot notation for which i have an aesthetic preference anyway

performance
namedtuple have a lower overhead than dictionary since the duplicate keys don t have to be stored per item but have the convenience of named access

usability
creating an instance of the namedtuple is easier than creating a dictionary

performance
namedtuple should perform better less overhead than dictionary if the lists are long

memory
as namedtuple lighter than dictionary

performance
namedtuple is faster and significantly more memory efficient than a dictionary

usability
it seems to me that swift would be way simpler to learn then objective-c for beginners i know because i learned it in like 2 months and swift is less complicated and better laid out then objective-c

performance
bottom line i would personally hesitate to draw any simple conclusions of swift is faster than objective-c or vice versa

performance
it is possible for swift to be faster than pure objective-c in things that you would traditionally use c or c++ for anyway

performance
most importantly for your image processing app the compiler will optimize swift code to run faster than objective-c

performance
the swift one is dramatically slower then objective-c implementation

performance
as craig revealed within the announcement of swift it is said to be faster than objective-c by far

usability
as you can see the swift example is more complex and error prone than your objective-c code

performance
there are multiple reasons why the swift code is slower than the objective-c code

performance
the swift runtime is smaller than the objective-c runtime

performance
the swift one is dramatically slower then objective-c implementation

usability
swift is neither easier to read nor understand than objective-c

usability
on the other hand swift is easier to learn especially if you have objective-c background so it can be adopted during the time slowly and paralelly with using objective-c

usability
executable size of swift application is much bigger than size of objective-c application

usability
i have a objective-c application working fine and smooth to be more comfortable with swift i decided to write the unit tests for this app in swift

performance
my view is that if in some cases objective-c is faster than swift it doesn t mean that all over performance of swift is slower

performance
there are multiple reasons why the swift code is slower than the objective-c code

performance
wouldn t swift be slower than objective-c in this case since it is layered on top of it

usability
injecting code in a swift application is harder than it was for an objective-c application but it s still possible

usability
as you can see defining a singleton class in swift is much easier than in objective-c

memory
you will notice that swift bundles are always about 4-5 mb larger than their objective-c counterparts and this is precisely why

usability
download xcode free and learn objective-c or swift swift is easier to learn than objective-c

memory
the swift runtime is smaller than the objective-c runtime

performance
wouldn t swift be slower than objective-c in this case since it is layered on top of it

usability
adding lightweight generics to your objective-c api makes it easier to interface with swift because your api gets translated more precisely

security
apple seems to claim that the optional type in swift is safer than nil in objective-c but i don t understand why this is so

usability
early this month i started learning swift as i found it fun and easier than objective-c

performance
i don t think that as of today you can run these tests and determine with any certainty whether swift 1.0 is faster or slower than objective-c

usability
objective-c print is more readable compared to swift

usability
with swift the code is much more readable than with objective-c

usability
as you can see defining a singleton class in swift is much easier than in objective-c

performance
the perf hit will be ridiculous i know apple say swift execute faster than objective-c but this is low level so it will be harmless

performance
i don t think that as of today you can run these tests and determine with any certainty whether swift 1.0 is faster or slower than objective-c

performance
and also apple does might not confidently announce that swift is more faster than objective-c in all the cases

usability
however i read that swift was the successor of objective-c and i would feel more comfortable with swift syntax

usability
it is worth mentioning that there is a commercial product named jrebel that is much more powerful than jvm hotswap

performance
my intuition is that transient properties would incurr less overhead than persistent properties because they do not need to be persistent and read from the database so converting them to persistent properties will likely only make things slightly worse

usability
it is similar to incron however config uses a simpler to read ini file instead of a plain text file

usability
because spring s xml config is slightly more powerful than shiro s ini spring users are encouraged to use full spring config instead of shiro ini

performance
since json can store arrays i can create quite complex config with it and it parses faster than ini files

usability
automating sudo is slighly more complex if you need to pass the passwd but still can be done

usability
from my point of view the datamapper model is much easier to grasp but since activerecord is the defacto standard it feels weird to change the orm just for this little problem

usability
activerecord is much simpler then a datamapper but also much more limited

usability
datamapper is potentially more complex then activerecord but it s a lot easier to develop your domain model and database asynchronous then with activerecord

usability
activerecord is much simpler then a datamapper but also much more limited

performance
i d recommend datamapper for orm not only it s way faster than activerecord but it s also very modularly built and plugins are actual gems that you can easily install

usability
can you provide any useful example that shows ienumerable could be more useful than iqueryable

usability
entity framework s iqueryable implementation is more picky about creating new objects in objects than regular linq to objects ienumerable

memory
for your view to expect an ienumerable you need to change your view declaration to be also if you really need to perform a find use iqueryable first them return the result as ienumerable since the payload on ienumerable is smaller than iqueryable

usability
entity framework s iqueryable implementation is more picky about creating new objects in objects than regular linq to objects ienumerable

performance
i assume applying iqueryable will be much faster than the ienumerable not to forget i was able to use iqueryable on the other entities without any issues

performance
in simple words all operations on ienumerable causes simple iteratation over all elements well it s lazy ienumerable really slower than iqueryable

usability
if you would like a unified front-end for elasticsearch and opentsdb you could consider grafana which has support for both elasticsearch and opentsdb but less functionality than kibana in regard to elasticsearch

performance
note i recommend using opera - it is much faster than google-chrome as it doesn t have memory leaks and comes with a built-in ad blocker

usability
for comparison 0.68 usage means this outdated google-chrome release is more popular than the current and previous versions of opera the penultimate version of safari on ios and ie 9 or 10

usability
since you noted thoughts on other browsers would be helpful opera s kiosk mode seems more powerful than google-chrome s

performance
if multiplying is slower than addition then case 2 is slightly slower than case 1

performance
you can try x1 c1 and then x1 + c1 but i don t think the addition is much faster than multiplying on todays cpus

performance
we don t actually multiplying it s slower than simple addition and as you can see we destroy temporary register t0 but don t touch s0 s1

usability
however multiplying is a more complex operation than addition or shifting

performance
you can try x1 c1 and then x1 + c1 but i don t think the addition is much faster than multiplying on todays cpus

usability
however multiplying is a more complex operation than addition or shifting

performance
we don t actually multiplying it s slower than simple addition and as you can see we destroy temporary register t0 but don t touch s0 s1

usability
the boilerplate code would multiplying rapidly when the express get more complex than addition of two terms

performance
for certain kinds of transactions a stateless session may perform slightly faster than a stateful session

usability
dealing with a stateless cluster is often simpler then dealing with a stateful cluster

memory
service to build drools knowledge and get session i prepared a stateless engine lighter than the stateful one

performance
for certain kinds of transactions a stateless session may perform slightly faster than a stateful session

usability
while a lot of development has been done with stateless connections to solve most problems sometimes it s just simpler with stateful connections

usability
dealing with a stateless cluster is often simpler then dealing with a stateful cluster

usability
second in order to add or update the value of listview in general extends arrayadapter is much easier than implements baseadapter because of arrayadapter support add remove insert method by itself

usability
why is implements runnable a better option than extends from thread class

performance
is implements the rawcomparator that much faster than extends writablecomparator

memory
implements gives larger errors because i tried with extends

usability
note extends mouseadapter is easier since you only need to implements the methods you want to handle

memory
implements gives larger errors because i tried with extends

usability
second in order to add or update the value of listview in general extends arrayadapter is much easier than implements baseadapter because of arrayadapter support add remove insert method by itself

usability
however i do not know if webstorm has a comparable option like that as it has less functionality than phpstorm or even intellij

usability
you can also use scgi it is a lot simpler than fastcgi

performance
is there anything obvious in ubuntu that would otherwise be making sfphpview- render run slower than centos

performance
xapian is slightly more difficult to setup but is much faster than whoosh

usability
vmware has more features but costs 80 virtualbox on the other hand is more basic but is free for most users see virtualbox licensing faq for details

performance
from my experience vmware 5 is faster than virtualbox 4.2 rc3 and has better smp performance

performance
even though vmware has been faster for me i still use virtualbox because it s good enough and is free and im cheap

performance
virtualbox is slower than vmware

reliability
however i found that vmware is much more stable full screen resolution much much better to handle the iphone connection via usb and i didn t have yet any crash when on virtualbox it s quite often

performance
in my experience i ve found that vmware seems to be faster than virtualbox although i don t have any hard data to back it up

memory
memory optimizations - phusion passenger uses less memory than thin and unicorn

usability
you may also consider using a listview which is easier to customize than the gridview

memory
regarding comparison between gridview and listview my experience is that listview is more lightweight as compared to gridview

usability
mayavi makes it easier to visualize the data but matplotlib looks more professional

usability
mayavi has more options for moving the camera than matplotlib but it doesn t seem to have a way to rotate around the y axis so i m guessing i ll need to perform some complex calculations on the azimuth and elevation to achieve the same result - but i m at a loss as to where to start i m new to working in 3d space and my brain doesn t think that way yet

memory
phpmyadmin also shows the larger number however i have switched to heidisql since i find it s gui is superior for my local development

memory
phpmyadmin also shows the larger number however i have switched to heidisql since i find it s gui is superior for my local development

performance
in google-chrome it seems .prototype is faster firefox shows no difference between the two although generally performs slower than google-chrome

performance
however if thats the case does this mean firefox is faster in execution than google-chrome

performance
based on what you have provided i cannot tell if google-chrome actually does load faster than firefox

performance
firefox is slower than google-chrome in javascript

performance
that means firefox is more than 7x faster than google-chrome here

performance
i use google-chrome for development as i find it runs faster than firefox and ie so it is a bore to guess where the icons are

performance
as you said google-chrome is faster than firefox so the webdriver is trying to interact with the dom before when elements are not yet visible exist

usability
with firefox it was very easy i just grabbed the apk from their ftp server run the adb install command one would think it should be even easier with google-chrome but it s really not

memory
for example if you have a text size of 15px well firefox makes a larger 15px than google-chrome does

memory
why in firefox text smaller left than in google-chrome and opera right

usability
firefox may be sniffing the document s encoding with more flexibility than google-chrome is

performance
it depends on the browser its definitely true for ie and firefox but seems slower on google-chrome

performance
better use google-chrome even thought firefox is not slower than google-chrome for once probably the tracing for the image comparison pays off yay

performance
i ve tested the sample on firefox and it s a bit slower than google-chrome but usable

performance
right now google-chrome is faster than firefox sunspider tests so your statement it loads faster in firefox is not really correct

performance
also google-chrome s map function is up to 2x slower than firefox on my machine

performance
use firefox rather than google-chrome - google-chrome with dev mode is much slower than firefox

performance
svg performance in firefox is slower than in webkit google-chrome and ie10

performance
spidermonkey firefox is slower 50 of google-chrome max speed but the speed is consistent

performance
firefox is even slower that google-chrome

security
found that the issue stemmed from using the firefox webdriver which apparently has much higher security than its google-chrome counterpart

memory
my question is similar the same page in my pc renders fine firefox google-chrome but the same one on a server rendered smaller by firefox google-chrome ok

memory
i have too problem with text in the firefox is bigger maybe bolder as in google-chrome .

performance
google-chrome is just faster than firefox which just faster than ie at bit-wise operations

performance
i am not concerned about the fact that firefox runs faster as browser js implementations will vary so much as the wide spread of results encountered in google-chrome that makes getting an accurate result impossible

security
i ve learned partly by trawling this site that the google-chrome security is fussier and the app loads correctly without errors in firefox and ie but i can t find any resources that are loaded from a non https source

performance
here is a simple performance test showing that in google-chrome filling is faster than clearing i am not sure what goes on with google-chrome and canvas nowadays but in firefox clearing is many times faster than filling both significantly faster than google-chrome

memory
while the rest of the browsers report the correct width of the document firefox reports a smaller one example at screen resolution of 1920x1080 ie google-chrome and safari reports 1920 while firefox reports 1903

performance
rendering without buffering on google-chrome is faster than firefox so i m actually not sure why google-chrome is having such a problem with drawimage

performance
because of how google-chrome s plugin system works development mode in google-chrome is much slower than in firefox or safari see here for more details

performance
google-chrome is extremely slow for your code path but grep seems to be 50 faster than array.filter here making it 900 slower than the firefox run

memory
suffice to say ie and google-chrome start having problems at larger heights than does firefox

usability
firefox is probably easier than google-chrome these days

performance
the reason google-chrome is slower than firefox is that the devmode plugin runs in a sandbox so calls and data have to cross the sandbox boundaries

performance
the funny thing is that for abc_def property google-chrome is actually much faster than firefox and ie as i expected

usability
firefox is easier and better than google-chrome in finding the element from the webpage

memory
google-chrome has a bigger time difference yet firefox is the one with the gap in the animation

performance
do you have any idea why google-chrome loads javascript function much slower than firefox

performance
the results varied from a browser to another firefox 4.0b12 is faster using but google-chrome webkit and opera is faster when using

performance
in google-chrome typeof is slower than the other two but in firefox it is the fastest

performance
now when clicking a time less than 1 millisecond will be displayed however it obviously takes nearly a second on my computer until the changed color actually is displayed where btw. google-chrome seems to be faster than firefox

usability
another alternative for javascript ajax is writing a google-chrome add-on easier than firefox or embeding a web browser within your application

memory
for example if you have a text size of 15px well firefox makes a larger 15px than google-chrome does

memory
safari and opera work with the google-chrome setting but firefox and ie display the iframed page larger than google-chrome causing part of the text to be cut off

memory
in google-chrome the button should be a tad smaller than in firefox

performance
firefox is slower than google-chrome which boats one of the highest javascript engines a modified version of webkit

performance
and also does anyone know why is firefox so much slower than google-chrome in 3d rendering

performance
in ie8 and google-chrome it runs even faster than firefox in general and this slow down never happens

performance
also firefox 4 has hardware accelerated canvas that is marginally faster than ie9 and a lot faster than google-chrome

memory
in google-chrome the font appears to be 1px smaller than firefox and ie and i cannot see why

memory
in google-chrome the green div is bigger than in firefox i really don t know what is the problem i think in firefox it displays as it should but in google-chrome and ie9 it displays different

performance
as google-chrome s v8 is dramatically faster than firefox s spidermonkey at the moment these things are constantly in flux pick the forward loop as it s faster on the slower engine

performance
of late firefox has had much better performance than google-chrome

memory
my menu links seem in google-chrome correctly but in firefox my menu links are 1 px smaller than google-chrome

performance
firefox - good a bit slower than google-chrome

memory
firefox thumbnail 4 times smaller than on google-chrome

memory
i ve found that the font-size in firefox is a bit larger than in google-chrome

memory
google-chrome has a bigger time difference yet firefox is the one with the gap in the animation

performance
google-chrome is just faster than firefox which just faster than ie at bit-wise operations

memory
if i remove this code the width of green image in firefox becomes smaller but it s still bigger than necessary about 100px the google-chrome images keeps unchanged

performance
for example using renatoargh s test google-chrome is faster with option 2 firefox with option 1

usability
i found programming google-chrome extensions easier than firefox but i couldn t come across something similar to xpcom in google-chrome

performance
because of how google-chrome s plugin system works development mode in google-chrome is much slower than in firefox or safari see here for more details

performance
in firefox it takes some more time compared to google-chrome safari

memory
but in firefox the left-collumn gets a much bigger height than in google-chrome

performance
and of course the results - if they are reproducible - might suggest that google-chrome is faster than firefox or that firefox just prioritises timeouts over dom events

reliability
2 install the firefox extension there s also one for google-chrome but the firefox one is more reliable -- so if you re a google-chrome addict like i am then use both

performance
this is trickier to work around and you should file a google-chrome bug describing the situation and where it s slower than firefox but you could potentially reduce the amount of buffer uploads by looking into instancing or using uniform arrays instead of updating vertexes for positions textures

performance
in my experience google-chrome will be a lot faster than firefox to debug huge js files

memory
why height in google-chrome is bigger than firefox of input

memory
arabic default font in google-chrome is larger than it is in firefox

memory
firefox produces more space compared to google-chrome

usability
i have been trying to do this in firefox webextensions but if it s easier with google-chrome i will try it that way instead.

memory
if we remove the font-size it appears properly in google-chrome but shows up smaller in firefox

performance
when i posted this on facebook someone said that since firefox is open source project developers optimized math.min but google-chrome didn t since google-chrome is just a modification of chromium but beside that above statement is not quite right that makes no sense because that doesn t explain the reason why google-chrome s and firefox s math.min a b performs in similar speed and google-chrome s math.min a b and firefox s performs in same speed because if firefox is faster than google-chrome then google-chrome s math.min a b should be much slower than firefox s

performance
tldr in firefox filter is slightly faster in google-chrome that s the opposite

performance
better use google-chrome even thought firefox is not slower than google-chrome for once probably the tracing for the image comparison pays off yay

memory
here the working header request with firefox bigger than google-chrome request

performance
this makes firefox 50x faster than google-chrome and 70x faster than safari is there any known reason for that

performance
using firefox even it s slower than google-chrome it s still more respectful of privacy

memory
google-chrome renders passwords smaller than firefox

performance
update just tried it on firefox 30 and it did not experience the same slowdown in a worker thread but it was slower than google-chrome when run in the main thread

usability
firefox is probably easier than google-chrome these days

memory
i am checking it in firefox and google-chrome and see that in google-chrome spacing between letter is larger than in firefox

memory
google-chrome renders passwords smaller than firefox

performance
but i guess google-chrome i have version 10 should be much faster than firefox 3.6

usability
google-chrome is more flexible in this sense than firefox which is why it works there

performance
maybe google-chrome is working faster than firefox try adding a wait with expected conditions

performance
on google-chrome it s significantly faster to do this using 1 0 but on firefox it s slightly faster to do this using bool

memory
i have too problem with text in the firefox is bigger maybe bolder as in google-chrome .

memory
it looks like google-chrome is smaller in your screenshot there so firefox could just not be at the defined break-point yet

performance
i ve found that firefox is greatly faster with imacros than google-chrome

performance
when i posted this on facebook someone said that since firefox is open source project developers optimized math.min but google-chrome didn t since google-chrome is just a modification of chromium but beside that above statement is not quite right that makes no sense because that doesn t explain the reason why google-chrome s and firefox s math.min a b performs in similar speed and google-chrome s math.min a b and firefox s performs in same speed because if firefox is faster than google-chrome then google-chrome s math.min a b should be much slower than firefox s

performance
the trouble is choosing a good value for x since for this particular page google-chrome is so very much faster than firefox which is faster than ie

memory
that happens because pixels size in google-chrome is bigger than in firefox

performance
i have been working with linear parsers lately and noticed the performance in google-chrome v37 was much slower than in firefox v30

memory
this is because in ie and firefox the footer link text is larger than in google-chrome and safari therefore the margins that i ve set up for the icons do not work

performance
it s just a matter of preferences and browser implementation eg firefox works faster with brackets while google-chrome works faster with the dots

performance
so why is google-chrome less efficient than firefox and ie

performance
why is firefox so much slower than google-chrome on my laptop

performance
as you can see ie 8 is about 5 times slower than firefox 3.6 and almost 20 times slower than google-chrome 9 at least when using sunspider tests

performance
what we can see is that regardless of raw hardware power google-chrome seems to run up to three times faster than edge and also significantly faster than firefox all updated to the latest verion

memory
i built a site and the problem is google-chrome display font-size 1px bigger than firefox

reliability
parsley is more robust and adds a lot more features than robotlegs which is why its been used in the world s largest flex applications

usability
parsley is more robust and adds a lot more features than robotlegs which is why its been used in the world s largest flex applications

usability
with requestfactory you pay an up-front startup cost to accommodate more complicated systems than gwt rpc easily supports

performance
gwt requestfactory by design is slower than gwt rpc and gwt json etc

usability
the qtablewidget is slightly easier to implement than the qtableview which also needs a qtablemodel as backend but it has less capabilities

usability
fifth many-to-one is much easier to use correctly in nhibernate and i assume hibernate than one-to-many collection mapping

performance
inverse is for bidirectional associations and most often it s on the same side with cascade but that s because the many-to-one side is much more efficient to control the association than the one-to-many one

memory
it is saying this because using the int to store the value 32 bits is going to use less space than a boolean 256 as each allocated boolean will take up 8 bits 8 256 2048

memory
would a boolean array of size 32 take more space than an int variable for example

performance
since the logic is the same i thought evaluating boolean objects takes more time than int equivalence true 1 and false 0 therefore i came up with the following benchmark and it turns out that i was correct

performance
since the logic is the same i thought evaluating boolean objects takes more time than int equivalence true 1 and false 0 therefore i came up with the following benchmark and it turns out that i was correct

performance
the int version seems to execute much faster than the boolean one

performance
i always assumed that boolean were more efficient than int at storing an on off value - considering that s their reason for existence

memory
a boolean takes less space than an int

memory
int occupy more memory than boolean so the heap got corrupted

memory
keep in mind that depending on the use and on the system using it while a boolean takes less space because it s just a single bit depending on the implementation an int is the native word size of the hardware

performance
a boolean would most likely not yield better performance than int since the excel formula engine is dynamically typed

performance
however the second loop causes the additional task of casting each of the values between a.length and 0 to a boolean which is more time consuming than int comparison

performance
the benchmark shows rythm is 2 to 3 times faster than velocity on a normal page

performance
rythm is a strong typed java template engine using razor like syntax with high performance 2 to 3 times faster than velocity and fm

performance
rythm is a strong typed java template engine using razor like syntax with high performance 2 to 3 times faster than velocity and fm

performance
rythm is a high performance 2 to 3 times faster than velocity pure java template which use razor like syntax

performance
you should always use the timeit module for time trials it is far more accurate than cprofile here

usability
i haven t played around with it recently but i think bcolz is more flexible here in terms of mixing dtypes but doesn t give you all the pandas dataframe conveniences obviously

performance
but for a really useful explanation you d have to tell us exactly which database and library you re using and which python versionâ cpython 3.3.2 s csv module seems to be a lot faster than cpython 2.7.5 s and pypy 2.1 2.7.2 seems to be faster than cpython 2.7.5 as well but then either one also might run your code faster tooâ and so on

performance
pypy is supposedly faster than cpython while gevent is based on co-routines and greenlets which supposedly makes for a faster web server

memory
if the dominant memory usage is program data structures then i wouldn t be at all surprised to find pypy using significantly less memory than cpython whether or not the jit was enabled

memory
secondly the current version of pypy consumes much more memory than cpython in a rather large set of cases

memory
i know many of pypy s data structures are actually smaller than cpython s but again that has nothing to do with the jit

performance
long-term evidence is showing that pypy runs certain python codes slower than cpython and this drawback seems to be rooted very deeply in pypy

performance
pypy which in general is much faster than cpython is considerably slower for this use case

performance
pypy is supposedly faster than cpython while gevent is based on co-routines and greenlets which supposedly makes for a faster web server

performance
i saw that pypy is generally faster than cpython

performance
as mentioned by ifloop this would be running a cpython c extension module on pypy which often works not always but is slower than on cpython

performance
in the competing programming a lot of problems are never meant to be solved with cpython but with pypy which has a faster integer-arithmetic and a git-compiler but otherwise a python interpreter just as cpython

performance
i haven t tried comparing the two but this pypy bug seems to suggest that multiprocessing in pypy is slower than in cpython

memory
secondly the current version of pypy consumes much more memory than cpython in a rather large set of cases

performance
i finally ran it through pypy and was delighted to discover that when the lists got really deep pypy was running significantly faster than cpython

performance
you might want to try running your trainer under pypy if you aren t already -- it s significantly faster than cpython for some workloads

performance
so how is it possible for pypy to be faster than cpython also becomes fairly obvious

performance
that site does not claim pypy is 6.3 times faster than cpython

performance
as gnibbler pointed out cpython is slower in the simple implementation but pypy is jit compiled for much faster code when you need it

performance
unfortunately as martijn pieters noted there are no accepted solution for python 3.x and only one for python 2.x and according to the amount of memory spent for solving it numerix could have used psyco the library on which pypy is based much faster than cpython

performance
some people may argue with me on this one but i find pypy to be faster than cpython

performance
pypy s jit can make python code execute much faster than cpython

performance
can someone please help to how use that script using the pypy as i heard it is much faster than cpython

performance
just keep in mind most of the time c is faster than python but then again most of the time pypy is faster than cpython

performance
note that there are plenty of python implementations other than cpython out there - for loopy code pypy tends to be much faster than cpython

performance
cpython is faster than pypy on the two tests slowspitfire and waf

performance
i saw that pypy is generally faster than cpython

performance
you could try running it in pypy - for some cases it can be significantly faster than cpython

memory
when people talk about pypy using less memory than cpython this is a major part of what they re talking about

performance
if that isn t sufficient a lot of standard python code can be run on the pypy implementation which generally faster than the cpython implementation

performance
i presume it s why is pypy faster than cpython some of the time

performance
pypy is now faster than cpython in most cases

performance
pypy is now faster than cpython in most cases

performance
however consider that pypy might do the linear search 100 times faster than cpython then a few times might be dozens

performance
part of the compiler toolchain includes an experimental jit generator now in its fifth incarnation and starting to work really well - the goal is for a jited pypy to run much faster than cpython

performance
jython is more unpredictableâ sometimes almost as fast as pypy sometimes much slower than cpython

performance
pypy is faster than cpython s sum intrinsic because it can figure out that all the elements of the array are numeric and slice out a bunch of per-element overhead

performance
i ve tried using pypy because i ve heard its faster than the cpython interpreter but still no good

performance
pypy compiled with jit is almost always faster than cpython frequently by a large margin

performance
so at this point in time pypy is just over 9 times faster than cpython in this micro benchmark

performance
this is why pypy may be slower than cpython sometimes it needs a warm-up phase in which it can actually optimize repeated operations

performance
under cpython tests run 4 times faster than under pypy

performance
in the competing programming a lot of problems are never meant to be solved with cpython but with pypy which has a faster integer-arithmetic and a git-compiler but otherwise a python interpreter just as cpython

usability
the pypy jit for python is also much more complex than cpython but also typically much faster â increased complexity is a fairly typical cost for speed. the four levels of disassembly for julia code give you access to the representation of a julia method implementation for particular argument types at different stages of the transformation from source code to machine code

performance
the answer is simple here - pickle on pypy is slower because it s implemeneted in pure python as opposed to c in cpython

performance
for python there is a pypy project which it includes jit making possible the code to run faster than in cpython in many cases

performance
judging from the benchmarks posted on the pypy speed center it appears as if pypy is faster than cpython for all but two of the tests presented

memory
any device in the path of communication between the sender and receiver whose mtu is smaller than the packet will drop such packets and reply the sender with icmp destination unreachable datagram too big message containing the device s mtu

performance
using apaches httpd.conf is faster since accessing the .htaccess adds a small overheadâ apache checks every directoryâ and parent directoryâ for the file and it will be loaded for every request

usability
double has its ieee floating point definition which is also much more complex than decimal

performance
decimal types libraries are fantastic for financial applications because we re used to dealing with the style of rounding required in financial stuff but there is the cost that they tend to be slower than ieee floating point

performance
crfsuite is faster than crf++ and it can deal with a huge training data

performance
if you are targeting android you can use firefox for android by developing a webapp that has native mathml support and because of it will be much faster than mathjax or other javascript solution

usability
i have been reading about cakephp but it seems a bit more complicated than codeigniter

memory
i personally use codeigniter which probably falls in to the heavy framework category but is at least much lighter than cakephp and lighter than zend too i think

performance
cakephp is considered slower than codeigniter but you can tweak it to enhance speed

memory
i suspect codeigniter doesn t have quite as flexible a structure it s smaller and lighter than cakephp but a quick look at the cakephp manual to see how behaviors components helpers and the vendors folder may be helpful

memory
in my view cakephp seems much more lighter then codeigniter but i never used either one so i can t judge

usability
cakephp is newer more feature rich and heavier than codeigniter codeigniter is designed to have a much smaller footprint so you will most likely find yourself creating functionality in codeigniter to match cake s

memory
well jspm is much larger and ambitious project than bower

performance
see the referred post for an example that reads a single file in parallel with fileinputstream which should be significantly faster than using bufferedreader according to these benchmarks

usability
the check for convex polygons your triangle is simpler than for concave ones see first linked article

performance
mergesort - in general mergesort is consistently faster than quicksort however quicksort is done in place and doesn t require allocating memory unlike mergesort

performance
however on smaller int sizes quicksort gets slower and mergesort gets faster

performance
quicksort generally runs faster than mergesort but under some circumstances it can degrade to quadratic running time

performance
quicksort is usually faster than mergesort just because it s easier to code a tight implementation and the operations it does can go faster

performance
quicksort is implemented well it is typically 2-3 times faster than mergesort or

performance
for the 10 tests on the same list the results should be quite the same at least all showing that quicksort is faster than mergesort or vice vesa

performance
i have read that quicksort is much faster than mergesort in practise and the reason for this is the hidden constant

performance
mergesort is slightly slower than quicksort but it does not have quicksort s susceptibility to pathological cases

usability
i would say that the quicksort is simpler for parallelizing than the mergesort

performance
it might be helpful to see why quicksort is usually faster than mergesort since if you understand the reasons you can pretty quickly find some cases where mergesort is a clear winner

performance
the quicksort algorithm is faster than mergesort which is what sorted will get you when called on a sequence of objects via java.util.arrays.sort

performance
quicksort is usually faster than mergesort just because it s easier to code a tight implementation and the operations it does can go faster

performance
purely in terms of the number of comparisons performed is mergesort always more efficient than quicksort

performance
in most cases quicksort will run faster than mergesort even though the worst-case execution time is longer

performance
when comparing my quicksort implementation with std sort on my compiler and my implementation of mergesort i noticed an odd pattern on large data sets when operating on 64 bit integers quicksort is consistently faster than mergesort

usability
parallelizing mergesort is simpler than quicksort in-place

performance
as many people have noted the average case performance for quicksort is faster than mergesort

performance
mergesort is slightly slower than quicksort but it does not have quicksort s susceptibility to pathological cases

performance
when comparing my quicksort implementation with std sort on my compiler and my implementation of mergesort i noticed an odd pattern on large data sets when operating on 64 bit integers quicksort is consistently faster than mergesort

performance
from what i ve read i was expecting quicksort to be faster than mergesort but on my code it is not so i assume there must be a problem with my quicksort algorithm

memory
mergesort may use more space than quicksort i m not entirely sure and merge may be better for linkedlists

performance
i have read that quicksort is much faster than mergesort in practise and the reason for this is the hidden constant

usability
quicksort is also more complicated than mergesort especially if you want to write a really solid implementation and so if you re aiming for simplicity and maintainability merge sort becomes a promising alternative with very little performance loss

performance
you can also see that for smaller collections quicksort is faster but then mergesort takes the lead but all of this is case specific so take your time to study all 4 algorithms

usability
quicksort is worse complexity than mergesort in the worst case.

performance
when comparison function is a callback function like in quicksort libc implementation quicksort is slower than mergesort by 15 on random input and 30 for already sorted array for 64 bit integers

performance
quicksort generally runs faster than mergesort but under some circumstances it can degrade to quadratic running time

performance
depending on where i look people say quicksort is faster than mergesort due to its locality of reference cache hits etc

performance
normally quicksort is faster than mergesort which is faster than heapsort

performance
mergesort - in general mergesort is consistently faster than quicksort however quicksort is done in place and doesn t require allocating memory unlike mergesort

performance
to be specific the quicksort runs faster than mergesort in the first test case and loses badly in the following 9 tests

performance
it might be helpful to see why quicksort is usually faster than mergesort since if you understand the reasons you can pretty quickly find some cases where mergesort is a clear winner

performance
i have been testing the practicality of openmp gnu parallel sort algorithms in the c++ standard library and have found the parallel quicksort algorithm to be significantly slower than the mergesort algorithm

usability
quicksort is also more complicated than mergesort especially if you want to write a really solid implementation and so if you re aiming for simplicity and maintainability merge sort becomes a promising alternative with very little performance loss

performance
it s because that quicksort is generally faster that people use it instead of mergesort

performance
quicksort is approximately 40 faster than mergesort on random data because of fewer data movements

memory
because most of the case zero-altitude distance is quite larger than altitude itself so normally you can ignore altitude

memory
because most of the case zero-altitude distance is quite larger than altitude itself so normally you can ignore altitude

usability
memcmp is simpler than strcmp and can be implemented even more efficiently in places where the strings are known to be properly aligned

performance
if you always keep track of the lengths of your strings you can compare lengths and use memcmp which is faster than strcmp

usability
similarly you might find using jacoco easier than cobertura

performance
in my understanding repeater is most suitable since it faster than gridview

performance
the repeater is still faster than the gridview but the difference shouldn t be big if you code it right

performance
the repeater is still faster than the gridview but the difference shouldn t be big if you code it right

performance
on almost any platform memcpy is going to be faster than strcpy when copying the same number of bytes

performance
for example for small amounts of data an memcpy optimised for large amounts of data may be significantly slower than a strcpy that wasn t optimised for large amounts of data

performance
memcpy can be more efficient than strcpy since rep movs is highly optimized on intel cpus esp

performance
so i feel that on x86 memcpy is faster than strcpy

performance
memcpy is usually faster than strcpy for longer strings

performance
notice that memcpy is faster than strcpy unless the source string is much smaller than the buffer s size which is rarely the case with ip addesses.

performance
memcpy is not really any slower than strcpy

performance
memcpy is rarely slower than strcpy or strncpy and often significantly faster

performance
because of the above replace strdup with strlen malloc memcpy memcpy is slightly faster than strcpy

performance
memset behaves like strcpy but the difference is that memcpy copied the data as it is byte but strcpy copies the formatted string as well so takes more time than memcpy to execute

performance
performance difference memcpy is usually more efficient than strcpy which must scan the data it copies

performance
if size is known normally a non-naive implementation of memcpy is faster than strcpy since it takes profit of the cpu s data bus size

performance
but sometimes memcpy performs faster than strcpy because it moves blocks of memory at a time which allows it to perform some optimization i will not go into details here

performance
information - use memcpy as it s faster than strcpy and we know

performance
we keep track of what cmd s length ought to be in a variable and copy the string with memcpy which is slightly faster than strcpy and does neither check string length nor copy the extra zero at end of string

performance
memcpy is rarely slower than strcpy or strncpy and often significantly faster

performance
memcpy is faster than strcpy and also enforces you to specify a buffer size

performance
because of the above replace strdup with strlen malloc memcpy memcpy is slightly faster than strcpy

performance
performance difference memcpy is usually more efficient than strcpy which must scan the data it copies

performance
is memcpy usually faster than strcpy on most real platforms

usability
the reason for not having strcpy i m guessing is that strcpy can be replaced more efficiently with memcpy for constant strings and if the string is not constant strcpy is a bit more complicated than memcpy anyway so not as beneficial to make inline optimisations for

performance
memcpy is usually faster than strcpy for longer strings

security
your macro with memset and memcpy was not any safer than strcpy

performance
we keep track of what cmd s length ought to be in a variable and copy the string with memcpy which is slightly faster than strcpy and does neither check string length nor copy the extra zero at end of string

usability
having used both i can tell you that it s a much more polished platform the servers are about 4ã faster you can run as many apps as you want and the heroku toolbelt is much more powerful than the openshift s client tools

performance
it is understandable that memset is faster than memcpy

performance
the problem is that memcpy is only slighly slower than memset when i expect it to be about two times slower since it operations on twice the memory

memory
if you want to exlude a number 4 that means the range is smaller by 1 so use r.nextint 5 and if the result is the excluded number then return the max allowed which is 5 because it will never be generated because you used max - 1

memory
that occasional max threshold is actually bigger than the range of small instance

memory
that occasional max threshold is actually bigger than the range of small instance

memory
if you date range is larger than the two years displayed just drag the formulas down to expand the max range

memory
the recursive cte is troublesome because it is limited to a max size of 32 767 much smaller than potential range sizes and has the very real possibility of being very slow

memory
but with this the last range is larger than the max value

memory
in general you want to have a range slightly larger than x max - x min and then divide the range into the desired number of bins

memory
a signed 64-bit integer range from âˆ 2 63 to 2 63 âˆ 1 the absolute value of 0x8000000000000000 or âˆ 2 63 is 2 63 is bigger than the max 64-bit integer

memory
so if you re getting a step exceeds the specified range error i d guess that the default step value 1 is larger than the max of the range the result of .

memory
i ll leave the rest up to you ov checking for error conditions such as more than 1 column passed in the range or range of unequal size or a max # of items returned being larger than the range size

memory
to create equal bins you can simply first define a min and max value which is slightly smaller than both range

memory
basically if you know that your events are never larger than a given duration you can search for a bounded range that s larger than the max duration then add restrictions to get rid of the extra stuff that matched

performance
murmurhash has 64 and 128-bit versions so you can experiment between the two and it s faster than md5 largely owing to md5 being a cryptographic hash function whereas murmur doesn t have the added expense complexity of being cryptographically secure i m assuming that you re not concerned about anybody attempting to intentionally generate hash collisions or anything like that

performance
but as that reference points out murmurhash is way faster than md5 and sha functions although it doesn t do a direct comparison to the object.gethashcode method i mentioned above

performance
should i be surprised that the keras theano backend is about 18x - 19x slower than the keras tensorflow backend

usability
in some ways the jquery-week-calendar has more features at the moment but fullcalendar has a bigger following and is closing the gap on features

performance
using drawimage canvas is much faster than using putimagedata

performance
drawimage seems to be much faster than putimagedata

performance
that beeing said putimagedata is much slower than drawimage at least when i tested them earlier this year

performance
as of right now drawimage is much faster than putimagedata

performance
the only problem that as far as i know using drawimage is slower than using putimagedata and it was required in old browser versions like firefox 2 or such

performance
right now putimagedata is much slower than drawimage as you can see here

performance
i have seen that the drawimage function is really faster than the putimagedata

performance
using the clipping version of drawimage will be faster than putimagedata

performance
as of right now drawimage is much faster than putimagedata

performance
that beeing said putimagedata is much slower than drawimage at least when i tested them earlier this year

performance
right now putimagedata is much slower than drawimage as you can see here

performance
using drawimage canvas is much faster than using putimagedata

usability
i have seen that the drawimage function is really faster than the putimagedata

performance
after a lot of googling i ve found that most sources say that the dijkstra algorithm is more efficient than the bellman-ford algorithm

performance
since a proper implementation of dijkstra is faster than bellman-ford use dijkstra unless there are negative weight edges in the graph

performance
the only issue with applying that technique for the single source shortest path problem is that reweighting with bellman-ford takes o mn time which is slower than dijkstra s o m log n

performance
bellman-ford as suggested in your question tends to be slower than either dijkstra s or a - it is primarily used when there are negative edge-weights which there are not here

usability
surely there is some situation in which the bellman-ford approach is better than the dijkstra approach

memory
since servers omit the working copy you should generally expect server-side bare repositories to be smaller than client-side non-bare repositories

performance
since you don t want to repeat yourself it s very tempting to put all your validation on one side or the other but there are tradeoffs either way and it is true that server-side validation is going to be slower than client-side

reliability
the server-side way is more reliable and browser-independent while the client-side approach will decrease the amount of incoming traffic to server

performance
as a general rule of thumb at least in security you should trust no user so i think it would be the wise choice to validate the data client-side it s also faster and then if the first validation passed validate it server-side to double-check or to have a safety net if the user has javascript turned off something you don t see that often

performance
client-side validation is faster than server-side because the validation takes place on client side on browser and the networking time from client to server is saved

reliability
i am curious to know if detecting the visitor browser with client-side script is more reliable than server-side script

usability
i think this method of manipulating the dom from the client-side is easier than using regex from a server-side language

usability
my guess is that server-side implementation may turn out to be more flexible and more powerful than client-side as i can add functionality to the server easily as long as the client understands it

reliability
i am curious to know if detecting the visitor browser with client-side script is more reliable than server-side script

performance
while not really a console skulpt.org runs python code client-side with no plugins or anything which makes it a lot faster than a server-side prompt

usability
now if you aren t generating your html server-side and are instead writing it by hand you can make your life just a dash easier with a client-side transformation like this

reliability
right now queryover is much more robust in the nhibernate community mainly because it is based on criteria queries which have been around for quite some time

usability
if you re looking for a ctrlp equivalent webstorm has a fuzzyfinder that s actually much more powerful than ctrlp

reliability
the libsvm results seems much more stable but scikit-learn results have some drastic fluctuation

performance
or is the do.call with by just typically much slower than tapply

performance
but this popular wsgi benchmark says eventlet is way slower than gevent

performance
but this popular wsgi benchmark says eventlet is way slower than gevent

performance
extfs4 or xfs are between 25 and 40 faster than ntfs or refs depending on the optimization

usability
other options to check are relaxng which is more flexible and powerful than xml schema or schematron which allows for exactly this sort of validation that needs to go deeper than structure and simple type-checks

usability
additionally if you have strdup then it is much more convenient than strlen + malloc + strcpy with identical result including the same obligation to free the allocated storage when you no longer need it

performance
if the taskproperty class is decorated with datacontract attribute and with datamember attribute for each property the deserialization is much faster than when it is decorated with serializable attribute

usability
side note check-out the json.net serializable which gives more options and better control over the deserialization process

usability
you ll need to implement serializable to have java handle the serializable or externalizable if you need more control over the deserialization process

usability
side note check-out the json.net serializable which gives more options and better control over the deserialization process

performance
for example i ve read that opera and ie will fix framerates slower than firefox

usability
firefox just provides far more access to its own internals and system to the extensions so its technically possible to do more with them than with opera widgets or google-chrome extensions

memory
update under linux gentoo amd64 it s the same - opera reneders slightly larger fonts than firefox but nothing that looks odd

memory
on your screenshot div width in opera is bigger than in firefox and google-chrome

performance
it seems to be slower in google-chrome and firefox but is significantly faster in opera

performance
but if firebug donâ t enabled after launch firefox â time equal 2ms that faster than opera and google-chrome and difference between empty filled array disappears

reliability
adding and subtract logarithms of factorials then taking the exponential at the end is more reliable than multiplying and dividing factorials directly

performance
subtract is faster than multiplying

memory
the logic is multiplying by 2 whole number 0.1 2 0.2 and if it s bigger than 1 subtract and continue

performance
p is sometimes chosen to be 31 because not only is it prime but a compiler resolves it to a bitshift and a subtract which is much faster than a multiplying

performance
p is sometimes chosen to be 31 because not only is it prime but a compiler resolves it to a bitshift and a subtract which is much faster than a multiplying

usability
edit for clarification miglayout is probably easier to use than gridbaglayout but if you get familiar with gridbaglayout it s not that hard to use and it doesn t require a download since it s part of the core java library

usability
you can also check out the open-source miglayout which is much more convenient that gridbaglayout and also a bit more powerful

performance
stemming gives better performance than fuzzy search because it is done when indexing and the actual search can be performed as exact match

usability
the nstextview process is much simpler as you only need to attach the nstextstorage object

usability
if your service already has an rss feed things are even easier with the rss reader integrated in the buzzbox api

performance
the atom feed option seems to load faster than the rss one fwiw

memory
magento is way ahead and has larger extensions than opencart

performance
magma routine magma_gemm has higher performance than cublas in some cases

performance
doing it with mouse is much more slower than it can be done with keyboard

performance
the keyboard is almost always faster than the mouse

performance
this is a radical concept i know but the mouse is slower than keyboard shortcuts

performance
i prefer the command line because i have a shell window open in the source anyway to run builds and tests and along with file name completion using the keyboard is faster than using the mouse for me

performance
the last fallback is to go the snail way - to mouse over to click on the red close window button but any mouse movements are slower than a keyboard shortcut

performance
since bit wise operations can be done very fast and division operations are relatively slow this type of modulo is much faster than doing a division

performance
a side effect of many division routines is the modulo - so in few cases should division actually be faster than modulo

performance
so in simple terms this should give you a feel for why division and hence modulo is slower computers still have to do long division in the same stepwise fashion tha you did in grade school

performance
if you compute modulo a power of two using bitwise and is simpler and generally faster than performing division

performance
so in simple terms this should give you a feel for why division and hence modulo is slower computers still have to do long division in the same stepwise fashion tha you did in grade school

usability
oo class diagram is more abstract and has more features than entity-relationship diagram

usability
for quadprog ipopt would be a much more powerful solver than nlopt

usability
you would be able to circumvent this by first running mvn clean install on magnicompcommon s pom.xml then on model pom.xml but this is much easier done by invoking maven directly on the root pom.xml

performance
my observation is that you get the webpage title using webchromeclient in lesser time than using webviewclient

usability
to sum up the webchromeclient is easier to use but the webviewclient allows you more configuration

usability
personally i m using sublimetext right now which i find easier than vim for searching and navigating the code but everyone has their taste

performance
using orientdb that is supposed ti be faster than neo4j for depth i m seeing a slow performance

performance
i found that orientdb is too slow at least much slower than neo4j even on relatively small 150k datasets when searching records by text pattern despite the presence of indices

usability
- you can also consider using webm which is a free alternative to h.264 and has better support on some platforms than fragmented mp4

usability
json jsonb fields support any json-encodable data type not just key value pairs but also tend to be faster and for jsonb more compact than hstore

usability
as a practical matter a cons is simpler than a list so you can get the value with a straight cdr rather than the conceptually more complex cadr the car of the cdr

usability
i think adhering to the dip principles makes it easier to comply with the ocp principles

performance
the solution from charliefl is approximately 100x faster than underscore.js depending on browser in this case and lodash being up to 2x faster than underscore.js

performance
if i remember correctly lodash argued they were faster than underscore.js because the use non-native functions for key operations

performance
lodash is another faster implementation of underscore.js that will provide a lot of utility methods for working wit arrays objects functions etc

performance
lodash is another faster implementation of underscore.js that will provide a lot of utility methods for working wit arrays objects functions etc

performance
i am stunned right now seeing a lodash performing 100-150 faster than underscore.js in even simple native functions such as array.every in chrome

usability
the easiest solution is to just replace underscore.js with lodash which has even more features than the latest underscore.js

performance
lodash is definitely not slower than underscore.js

memory
it is widely used to have a separated tag with the postfix -alpine in it to indicate that alpine linux is used which is a much smaller base-image than the debian image

performance
also note that in my code above manually calculating the euclidean distance is much faster then calling pdist

performance
also note that in my code above manually calculating the euclidean distance is much faster then calling pdist

memory
i reimplemented the mouse move press and release events for the inner widget in order to be able to move it inside its bigger parent with drag drop

memory
it ends up in a state of confusion...you basically cannot release the drag of the table it keeps getting bigger and smaller as you move your mouse - but you can never let go and release it to get the size you want

performance
i got a draggable object done with jquery ui and when i drag it it s way slower than i move my mouse

usability
other useful pieces would be jdbi for database access much simpler than hibernate or other full orms async-httpclient for doing calls to other web services

usability
for similar functionality that speaks pandas but has more flexible features you could use the facetgrid object from seaborn

usability
i also think working with seaborn is much easier using pandas dataframes and not numpy arrays

performance
construct java.util.calendar is comparative slower than java.util.date

performance
construct java.util.calendar is comparative slower than java.util.date

performance
in my case apc is 59 times faster than memcached

performance
my experience say that apc is nearly 7-8 times faster than memcached

performance
as you know apc is much more faster than memcached if we re fetching keys from a single server

memory
the big caveat here is that apc generally has less memory available for storage though. default being 32mb memcached s big adavantage is that while still fast it s distributed so if you have multiple servers running they could share this data

performance
a quick googling says that apc is 5 times faster than memcached

performance
as you know apc is much more faster than memcached if we re fetching keys from a single server

usability
memcached has more functionality but is intended for distributed environments while apc works on single servers only

usability
apc gives you some more functionality than memcached

performance
apc is faster on a single server - but memcached is distributed

performance
it s slower than apc but it s faster than memcached redis etc

performance
better use apc on apache server it will be much faster than memcached because you don t need to make a tcp ip call to connect to memcached

performance
memcached is faster than apc as zend_cache backend but you still need apc extension installed even in development mode to get a great speedup of your code

performance
memcached is in-memory too and a bit slower than apc

performance
apc access is a bit faster something like 5 times faster than memcached if i remember correctly as it s only local -- no network involved

usability
apc have less feature than memcached and is easly to use and optimize but this depends on your needs

performance
please don t mention memcached i am already using it but it is not suitable as direct replacement of apc because i am doing many apc_fetch calls because apc is much faster than memcached for this purpose

performance
memcached has more overhead since you have to use a tcp connection to access it versus just a function call for apc xcache shared objects

performance
memcached around 4-5 times slower than apc but run as a single process that can be touched everywhere in my environment

performance
please don t mention memcached i am already using it but it is not suitable as direct replacement of apc because i am doing many apc_fetch calls because apc is much faster than memcached for this purpose

performance
this is why rsa is much slower than dsa

performance
this is why rsa is much slower than dsa

performance
i have made some testing and it came out that rsa is lot slower than dsa

performance
i have made some testing and it came out that rsa is lot slower than dsa

performance
a dsa signature generation could be somewhat faster than a rsa signature generation maybe up to twice faster

usability
use dsa it tends to be more compact than rsa

memory
dsa has signature that is independent of key strength and is much smaller than rsa signature for equivalent security rsa 1024 1568 vs dsa 192

performance
however dsa verification expect verification calls to be 100x issue is about 10x slower than rsa verification

usability
cfstring has some slightly better functionality than nsstring but is a bit harder to use

memory
while alloca gives you automatic de-allocation on function exit the stack is usually a smaller resource than the malloc heap and if you exhaust the heap it gives you back null

memory
silex seems to have a bigger community than slim maybe it s just my point of view

performance
puremvc is generally much faster than robotlegs in terms of performance

memory
when i launch it with firefox or internet explorer the box gets immediately to a huge distance from the margin much bigger than the width of the screen and now i noticed that if i run it with stackoverflow s snippet function the box does not move

memory
anyway i just set the margin to a value a little bigger than the width of the image and overlap is eliminated only in the very specific case we want

memory
the first-child column has 10 pixels or whatever the margin size is greater content area width than it s siblings

memory
what i do not understand is why the size of the point and the text is not the same and why the margin can be bigger than the width of the figure

memory
but in general this wouldn t work because of the specified width is bigger than the real one and exceed it so there s no margin to auto it and center the content which found in div

memory
the box is never too small infact the margin of the adjacent div is bigger than the width of ul div

memory
the the main content div needs to have left margin larger than the width of your sidebar

memory
the reason why your website is x-scrollable on all devices is that you forgot to add to and the row inside it has 100 +15px left margin +15px right margin which is bigger than window width

memory
when the screen width becomes larger than 500px the contents of the media query are ignored and the margin becomes 20

memory
by giving the middle indicators div a left and right margin slightly larger than the width of the left and right button divs you allow it to float up between the two and take up as much space as possible

memory
the reason why your website is x-scrollable on all devices is that you forgot to add to and the row inside it has 100 +15px left margin +15px right margin which is bigger than window width

memory
aside of the left floated div i have another div article with a margin a little bigger than the width of the floating div just usual for a two column layout

memory
the first-child column has 10 pixels or whatever the margin size is greater content area width than it s siblings

performance
wel i have used both orika and dozer i can say orika is at least 10 times faster than dozer in my project after the replacement

performance
orika is way faster than dozer and quite close to manual mapping

performance
i tested orika and it was a lot faster but was slower than dozer with small collections

performance
orika is way faster than dozer and quite close to manual mapping

usability
it fills the gap between scalatra and lift more powerful than scalatra and easier to use than lift

performance
this generally uses a hash algorithm that is much faster than md5

usability
if the hash function is more complex and cryptographically strong md5 or sha1 then it is theoretically not possible

reliability
all hash functions have that problem but some are more robust than md5

usability
if the hash function is more complex and cryptographically strong md5 or sha1 then it is theoretically not possible

reliability
sha-256 uses 64 characters in the database but with an index on the column that isn t a problem and it is a proven hash and more reliable than md5 and sha-1

usability
the hash cake generates are more complex than md5

security
finally sha1 hash are safer than md5 i tell you that because you used the md5 tag in your post

memory
any hash function like md5 sha1 sha256 etc obviously cannot be 100 unique - because they have a fixed length and due to the there must necessarily be non-unique results for input content that is larger than the hash

usability
the wrapper uses these in such a way that even the md5 implementation is significantly more secure than a simple hash

performance
also the hash algorithm itself is much slower than sha1 md5 sha1 md5 are made for speed - not a useful property when storing passwords

usability
the wrapper uses these in such a way that even the md5 implementation is significantly more secure than a simple hash

performance
in that case some hash functions are somewhat faster than other md5 being one of the fast functions but md4 is faster and it is simple enough that its code can be included in any application without much hassle

performance
the fact that bcrypt produces hash slower than md5 because of security reasons is also clear for me

memory
the difference between crc32 and md5 is that md5 generates a larger hash that s harder to predict

usability
of course any hash algorithm is going to have some chance of collision but you have better options than md5 that would still satisfy the 1024-byte limit

usability
i would like to apply a hash code solution on my webpage which is more compact than md5 and sha-1 because i want to use them as keys in a json hash table

memory
hashing is one way you can prove this to yourself by taking an md5 or shasum of a large file since the file s size is larger than the hash output by pigeonhole principle hash can t be restored.

usability
the hash cake generates are more complex than md5

memory
it s like complaining that a sha256 hash is bigger than an md5 hash - yep it is but only one of them might slow the attacker down for a while

usability
of course you can only debugging the code to see the generated sql but it s easier with a profiling tool and you ll see how long time the query takes

usability
the reason is that maybe like in my case the xcode bot was attempting to archive with the development profiling and development profiling is much easier to debugging than 4f96f173-7ebe-4892-b283-52489de2f409

usability
it is working only for simple .php files but wordpress is more complex and after long period of loading it show elgg nothing found site loaded

performance
again we see the pattern of it getting faster during the first two runs after which it settles somewhere in between slightly faster than yarv and the other jruby and slightly slower than rubinius

performance
using varchar is less efficient than using tinyint like aju john suggested in his comment but unless i m dealing with a really performance-critical or a huge table - i find it easier to deal with

performance
marcus yes memmove is faster than strcpy and faster than python but why

usability
why don t you do a simple test that tries to read and display an image in a jlabel first since using a jtable is more complicated than using a jlabel

usability
note that the png format is much more complex than bmp since it allows compression etc

performance
jpg png is slower to draw than a bmp

memory
rebuild a new png format in-memory data which is much more smaller than current bmp data and send the new png format data by socket to remote server

usability
note that the png format is much more complex than bmp since it allows compression etc

memory
not only do png files have natural support for transparency they are also smaller than bmp files

performance
i have a sample wpf app here and wondering why bmp is loading faster than png

usability
i prefer yourkit as i find it easier than visualvm

usability
in its stead you can use isotope - which does filtering a lot easier than masonry

usability
i got it to work by using a child process from pexpect which is much more flexible than telnetlib

usability
i got it to work by using a child process from pexpect which is much more flexible than telnetlib

usability
for load testing jmeter is better option but you have quite enough funding then go for loadrunner neoload rational performance tester and for cloud try blazemeter

usability
my only problem is that is seems that using uicollectionview is a better approach and i have read some seemingly off-hand comments about icarousel being a poor approach

usability
compare the very active django tag on stack overflow with that of pylons or turbogears though and i d argue getting started is simply easier with django irrespective of anything to do with code

memory
the problem is that with the code below the jlayeredpane always expands to fit the size of the jscrollpane and in the event that the jscrollpane is smaller than the jlayeredpane it does not provide the scrolling ability

reliability
adb is more reliable since you get the feedback immediately unlike monkeyrunner which does not provide reliable exceptions in case of any failure in triggering the event

usability
grouping has looser constraints than sorting so in theory it could be marginally faster than sorting but unless you re dealing with a lot of data you re unlikely to see a speed difference

performance
the reason being that sorting less elements which the grouping generally produces is going to be faster than sorting all input documents

performance
of course ordering could be forced obj.gettype .tostring and using lexical order but since a strict order is not necessary only grouping i was wondering if there s a more efficient way than sorting

usability
instead knowing that we want to grouping by these columns we can make the application code to do so simpler by sorting by these fields

usability
if you will have only yours commits on your branch issue is much simpler you can do squash those git squash

usability
vba is in fact a superset of vb6 not a subset -- vba has more functionality built in than vb6 itself

performance
if you are on linux and have chosen blas and lapack from a repo it is very likely that they are much slower than openblas

performance
evidently though mod-alias can be somewhat faster than mod-rewrite all other things being equal of course

memory
if division result is larger than 1 push the current transformer to the results array and subtract the current wattage from the total wattage

performance
spdy is a more efficient protocol than http

performance
spdy is a more efficient protocol than http

usability
consider using force.com canvas now ga which is an added-value iframe with more security and easier integration with salesforce apis than raw iframes - see

performance
but heapsort is assumed to be on average somewhat slower than standard in-place quicksort

usability
yum makes it easier to maintain groups of machines without having to manually update each one using rpm

memory
both commands works in the same way only difference is yum list installed output maybe bigger than rpm -qa because yum will show package dependencies also in its output

memory
here is a solution which encapsulates the call to malloc allocates a bigger buffer for alignment purpose and stores the original allocated address just before the aligned buffer for a later call to free

memory
most likely malloc allocates more memory and puts so-called guard values that happen to contain null bytes or it puts some metadata to be used by free later and this metadata happens to contain a null byte right at that position

memory
one interesting experiment you can try is to try and malloc more memory after you free d that pointer

memory
presumably the mac malloc aligns to bigger boundaries and so it s spotting the pointer you re passing to free can t be correct since it has the wrong alignment

usability
malloc is much easier to implement if there is no free

security
in addition to the previous answers the strncpy char pointer which seems unsafe for my opinion and the malloc which is safer but you need to remember to free it outside of the function and its inconsistent with the hierarchy of the program you can do the following

memory
here is a solution which encapsulates the call to malloc allocates a bigger buffer for alignment purpose and stores the original allocated address just before the aligned buffer for a later call to free

memory
presumably the mac malloc aligns to bigger boundaries and so it s spotting the pointer you re passing to free can t be correct since it has the wrong alignment

usability
i understand that strtol and strtof are preferred to atoi atof since the former detect errors and also strtol is much more flexible than atoi when it comes to non-base-10

reliability
use strtol it does better error reporting than atoi

usability
i understand that strtol and strtof are preferred to atoi atof since the former detect errors and also strtol is much more flexible than atoi when it comes to non-base-10

usability
i start off calling gets to fill the buffer then using strtol to convert the human-readable text in buffer to an actual computer int value - note that strtol is more powerful than atoi and uses long int instead of int as its declared type

reliability
i would recommend strtol which provides better error handling than atoi or sscanf

usability
besides strtol is a better option than atoi as strtol can handle failures better

usability
matrix multiplication is the easier one there are several matrix implementations with a multiplying method in packages org.apache.spark.mllib.linalg and org.apache.spark.mllib.linalg.distributed

usability
implementing multiplication is easier if you remember an shl operation performs the same operation as multiplying the specified operand by two

performance
mathematically left shifting is the same as multiplying a number by a power of 2 but as the operation is done only by shifting it is much faster than doing multiplication

usability
multiplying first is probably simpler than using floating point if you only want an integer result and if you know that the multiplication will never overflow

usability
multiplication is the easier of the tasks just remember to multiplying each block of one number with the other and carry the zeros

usability
multiplication is slightly more complex as it needs an integer multiplying followed by a scale back such as 0.72 2 becomes 72 200 becomes 14400 becomes 144 scaleback becomes 1.44

usability
my friend used beyondcompare however i am more comfortable with winmerge

performance
just to goof off a version using boost string_ref is much faster still due the reduced allocator

performance
just to goof off a version using boost string_ref is much faster still due the reduced allocator

performance
i d like to use mediacodec to encode the data coming from the camera reason it s more low-level so hopefully faster than using mediarecorder

usability
android 5.0 api 21 allows surface input to mediarecorder which is often much more convenient than mediacodec

usability
if your output is going to be similar to your input with small changes then the xslt solution is often a lot simpler than the xquery solution

performance
having data structures that start on 4 byte word alignment on cpus with 4 byte buses and processors is far more efficient when moving data around memory and between ram and the cpu

memory
in general when used on single processors single core machine this should be sufficient assuming int size same or smaller than cpu word like 32bit int on 32bit cpu

usability
i find using system monitor that consistently 100 of one cpu is used when i run the program directly in terminal whereas when i run it in bash in a loop a maximum of 60 of cpu usage is recorded and seems to be linked to the longer completion time although the average cpu usage is higher over the 4 processors

performance
the difference you notice is very small but i think the multi-thread processors is spending more time because the concurrency for the cpu resources between the threads

performance
the cpu is indeed slower on sparc 1.2ghz and as answered by one of the sun s engineers t2 is usualy 3 times slower for single-threaded application than modern intel processors

usability
ant is much more powerful than maven in many respects but maven excels in dependency management and ease of deployment

usability
ant is simpler and older and the default just called a java project maven is newer more powerful and flexible

usability
i think updating dependencies with maven is pretty easier than dealing with ant but of course you could select the other way if you feel more conifrtable

usability
ant is much more powerful than maven in many respects but maven excels in dependency management and ease of deployment

usability
does this make ant more complex than maven

performance
also note that while maven is no slower than ant for multi-module projects of this sort importing your maven project into an ide will generally result in far faster builds than maven can perform itself

memory
the size of maven jar is bigger then ant jar i don t know why help me please

usability
i know maven is more powerful than ant

usability
so i suggest you build a p2 repository can be done in ant but seems simpler in maven tycho and split the projects to several repositories

reliability
troubleshooting the build maven is less reliable than ant especially the non-core plugins

memory
the size of maven jar is bigger then ant jar i don t know why help me please

usability
you can take a look on gradle which for me could provide more freedom than maven but is easier to use than ant

usability
maven usage is lower compared to ant but just how much lower is not really known

usability
all of racket s languages can interoperate so your language of choice is up to you though the rnrs languages tend to go unused in the racket community #lang racket is much more useful for writing programs than any of the scheme implementations but they can be useful if you want to write programs that run on different scheme implementations

usability
kerberos could be considered as a better option than ntlm

performance
i understand that kerberos has better performance than ntlm

performance
kerberos is complex to set up and even though it generally is considered faster than ntlm this is only true when you reach a certain limit of simultanious users on your site

performance
for a low traffic site the huge tokens that kerberos send across the network actually makes it slower than ntlm

performance
ram is a lot faster than disk so reads and writes are temporarily stored until the data is requested by the code or the disk is able to receive it

performance
if too much memory is consumed it might swap to disk which is slower than ram

performance
run the following to sort the data on disk this is slower than pulling it into ram sorting and then writing to disk

performance
if lob-storage isn t in ram at the time of a query execution then we need to read it from a disk which is of course much slower than from ram

memory
in future these lists may be read from disk and larger than available ram

performance
remember the tuples are saved into the disk which is vastly slower to access than things in ram

performance
ssd disk are good but they are still much slower than ram

performance
however be aware of this to cache pixels to disk is several orders of magnitude slower than using ram

performance
buy as much memory as you can afford ram is alway faster than io from disk

performance
saving information to a variable and therefore to ram is always faster than direct to disk

performance
this is slow because your hard disk is significantly slower than ram and at 7gb there will be a lot of data being read from your hard disk put into ram then moved back to your page file the file on disk your operating system uses to store data that has been copied out of ram

performance
disk access is much slower than ram

performance
make sure you have enough ram so that your data set fits with ram atleast your index should fit inside the ram coz each time a data fetched from disk is 10 times slower than ram

performance
as disk is 1000s of times slower than ram this problem can grind the machine down to a practical halt

performance
since your disk even if it s an ssd is several orders of magnitude slower than ram the systems gets unresponsive

performance
the initial read has to access the disk which is a lot slower than accessing ram

performance
disk files are of course an order of magnitude slower than ram and thrashing your virtual memory system could actually be worse than that depending on your access patterns

performance
if the worker processes do other things than just calulations read from or write to disk they will have to wait a lot since a disk is a lot slower than ram

performance
there exist battery-backed packages of ram modules which can act as an ultra-fast hdd substitute but if they attach via sata scsi or other typical disk interface the still are slower than system ram

performance
when the data is in memory - you can do anything much faster on it since disk io is extremely slower then ram so sorting it and reading it multiple times is expected to be much slower then manipulating the data on memory

performance
disk i o is about 100 000 times slower than ram

performance
but you should consider that disk io is way slower than ram

performance
pros of objects faster disk read is slower than ram lesser dependencies of the system s state

performance
it won t do anything to change the fact that disk io is orders of magnitude slower than ram

performance
ram is much faster then disk io

performance
query speed is mainly limited by disk i o speed which is at least 1000 times slower than cpu ram speed

usability
i m sure there are other holes like that too - but the code above will work on any system which supports paging and where disk access is much more expensive than ram access

performance
the ram is much faster than the hard disk

performance
but you should consider that disk io is way slower than ram

performance
using multiprocessing is probably not going to speed up reading data from disk since disk access is much slower than ram access or calculations

memory
the os heap uses the cpu s virtual memory hardware and is free from fragmentation issues and can even effectively use the disk s swap space allowing you to allocate more memory than available ram

usability
using multiprocessing is probably not going to speed up reading data from disk since disk access is much slower than ram access or calculations

memory
it uses swap space on disk to allow for processes much larger than ram

performance
just wanted to weigh in my two cents what serialworm and thephpdeveloper said share the fact that memory ram is much faster than any disk io bound operation you come up with

performance
another option is to spend a bit of cash on a 15000 rpm disk or a ssd solid state disk although that ll be slower than a ram disk

usability
and ram access is much more fast than disk access

memory
so while the writes my be sequential on disk for datasets larger than ram these random reads will quickly become the bottle neck

performance
remember disk is 1000s of times slower than ram

performance
caching and buffering are quite important since disk are just so much slower than ram and ram is much slower than the cpu

performance
ram is much faster then disk io

performance
changing it will require a reboot. that will slow things down a bit as the swap file on disk is much slower than ram

usability
and ram access is much more fast than disk access

performance
only one disk read - since the disk is much slower then ram -

performance
the idea is to get the library and application loaded from ram into ram which is much faster than loading from disk

performance
only one disk read - since the disk is much slower then ram -

usability
however if this is indeed the case - and the data does not fit ram and you cannot use map-reduce i suspect sorting and iterating - though will be o nlogn will be more efficient using external sort - because the number of disk accesses will be minimized and disk access is much slower then ram access

performance
because hard disk have a much slower memory than ram virtual private server performance may slow down considerably

performance
in other words the operating system is using some of your hard disk space to satisfy your 13 mb allocation request at great expense of speed since the hard disk is much much slower than ram

performance
which will lead to performance issue all programs will be work slower because read info from disk is slower than from ram

performance
accessing the main memory ram is much faster than reading values from the hard disk

performance
memory is a bottleneck to performance ram runs slower than the cpu and if you re paging to disk than it s really slow

performance
so even ignoring practical considerations like disk is slower than ram it will be slower

performance
i understand that ram is typically thousands of times faster than disk but i o speed is not the only code running

performance
but becuase reading from ram is usually faster than from other kind of memory storage divice os copy the program from disk on ram and start executing program from there

performance
disk io will be slower than ram

memory
edit true the file on disk is not larger than ram but the in-memory representation can easily become much larger than available ram

performance
that means that without caching a hit against disk will be 200 times slower than accessing ram

performance
as disk is 1000s of times slower than ram as the memory usage increases your machine grinds more and more closer to a halt

performance
when the data is in memory - you can do anything much faster on it since disk io is extremely slower then ram so sorting it and reading it multiple times is expected to be much slower then manipulating the data on memory

memory
we all know that the access to ram memory is faster than access to hard disk

performance
once you re out of ram and the system starts swapping - disk access is thousands times slower than ram so any potential benefits of 64-bit code are flying out of window

performance
i would say that probably yes as long as we have enough of ram which is faster that virtual memory in case we need to access something from the disk which is extremely slow... but also i know that some applications just require having paging

performance
since using ram is faster than using disk zram allows linux to make more use of ram when swapping paging is required especially on older computers with less ram installed

performance
as you run queries it has to fetch data from disk which is much slower than ram

performance
obviously reading a block from cache is much more efficient than reading it off the disk since ram is much faster than disk

performance
for the stand of file operations writing to memory ram is always faster than writing to the file on the disk directly

performance
the first load involves reading alot from the hard disk which is slow even ssd is slower than ram subsequent loads should be faster though 3 seconds on the ssd seem to be odd

performance
that s basically possible but it would take hours as hard disk access is so much slower than accessing ram caches

performance
ram is 100 thousand times faster than disk for database access from

performance
as disk i o is orders of magnitude slower than ram i o this can cause a very significant difference in query execution times

performance
i think it is because the disk is slower than ram

usability
however if this is indeed the case - and the data does not fit ram and you cannot use map-reduce i suspect sorting and iterating - though will be o nlogn will be more efficient using external sort - because the number of disk accesses will be minimized and disk access is much slower then ram access

performance
ram is much faster than disk

performance
disk is 100x slower than ram

performance
ram is much faster than disk

performance
just wanted to weigh in my two cents what serialworm and thephpdeveloper said share the fact that memory ram is much faster than any disk io bound operation you come up with

performance
pros of objects faster disk read is slower than ram lesser dependencies of the system s state

performance
changing it will require a reboot. that will slow things down a bit as the swap file on disk is much slower than ram

memory
in this case the latter is likely to cause trouble because the insertion of a name hits a random node in the tree i.e the name insertion doesn t follow a pattern and your ram is smaller than the index chances are high that the destination must be fetched from disk

performance
disk io - even ssd - is many orders of magnitude slower than the ram that the hashing is going though

performance
no trivial support for cache accessing ram is faster than accessing disk

memory
edit true the file on disk is not larger than ram but the in-memory representation can easily become much larger than available ram

performance
which will lead to performance issue all programs will be work slower because read info from disk is slower than from ram

performance
reloading pages data or program code from disk which is much slower does not usually happen very often as long as the program is actually running and as long as the machine is not desperately low on ram

usability
also keep in mind that once ram is exhausted your program will start running in virtual memory on disk which will probably cause far more disk i o activity than the program itself so if you re concerned about disk i o your best bet is probably to make sure that the batch of data you re working on in memory doesn t get much greater than available ram

performance
this is relatively slow since reading from the hard disk is slower than reading from ram

memory
it is needed for a lookup of repetitions in disk files much larger than available ram

performance
a disk seek takes about 10 000 000 nanoseconds of course some disk are faster but the best of them are still thousands of times slower than ram

performance
ram is always faster than disk

memory
so even if your ram is much smaller than your disk you could assume you can read data that s already in ram 90 of the time or more

performance
anyway you will have a huge performance loss due to the fact that your disk is way slower than your ram

performance
reading audio files from ram is much faster than reading audio files from hard disk

usability
disk access is much slower than ram

memory
this is well within disk space but far larger than ram

performance
because disk access is orders of magnitude slower than ram access

performance
1 yes there is a obvious benefit reading from ram is faster than reading from disk

memory
so even if your ram is much smaller than your disk you could assume you can read data that s already in ram 90 of the time or more

memory
the table on disk is bigger than your ram

performance
ram is a lot faster than disk

performance
this is slow because your hard disk is significantly slower than ram and at 7gb there will be a lot of data being read from your hard disk put into ram then moved back to your page file the file on disk your operating system uses to store data that has been copied out of ram

performance
as sven marnach wrote in the comments your problem is most likely i o bound since disk access is orders of magnitude slower than ram access

memory
this approach will radically reduce heap space usage - disk space is cheaper then ram too

memory
alternatively you can use an ssd with file storage in varnish to reduce disk io bottlenecks when using an object cache larger than available ram

performance
loosely speaking ram is 1000 or more times faster than disk and cpu is faster still

performance
disk even ssd are orders of magnitude slower than ram

performance
for this reason it seemed natural to me to initially load the file into memory and interpret it later at my leisure since reading from ram is supposed to be much faster than from disk

performance
as you run queries it has to fetch data from disk which is much slower than ram

performance
there are libraries that allow on-disk data structures comes to mind and another one whose name i can t recall at the moment but disk accesses are orders of magnitude slower than ram

performance
ram is always faster than disk

performance
obviously reading a block from cache is much more efficient than reading it off the disk since ram is much faster than disk

memory
disk is bigger than ram

memory
this approach will radically reduce heap space usage - disk space is cheaper then ram too

memory
data in ram can take a lot more space than on disk

usability
i m sure there are other holes like that too - but the code above will work on any system which supports paging and where disk access is much more expensive than ram access

performance
so my question is how to move this database into ram where i can access it via sqlite3_open or if my idea is bullshit and leaving the database on disk is faster than moving it into ram via mapping

performance
or if there is too much intermediate output to be shuffled your job will become slow as you will need disk based shuffle in such a case which will be slower than ram based shuffle

performance
anyway you will have a huge performance loss due to the fact that your disk is way slower than your ram

usability
research showed me that mantis is simpler to use over bugzilla so i decided to use mantis but have no idea how to install it.can anyone please tell me what are the steps you need to take in order to install mantis bug tracking system in a small company to track website mobile portal bugs

performance
i m working in a spring mvc project and i want to use a template engine i originally choose apache velocity because a slideshare presentation that says it was two times faster than thymeleaf page 41 and since i m working with big tables i need to use a fast template engine does apache velocity supports html5 if not is there other template engine that supports html5 that is not thymeleaf

performance
these can be compared to multiplying by 2 x left-shift or divinding by 2 x right-shift but it should be noted that a binary shift is much faster than a division operation

usability
but determining the digit and the carry by division is much more concise and for the larger factors also much more efficient when multiplying a digit by 100 the result is on average 450 requiring 45 subtractions but two divisions are sufficient for all factors

performance
i presume that you know that using a division is a lot slower than multiplying by decimal number 5 is always slower than 0.2

performance
according to agner s instruction tables a single fp division is slower than a single reciprocal op and a single multiplying op

performance
sure that s probably compiled or jit d away but you should avoid division in performance critical code it s far slower than multiplying

performance
perhaps it s the case that division is much more accurate than reciprocal plus multiplying

performance
note that i ve incorporated dshin s comment that multiplying is faster than division however the performance improvement is about 90 removing the binary search 10 multiplication vs

performance
note that some people feel that ng-show is a little faster than ng-switch and ng-if for file-based templates

performance
if you know the lengths of the strings memmove is a sensible choice - and nominally faster than strncpy because it does not have to check for nulls as it goes

performance
i have noticed that content extraction is faster in itext but searching words using regex in the content extracted by itext takes longer time than pdfbox

memory
the motivation is that font size 12 under kde seems to be much larger than under gnome

performance
enthought-dev is chaco faster than matplotlib

performance
why is enumerate slower than xrange + lst i

performance
if you measure properly you ll see there s essentially no difference enumerate is microscopically faster than xrange in this example but well within noise

performance
if you measure properly you ll see there s essentially no difference enumerate is microscopically faster than xrange in this example but well within noise

performance
i ve only done one experiment with angular material myself and i wasn t experiencing any real performance issues at the time but i did read some people writing about it being slower than plain ionic

performance
perforce is soooo much faster than svn because all the check-outs are stored on the server so it doesn t have to check every file on an update

usability
perforce does have support for many other oses but our non-windows devs feel more comfortable with svn too

usability
in free and turbo pascal file handling is much more easier than in delphi in pascal we have assign instead of assignfile and close instead of closefile

usability
i want to use accelerometer but i learnt that gyroscope is better option to calculate the accelerometer

performance
so after googling this i found that using gyroscope sensor is more accurate than the accelerometer

performance
also i have tried the accelerometer sensor and it worked but i m asking to check whether the gyroscope is more accurate to this function or the accelerometer

usability
you can also user a stemming which is a simpler version of lemmatization

usability
you can also user a stemming which is a simpler version of lemmatization

memory
it s probably overkill for what you need but sproutcore is an mvc framework and it doesn t look any more heavyweight than javascriptmvc or trimpath s junction

performance
i have worked pretty heavily with both flavors of the gwt extjs libraries though i ve spent more time with gxt recently

performance
floating-point divide is faster than integer fewer bits to divide assuming your cpu has floating-point unit

performance
historically floating-point could be much slower than integer

performance
but another added benefit of this approach is that it could make your program run faster since fixed-point integer arithmetic is much faster than floating-point arithmetic

performance
integer math is often much faster than floating-point so such a function could be a major performance win

usability
floating-point arithmetics is by far more complicated than integer arithmetics

performance
floating-point division is typically faster than integer division on the cpu

performance
on somewhat limited processors like those in high-end cell phones floating-point may be somewhat slower than integer but it s generally within an order of magnitude or better so long as there is hardware floating-point available

performance
there are lots of cpu gpu combinations where a 32b integer multiply is faster than a 32b floating-point multiply on cpu and vice-versa on gpu

memory
floating-point types have a larger range than the integer types so

performance
historically floating-point could be much slower than integer arithmetic

performance
they take up more space and floating-point math is slower than integer math

performance
which uses all integer arithmetic is usually faster than its floating-point equivalent likely significantly faster in the case of a floating-point type equivalent to t-sql s decimal type

performance
which uses all integer arithmetic is usually faster than its floating-point equivalent likely significantly faster in the case of a floating-point type equivalent to t-sql s decimal type

performance
floating-point division is typically faster than integer division on the cpu

performance
today s floating-point units are pretty fast and may actually divide faster than an integer unit

performance
depending on context floating-point code may be as fast as or faster than integer code or it may be four times slower

performance
floating-point may be somewhat slower than integer but it s generally

performance
as a rule of thumb floating-point is about 2x slower than integer on

performance
but another added benefit of this approach is that it could make your program run faster since fixed-point integer arithmetic is much faster than floating-point arithmetic

performance
it s even possible that you could implement pong using only integer arithmetic which is likely to be faster than floating-point -- but the difference is unlikely to be critical

performance
generally integer math is faster than floating-point math

performance
they take up more space and floating-point math is slower than integer math

usability
but integer arithmetic arguably is inherently simpler than floating-point

memory
nsdecimalnumber and the floating-point types may be able to store bigger numbers than the integer types though with decreasing precision

usability
consider taking a look at splinter which is a simpler webdriver api than selenium

usability
splinter simpler than selenium

usability
consider taking a look at splinter which is a simpler webdriver api than selenium

usability
splinter makes it easier to use selenium plus

usability
jpgraph has far more capabilities than phpgraphlib

memory
but a large period prng takes up more memory for maintaining the internal state and also takes more time for generating a random number due to complex transitions and post processing

usability
you might have even noticed the fgetc version is simpler than the fread version

usability
you might have even noticed the fgetc version is simpler than the fread version

performance
the fgetc loop variant was consistently 45x slower than the fread loop

performance
doing things like 1000 successive fgetc is much slower than doing one single fread of 1000 bytes

usability
livescript is coco but much more compatible with coffeescript more functional and more feature rich

usability
ubuntu 12.04 ships with the ffmpeg fork libav in version 0.8 which is more compatible with ffmpeg 1.0+ or even later ffmpeg versions iirc

performance
post explaining why spi is faster than i2c

usability
communication via i2c is more complex that with uart or spi solution

performance
i have done some research about them and it seems to be that spi is faster than i2c but the last one ensures more control and error detection over the first one

performance
on top of that the i2c bus is slower than spi because there are control data exchanged

performance
i wanted to know that what makes spi faster than i2c

usability
i know i2c is more complex slow than spi uart etc. but it s a constrain

performance
on top of that the i2c bus is slower than spi because there are control data exchanged

usability
first bit banging i2c is way more complicated than bit banging spi

usability
i know i2c is more complex slow than spi uart etc. but it s a constrain

usability
nunit is more popular because it was there first therefore more articles about it on the web and better tooling and because most programmers don t care about or need the advanced features that mbunit offers

usability
from what i have read on here i here that nunit is more popular over mbunit

memory
however the imageview has a smaller width than the textview

memory
i have an imageview that is bigger than a textview and i want to center the textview on top of the imageview both vertically and horizontally

memory
assuming the imageview is always bigger than the textview it ll drive the parent height

memory
this should work as long as the imageview is larger than the textview in all dimensions

memory
add layout_weight properties to sub views as well.assign 3 to imaveview and 1 for textview now imageview always will be bigger than textview 3times and textview can not invade imagevies s space

memory
i also tried to do spacing from imageview to textview but then if the textview is smaller than the imageview the spacing will be wrong again

memory
assuming the imageview is always bigger than the textview it ll drive the parent height

memory
in the image the square represents a fixed size imageview the rectangle is a textview which can 1 line smaller height than imageview or multiline height is larger than imageview

memory
however the imageview has a smaller width than the textview

performance
mysql s version is apparently marginally faster than postgresql but lacks some of the more advanced spatial features therefore it s pretty much limited to finding records that match a certain range of coordinates

security
i d have said that postgresql is more security aware than mysql supporting roles more authentication methods ... but that the database itself has generally a very limited impact on the security of an application

performance
postgresql is already slower than mysql up to a certain point it is actually faster when you have a ridiculously large database

reliability
there is also postgresql its a bit more robust than mysql and is free just the same

performance
according to my own experience postgresql run much faster than mysql especially handling big tables 1.4 gb lineitem table in my case

usability
postgresql supports recursive queries in the form of recursive common table expressions which make querying heirarchical data easier than in mysql and also give better performance

usability
explain in postgresql is way more useful than in mysql

usability
not only does postgresql have a far more flexible indexing than mysql but the table approaches are very different also meaning the appropriate indexing strategies are as different as the tactics are

performance
for these ultra simple queries postgresql can be slower than mysql - postgresql has richer planner that works better on more complex queries but on trivial queries is slower

usability
triggers in postgresql have a syntax a bit more complex than mysql because they execute procedures as the action

performance
postgresql is already slower than mysql up to a certain point it is actually faster when you have a ridiculously large database

usability
postgresql has better support but the support by mysql depends on the used storage engine

memory
while mysql has a larger user base postgresql is gaining more an more popularity ever since implementing several crucial features that were missing in earlier versions

usability
it s a shame postgresql isn t more popular than mysql since it supports exactly this feature out-of-the-box you d only have to share one sequence object between tables.

memory
b use indexes - postgresql has bigger repertoar of indexes then mysql so use it - there are gist gin indexes

security
traditionally postgresql has had fewer security issues than mysql but they are both doing very well on that

performance
postgresql gets much better performance and this is coming from a former mysql partisan

performance
i did some benchmarking 3 years ago may be stale... which showed that on large datasets basically postgresql fulltext is 10-100x faster than mysql and xapian 10-100x faster than postgresql but not integrated

memory
b use indexes - postgresql has bigger repertoar of indexes then mysql so use it - there are gist gin indexes

usability
in your case postgresql may be a better option than mysql because your query is going to likely be against secondary indexes

performance
i did a simple performance test and i noticed postgresql is slower than mysql

performance
unfortunately in postgresql select count is often slower than mysql to which it often get s compared to

usability
postgresql specifically has gotten easier to manage while mysql has lost some of the simplicity that gave it an advantage without picking up enough features that really matter

security
if i were able to upgrade the server s versioning of mysql to 5.5 would innodb be a safer bet than postgresql

performance
some recent tests we did showed that postgresql does perform faster than mysql and we believe the table partitioning feature in postgresql will be very important with a table in our database we foresee to grow into 100 million rows and more in production

performance
mysql run 4x faster than postgresql

usability
i totally understand the error and assume that the mysql implementation is less sql conform than the postgresql implementation

usability
while postgresql is less popular than mysql most of the serious web hosting supports it

usability
postgresql is far more powerful and scalable and doesn t have mysql s silly limitations and gotchas

reliability
i hear postgresql is more robust and doesn t crash like mysql does in these situations

performance
postgresql is faster than mysql s innodb

usability
is postgresql a better option than mysql for partitioning tables by date

usability
though mysql is more popular than postgresql but instagram is using postgresql maybe due to these reasons

usability
i found that postgresql 9.3 has better capabilities for json than the mysql versions i am using

usability
mysql is easier than postgresql but it doesn t really matter either way

performance
do you find rails with postgresql is slower than mysql knowing that it produce more query on the background

performance
with django it is easy to use postgresql instead of mysql so i tried it with the same query and same data in db postgresql is much faster that mysql x10 more faster while using inner join analyse shows it uses indexes unlike mysql

security
postgresql supports some more security features than mysql for example integration with gssapi or kerberos for logins last i checked mysql didn t have these

performance
in my personal openion mysql is slower than postgresql and mongo db

memory
while mysql has a larger user base postgresql is gaining more an more popularity ever since implementing several crucial features that were missing in earlier versions

usability
i totally understand the error and assume that the mysql implementation is less sql conform than the postgresql implementation

usability
i suggest postgresql it s more capable has more features and better support for complex queries and datatypes than mysql and has a lot of tuning options

performance
i wonder why postgresql s single insert statement is completely faster than mysql s when autocommit is turned on

reliability
as for reliability i think that postgresql is more reliable especially when compared to mysql using myisam - innodb is a lot better here

performance
in most regards postgresql is slower than mysql especially when it comes to fine tuning in the end

usability
i cannot propose any db not knowing your specific needs but if you want to use a free software which excludes oracle and you re not already experienced with mysql you should try postgresql which is more powerful than mysql

performance
as i said postgresql is far superior and i hate mucking with mysql s bizarre bugs and i think that overall postgresql performance is probably better than mysql for any even slightly complicated query

performance
i ve found that postgresql is in my expirience is slower as mysql

performance
mysql i am told can be optimized to do faster reads than postgresql but both are pretty ridiculously fast in terms of # transactions sec they support and it doesn t sound like that s your problem

usability
why postgresql is more capable than others mysql etc. on django

usability
the only reason i was considering postgresql was that some research suggested postgresql has much better support for changing schemas along the way than mysql

performance
may be postgresql takes less time than mysql

usability
i saw he used checkbox which to seems much more useful than button since you can take multiple objects out at a time

memory
what i d like to do is make the button images slightly larger than the checkbox and have the text checkbox and both button on the same line

memory
in both cases plus minus same except in case where is the small checkbox the button is bigger on width maybe it is related with space for checkbox

performance
you can have a look at this speed performance benchmark from fftw which suggests that gsl is about 3-4 times slower than fftw 3

usability
so in my practice using war app easier than jar to manage and re-configure

memory
if window height is bigger then window width the we have a portrait or in any other case we have a landscape orientation

memory
when the uitableviewcontroller view width is made bigger 500px+ the cell adopts the correct height however label 1 becomes too big for its content spanning 1 line of text over 2 lines and label 2 becomes squashed spanning 2 lines of text into 1 line

memory
in this case if i want to have a fixed width while keeping ratio i just set height to a very large number so that the resizer will actually ignore it since the ratio of real height to desired height is far smaller than the ratio of real width and desired width

memory
alternately you could make use of background-size contain it would preserve the aspect ratio but it will leave white space on the left and right if the width is larger or on the top and bottom if the height is larger

memory
now if you get these confused and use the height for the width and the height is larger than the width this is going to blow up

memory
landscape mode is when the window width is larger than window height

memory
if the height is bigger smaller than width don t draw or set visibility false

memory
in other way if width is larger than height it should be width 100 height auto

memory
other approaches like making the element s width larger than height or using scale would result in an elliptical arc and it would also require tweaking to positioning attributes when height or width changes

memory
height is usually larger than width

memory
when resizing the image if the width side is larger than the height resize the image so that the image height is the div s height and hide the width overflow after centering

memory
i m then attempting to use jquery to run a check on whether or not the images height is bigger than it s width visa versa or they are equal

memory
â inversement if the width is bigger than the height

memory
also if the image width or height is smaller than displaywidth scale you might want to cap it to be image width instead

memory
how would i write a media query for when the device height is larger than device width or vice-versa

memory
landscape mode is when the window width is larger than window height

memory
to answer your question monopsace characters have often a height two times bigger than their width

memory
when i resize my browser window and the div s width becomes smaller the elements inside the div jump below expanding the height

memory
when i resize a borderless form to a small width and height it won t get smaller than width 132 height 38

memory
hi i m working on an application that will be loading images and i m looking to scale each image to it s largest possible size for instance if the image is a landscape image if width is larger than height i would like to stretch the width to fill the width of the phone and scale height to keep it s aspect ratio

memory
if i set the frame of the tableviewincell to a width larger than the height of the containing cell then it goes heywire

memory
if i have a writeablebitmap version of my image and either the height or width whichever is larger is scaled to be either the screen height or width then how might i over lay that image on top of another image that is the page size to make the image become a full screen image

memory
you would then need your height to be 2 times bigger than your width

memory
using media screen and orientation portrait means that when is the width of the screen bigger then its height and when the soft keyboard popup the width of the screen become bigger than the height so that happen

memory
also if the width is smaller it will start flashing a higher height

memory
the height width ratio since the height of the text box is relatively smaller than the width and the area of the text box

memory
so the ring shape will be cropped if the width of the imageview becomes bigger than the height

memory
so can i change the background image for a div when the device width is smaller than height

memory
basically it should check weather container length or height is smaller compared to image width and height normalized and adapt it to that

memory
using jquery of javascript you can get the height of the table and set the div to be slightly smaller than the width you retrieved from the table

memory
but the code does not function correctly if the width is smaller than the height since l ranges only 1 to

memory
portrait orientation is that one where the width smaller than the height

memory
if the screen width is smaller than the height i need the white circle s radius to be width 2 and if the height is smaller than the width i need the circle s radius to be height 2

memory
personally i would extract it to a separate class just so that i could in isolation verify that given a width larger than a height i was returned a scalr.mode.fit_to_width and vice-versa

memory
you can change the width and height attributes on the referenced svg if they are bigger than the width and height on the iframe element you should get scrollbars

memory
with jquery you can check if height is larger than width and vice versa

memory
another problem is if use multiple monitors together for viewing desktop the width will be very bigger than the height so the boxes will have smaller height and bigger width

memory
portrait mode sets the smaller side as the width and larger side as height for example 9 16 landscape the sets the larger side as the width and smaller side as height 16 9

memory
i can successfully crop the photo if its height is larger than the width but not otherwise and i just can t see whats wrong

memory
if the height is larger than the width the window is in portrait mode

memory
others because the width is larger than the height doesn t fit properly.that s why i crop them they must be centered in order to make sence

memory
the goal is to have the top wrapper container green to take on the height of the vertical black wrapper and the left column wrapper to be no larger than the width of the rotated black wrapper

memory
in order to do so you need to find out if the svg is portrait or landscape - meaning if the width is smaller than height former or not latter

memory
the images can be of any resolution size and the height sometimes is bigger than the width and vice versa for both images

memory
this algorithm could be optimized if you rotate points or just exchange x-y coordinates so that width of the occupied area is not larger than its height

memory
i m wondering if it s possible to automatically arrange the icons so that when the width gets smaller than x the last icon of each row gets pushed to next row so that it grows in height

memory
for example if you know that you have no such object whose width or height is smaller than 50 pixel then you will put 50 as the increment in the nested loop either on width or height or both.

memory
you should consider if the height is bigger than the width portrait

memory
you have to calculate a ratio like this when width is bigger than height

memory
note that i am using jquery to set these boxes max-height so they will never have the height bigger than the width

memory
with this code image will be stretched if image container width is bigger then image actual height

memory
the idea is that the width is 3 times larger than the height and i was thinking to achieve this with overflow-x auto and overflow-y hidden as shown in the example from the second row 6-th column on these website

memory
if the device width is smaller than height so the device is a tablet or a mobile phone in standard position and rotation usually

memory
i found this how to detect the orientation of a pdf document in iphone sdk - but when i try to get the dimensions of the pdf the height is always bigger than the width no matter what orientation the pdf has.

memory
for example if you know that you have no such object whose width or height is smaller than 50 pixel then you will put 50 as the increment in the nested loop either on width or height or both.

memory
the solution is to choose the minimum metric between width and height since in multi-window mode the height can be smaller than the width

memory
if height is bigger than the width it s height won t be 100 only it s width in all cases will be 100

memory
this second snippet is the same as the previous one but now the height is 20 smaller than the width it was equal on the previous example plus have a max-height limit of 100px

memory
inside default mainpage you can override constructor and load page with another design if height is larger than width

memory
for some of them the width is much more bigger than the height for some of them the height is much more bigger than the width and for some of them height and width are almost the same

memory
if the height of the image is smaller than the width i set the height to be equal to the width and crop the width accordingly with aspect unchanged

memory
to draw a crossed rectangle of height 2 times larger than its width using the low-level graphics package facilities i call

memory
the basic idea behind the approach is that you map the coordinates of the images to the interval by dividing by the width assuming the width is the larger dimension but it does not matter if it is smaller than the height

memory
this should fit the image to the height of the gridview maintaining the aspect ratio and crop the remaining width unless the image s width is smaller than that of the gridview when the height is matched

memory
you can see in the opencv source code for fitellipse that the height of the ellipse is always larger than the width

memory
because the width of the screen is bigger than height on monitor the landscape will scale better

memory
if the width is still smaller than the height adjust it manually and you should be able to fix your issue

memory
the reason why i m struggling is that sometimes the width is bigger than the height and sometimes the height is bigger than the width

memory
width is always bigger than height

memory
if the width is bigger than the height i want the height to be set to auto

memory
the width should be larger than the height

memory
i have report with width size is bigger than height size like landscape but set to portrait in format - page format ireport

memory
if the bin width is smaller than zero the bar height might become very large

memory
so if i set height attribute to 40 i might find myself with images larger than 120 width

memory
the right image doesn t look like a square the width is larger than the height

memory
my camera by default is in landscape mode therefore it takes pictures with a width much larger than the height

memory
landscape width is bigger than height

memory
now pen style thumb width is much bigger than height show correctly

memory
i noticed that the horizontaladvance of the chars f w y a is smaller than their normal width and the verticaladvance of the char is smaller than its height

memory
if the width is bigger then the height landscape

memory
you can check the width of the image and if the width is bigger than height you reduce the image for the width instead reduce from the height to fill the container something like that

memory
in landscape mode the container s width somehow gets larger than its height as shown below

memory
if width is larger than height you get undefined behaviour probably writing into random memory under which anything can happen

memory
checking if screen width is larger than height is useless in my case because the app always runs in landscape

memory
and the height is smaller than the width physically

memory
for photos taken on other devices pass successfully when are rotated to portrait height bigger than width

memory
surprisingly if i set the heightmeasurespec to a lesser value than widthmeasurespec still the item height gets larger than the width

memory
if you wan to account for all the possible options real height width bigger smaller than virtual height width and to make sure that the best configuration is delivered the rescaling occurs such that the available space is maximised it is not so straightforward

memory
but in safari browser the table cell height is bigger than the width i did not set the whole table dimensions

memory
for images having width much smaller than height no margins observed

memory
for images with height larger than width it s the following line that causes error

memory
i have report with width size is bigger than height size like landscape but set to portrait in format - page format ireport

memory
the problem is that the image has static width and height and then if i access the blog on a mobile device the image is cut because it s bigger than the width of the device

memory
i need to apply a condition in the case that an image s width is bigger than equal to or smaller than height but i m in trouble when i try to compare the variables

memory
i have a fullscreen image standard 16 9 that scales proportionally unless the users height is larger then the width

memory
if the height is bigger smaller than width don t draw or set visibility false

memory
and to resize the image proportionally when the screen width is smaller than 1000px i set the max-width as 100 and height as auto using css

memory
portrait mode is when the window height is larger than window width

memory
this xml code works well if the image is a 1x1 ratio or if the height is bigger than the width

memory
my current code will rotate but will crop the edges if the height is larger then the width

memory
despite them being set to the same numbers the column width is much larger than the row height

memory
in case the image s width height is larger than the device s screen width height i want to crop the image so it matches the device dimensions see picture below

memory
when you are using the orientation landscape you have to consider whether the keyboard popup will change the display once the width size is larger than the height size the css will consider it as landscape

memory
but this is no good for desktop because the height may be larger than the width probably quite rare though but the orientation will never change

memory
the first two commented lines for setting width and height of dialog works but second two uncommented lines does not work displayed height is slightly smaller than it should be and content overflows vertically width is ok

memory
in landscape mode the container s width somehow gets larger than its height as shown below

memory
i have a code which zooms and pans the imageview matrix it works well but i want the imageview to not be zoomed smaller than my screen and i don t want it to be zoomed very much i want to set a limit for zooming and to the same thing for dragging panning it should pan horizontally if image s width is larger than screen and it should pan vertically if image s height is larger than the screen how can i achieve this result

memory
see picture above height 1280 width 720 when the actual splashscreen have a width bigger than the height

memory
so the height must be 1.24 times larger than the width

memory
width 110px | height relevant to the width if the height is bigger than width

memory
it will also automatically apply a 90 degree rotation transformation if the width is bigger than the height before applying any scaling

memory
just check if the height is bigger then the width thus portait

memory
i want to have two columns stacked into one column when the height of view port is larger than the width of the view port

memory
since the height is much bigger than the width there are top and bottom parts that are captured in the image that are not showing up in the live feed naturally

memory
how to set the size of img so that it s max-width is set to 200px if the width is smaller than height the image height is auto in this case to preserve aspect ratio and set max-width to 200px if the width is bigger than height

memory
the current solution works for shapes with equal sides but my divs are not like that their width are bigger than their height

memory
because the width was bigger than the height of the pictures the img element was too small and the rotated picture overlaid some of the text above and below

memory
as i understand it you need footer to be on the left side of the sidebar when content height is smaller and full width bellow sidebar when content is higher

memory
i have an image in my site which it s height is bigger than it s width

memory
when i add a margin to the divs the width becomes smaller and the height stays the same so the aspect ratio changes

memory
again a uiscrollview will not scroll in height width unless the contentsize property s height width is larger than its frame property height width

memory
i have a view where i need to place an uiimageview and i was told to place it inside a rectangle that takes the screen width and its height is smaller than width fixed size

memory
what i did is in the completion block of downloading image method i check if the image width is larger then i change the imageview to the new imageview with new resized height but i can t make it work with autolayout

memory
you can also see if the screen width is larger than the screen height since sometimes especially on first launch of the app it will be uideviceorientationunknown

memory
the device width is bigger than its height so it seems to be inverted

memory
the diameter of the dot shall not exceed half the height of the aggregation diamond and shall be larger than the width of the line

memory
on landscape as the width is bigger than the height you should set top and bottom 0 and ratio 1 1 and center it horizontally in container

memory
if width is bigger than height print image-horizontal else print image-vertical

memory
portrait mode is when the window height is larger than window width

memory
i m currently using a before element with padding-top 56.25 which works only with respect to the width of the outer div and overflows the outer div if the width is much larger than the height

memory
but since i want a portrait preview i need to rotate the image and as a consequence i get images with an height much larger than the width the transpose of the original image i guess

memory
i would advice to check if the width is bigger than the height of the picture taken landscape picture and if that is the case show an alert to the users to explain that just portrait pictures are supported

memory
if height is bigger than width then this will result in unallocated arrays for some of the in your code as it stands

memory
when the height is larger than the width - things are perfect like this

memory
when text records in autocompletetext are more than its height automatically vertical scrollbar appears but why when length of text is bigger than autocompletetext width scrollbar doesn t appear

memory
but when i stretch the width to be larger than the height it crops the image even if i switch to object-fit contain

memory
yet when i save the image the image his in landscape width is bigger than height

memory
if the width is larger than the height itâ s in landscape mode.

memory
width return a larger dimension than height which is not correct

memory
while on portrait you should set trail and lead constraints as your height is bigger than the width so if you set 0 for trail and lead and 1 1 ratio you are safe that it will fit beautifully

memory
if the ratio is bigger then 1 then the width is bigger than height let s say 700px 500px and after resizing the image is filled with white spaces in the top and bottom of the image

memory
this is weird cause i would figure that the width should have a bigger value than the height right now

memory
that will also works if the height of the window is larger than the width

memory
in this post he used 56.25 to make a ratio of 16 9 while i understand the maths 100 16 9 it doesn t seem to be the case if the height is larger than the width

memory
how would i write a media query for when the device height is larger than device width or vice-versa

memory
my current code will rotate but will crop the edges if the height is larger then the width

memory
the following code is working without any error but my problem is when i create a thumbnail some times thumbnail are non understandable one some conditions such as width is very larger than height i also tried a code for calculate height automatically.but it won t perfectly works

memory
of course if the ratio is less than 1 then the width is smaller than height let s say 500px 700px and you will see the white spaces on the left and right of the image

memory
on devices like the droid the bottom row is squinched in because the table width is smaller than the height

memory
i have a fullscreen image standard 16 9 that scales proportionally unless the users height is larger then the width

memory
when the medium width becomes larger than its height then it would be the default landscape size

memory
although the uiimageview is square the uiimage s height is much larger than the width

memory
basically you would start with a font height smaller than the height of your textview and then iterate or do a binary search through fonts of varying sizes until you find one that measures to smaller than the width of your textview

memory
what i want it to do is to center a given image from a database into a div for example if the given images width is bigger than height it echos it with a left margin

memory
my image has the width bigger than the height so i want that the minumum zoom is the width

memory
below is my code for displaying a full-screen background image and also has some basic function for detecting whether the device s width is larger than the height

memory
in details height is getting larger than expected and event more than width

memory
when requesting the preview sizes from the camera you always get pairs where the width is larger than the height because landscape is the usual orientation when taking a picture

memory
how can i make the outer div height and width never be any smaller than the height and width of its contents

memory
such that a landscape image would have an ideal height of 300 or slightly larger with a width 400 and a portrait image would have an ideal width of 400 or slightly larger with a height 300

memory
i would when the height is bigger than the width the width 100 height auto

memory
if width goes bigger height will goes bigger

memory
but if i look at in the firefox responsive design developer mode the circle takes always more space than it should when the wrapper containers height is larger than its width -

memory
or continuously check the stage width height in onenterframe update and if height is bigger than width portrait else landscape

memory
it seems like image in width is larger then the image in height where as it is not in reality

memory
auto shrink only seems to apply when the width is smaller than needed and not when the height is insufficient

memory
this version gives me a fixed 500px height and an image that looses aspect ratio when viewport is smaller than image width

memory
if requested width or height of a window is larger than width or height of a screen desktop the function shrinks the values to the screen sizes

memory
resize scale image only if the width height is bigger than 1000px so that the resulting image s max width height is 1000px or less

memory
check if the image s width is bigger than its height

memory
however if you want to redesign your layout or make adjustments based on wether the screen is in landscape width is larger than height or portrait height is larger than width mode you can definitely use css media queries

memory
of course this would have the problem that in displays where the width is bigger than the height there will be an area not covered by the video

memory
so this will make width proportional with the height that is set but the problem is when the width is bigger than height

memory
for a quick fix you can check if image s width is bigger than image s height

memory
let s assume that width of the array is bigger than height otherwise we will split in another direction

memory
the asymmetry might ve been caused by the dimensions of the spinner container .round where its width was 2px larger than its height

memory
for some of them the width is much more bigger than the height for some of them the height is much more bigger than the width and for some of them height and width are almost the same

memory
what is the best approach to dealing with images whos height is much much larger than their width in regards to covering the background

memory
the image renders but then when i try to pinch zoom in and out only the height of the picture changes bigger or smaller with the width stuck at the iphone screen width

memory
the program does load a picture its width height always bigger than canvas width height and when i make a mouse click on the canvas it returns a x y - coordinates and color grayscale value but it always a coordinates of canvas not an image ones

memory
when resizing the image if the width side is larger than the height resize the image so that the image height is the div s height and hide the width overflow after centering

memory
now you should have square cell - as you see those dimension are not pixels and height must be bigger than width

memory
if the width is still smaller than the height adjust it manually and you should be able to fix your issue

memory
however after rotating a rectangular image its new width and height is much bigger as these two screenshots should help clarify during rotation and after rotating then rotating again -- the little handles show where the images x y width height extends to

memory
when the window width is smaller than its height then the orientation would be considered portrait

memory
your main div has height 1200px and the content are larger than this width so border is not displaying on the content which are overflowing you can check by increase height it will showed

memory
i can only find adaptivetriggers which take a static minwindowwidth or minwindowheight .but what i need is no matter how big or small the screen is if the height is bigger than the width go with the first design and if the width is bigger go with the second design

memory
the image is exaggerated in that it s width is normally bigger than its height

memory
the problem is when the window s height is larger than it s width the grid inside the window gets clipped

memory
if the height of the video with width 100wh is bigger then the height 100vh i want the video to crop so it will be on fullscreen view on the max with and height youre browser

memory
the problem i hit is when the width is bigger than the height

memory
in this example the absolute difference in width is larger but the percentage difference in height is higher

memory
most popular video formats are 4 3 or 16 9 so the width is larger then the height

memory
this should allow you to solve for your concern about aspect ratios i ve tried using vmin but that does not help as the height of the window is almost always smaller than the width

memory
as you can already see from these dimensions the captured image s width is smaller than its height whereas the uiimageview s width is larger than its height - the proportions are different

memory
this code is not perfect though because it doesn t support when height is bigger than width easy to fix thoughâ

memory
therefore when i get my browser bigger width gets bigger as well as height

memory
width is always bigger than height

memory
this can be done using pure css using the vw viewport width vh viewport height vmin relative to width or height whichever is smaller vmax relative to width or height whichever is larger length units

memory
the above scaling assumes that the height of the grid location is always smaller than the width of the grid location

memory
if the aspect ratio is 1 then the height is larger than the width

memory
in other words to check if the height is bigger then the width

memory
if the background image s width is bigger than it s height it s width must be 100

memory
the problem is that the width is bigger than the height and i want it to be the same 1 1

memory
but the measurement is reverse row height shows bigger number than column width

memory
but the video height and width is smaller then then device screen height width

memory
pages are landscape if their width is bigger than their height

memory
portait in a mobile device is that orientation where the width is smaller than the height

memory
in second scenario i will display image in fix width and height div which will be smaller than image width and height

memory
if set true then it might increase the width or height if the given width and height are bigger than original width and height

memory
if the height of the video with width 100wh is bigger then the height 100vh i want the video to crop so it will be on fullscreen view on the max with and height youre browser

memory
the third url works fine when the image width is larger than the height landscape but when the height is the largest dimension portrait it resizes the height correctly but the width dimension does not get padded to fill the 600px width but instead becomes whatever size is calculated to maintain the aspect ratio

memory
if the image that s inside has a width that s smaller than its height add class portrait

memory
elements smaller than height or width is less than 2000px will become circles elements larger than height or width is more than 2000px will not become circles but rather stay their original shapes but have largely rounded corners

memory
if they are equal or the width is bigger i set those to 100 each and set height as auto whereas if the height is the greater value i set that to 100 and width to auto

memory
i figure it has something to do with an image which has a width smaller than its height

memory
i seem to remember reading somewhere that if report height is smaller than width printout is automatically rotated to landscape

memory
such that a landscape image would have an ideal height of 300 or slightly larger with a width 400 and a portrait image would have an ideal width of 400 or slightly larger with a height 300

memory
i would like somehow to fit the image to scale it normally without setting up fixed values for width and height so if the width is bigger - scale the height and if height is bigger - scale the width

memory
specifically i take the image s height and width and then divide both by larger value 300 so that the aspect ratio is maintained and the image is optimized to fit in the space i have designed for it a width that is never smaller than 320 and a height that is always exactly 320

memory
if the width is bigger then the height landscape

memory
the basic idea behind the approach is that you map the coordinates of the images to the interval by dividing by the width assuming the width is the larger dimension but it does not matter if it is smaller than the height

memory
i would like somehow to fit the image to scale it normally without setting up fixed values for width and height so if the width is bigger - scale the height and if height is bigger - scale the width

memory
on every image load a call this function with image and resize if its width or height is bigger than my max width and max height

memory
since your height is smaller than the width it should do the trick

memory
when i select images which height is bigger than width

memory
if the height could be bigger than width you can add

memory
for some of them the width is much more bigger than the height for some of them the height is much more bigger than the width and for some of them height and width are almost the same

memory
essentially i detect if the view s width is larger than the height and if so rotate the view that contains the boxes

memory
shapes width are a couple of pixels larger than their height and using that value in computations works

memory
if width is bigger than the height it s width won t be 100 only it s height in all cases will be 100

memory
like on the ipad lest say its 137p x 60p and lets say the iphone s width is 150 smaller and the height is lets say is 125 smaller

memory
but the result does not look like a square at all the height seems to be larger than the width

memory
as they say above you can resize your browser window to have the height be larger than the width so then the media portrait is true

memory
the presence of a tab bar controller was enough to make the height 768 - 20 - 49 699 just smaller than the width 1024 - 320 - 1 gutter 703

memory
in case your form contentpane s width height is smaller than the images width height than a better option would be use

memory
right now what this code is producing is the right image doesn t look like a square the width is larger than the height

memory
if image height is larger than width portrait then scale the width to 1024 pixels and scale the height to appropriate value to maintain aspect ratio

memory
what i did is in the completion block of downloading image method i check if the image width is larger then i change the imageview to the new imageview with new resized height but i can t make it work with autolayout

memory
height is usually larger than width

memory
in picturebox i saw this image left rotated.but if image width is bigger than height there is no problem

memory
i m trying to set the height of a image to 150px if the image width is larger than the height and if the image height is larger than the width the width of the image changes to 150px

memory
if the images height side is larger than the width resize the image so that the width matches the divs width and hide the height overflow after vertically centering

memory
with this gives you a figure of which the height is 300x smaller than the width

memory
i am using liquid fun library for my android project when i have my glsurfaceview width equal to or bigger than the height everything works well but when i set height bigger than the width the particles rendering doesn t work well

memory
one where height is bigger than width and one where width is bigger than height

memory
if you have an image which has a ratio like 16 9 so the width is larger than the height use the method above

memory
the solution posted by nathaniel actually fails if the image height is larger than the image width

memory
however if the image width is far smaller than the height the image is centered which crops the top

memory
how come photoshop sees its height bigger than its width

memory
but the problem is on resizing an image with 1920 x 1200 pixels as the height is much smaller than the width

memory
there is an image restriction that is not documented or at least i couldn t found anything the aspect ratio limit is 1 3 when the height is bigger than the width on the image

memory
for example if the image width is much larger than the image height than on smartphone the image will use 100 of the width of the screen and in proportion to that will be the height of the image

memory
if window height is bigger then window width the we have a portrait or in any other case we have a landscape orientation

memory
the problem is when a users browser s height is smaller than the popup the overflow css property adds the ability to scroll which is what i want but it also adds its own width inside the popup causing one product to move down to next line

memory
if the screen width is smaller than the height i need the white circle s radius to be width 2 and if the height is smaller than the width i need the circle s radius to be height 2

memory
once again my question is why is my program crashing if the width is larger than the height when the computer plays

memory
if your image s width is larger than its height then mark s solution will leave space at the top and bottom of the screen

memory
now i want to order this array by the pictures with the biggest width worth and where the width is bigger than the height

memory
if the video height was larger than its width the math is the same

memory
if you have a portrait device the width is smaller than the height

memory
if a user s screen had a resolution of 1000x800px 100vmin would be equal to 800px and 100vmax would be equal to 1000px as the height here is the smaller unit and the width is the larger unit

memory
if the image s width i bigger than its height i want the height of the croppingarea to automatically scale to the height

memory
if width is smaller than height store width in one variable called value else store height

memory
from my experience every time the kindle fires up my landscape app with a width smaller than the height thus by definition not really giving me a landscape view i just ignore the surface and wait it quickly gives me a a real landscape flipping the height and width so that its a true landscape view

memory
the canvas height is slightly larger than the width

memory
it seems like image in width is larger then the image in height where as it is not in reality

memory
most popular video formats are 4 3 or 16 9 so the width is larger then the height

memory
if your height is bigger and width is smaller than container width will be stretch to 100 and height will be trimmed from both side

memory
when the height gets dramatically larger while width stays the same we throw a hide keyboard event

memory
if the devices width is smaller than its height the card should also rotate 90deg

memory
try to change overflow hidden to overflow auto this should make it scrollable horizontally if width is bigger than screen and vertical if height is

memory
the other page isn t rotated but it has a height that is smaller than the width

memory
in portrait view the width is smaller than the height

memory
how do i make perfect centered circle always 100 height of blue div until blue div width because smaller than height and image always covering full circle

memory
however if the height is larger than the width aspect fit will increase the height of the uiimageview

memory
i found this how to detect the orientation of a pdf document in iphone sdk - but when i try to get the dimensions of the pdf the height is always bigger than the width no matter what orientation the pdf has.

memory
since the height is much bigger than the width there are top and bottom parts that are captured in the image that are not showing up in the live feed naturally

memory
one page is a page of which the width is smaller than the height sounds like it s a page in portrait but as there s a rotate value of 90 added to the page dictionary it is shown in landscape

memory
since the svg s width is much larger than its height every 1px change in the height of the svg is causing the width to change by about 10px

memory
if you want a pure css option i believe an absolute positioned div inside the body with width and height of 100 overflow auto and right padding larger than the width of a scroll bar will replace the normal scrollbar without shifting the content to the left on long pages

memory
if the images height side is larger than the width resize the image so that the width matches the divs width and hide the height overflow after vertically centering

memory
make it very narrow and while its height is bigger than the desired one keep increasing width

memory
however if you want to redesign your layout or make adjustments based on wether the screen is in landscape width is larger than height or portrait height is larger than width mode you can definitely use css media queries

memory
i needed to compare the width and the height of the uiimage when width is larger than height i will add border

memory
i.e if the browser height goes smaller the image will scale down while not overlapping or going under the text and staying centre same goes for width

memory
left position in fixed worked probably due to the fact that it s width is larger than it s height

memory
but with iframe it is a problem - window height is always bigger than width

memory
bottle thumb height is much bigger than width are only partly visible

memory
this approach doesn t work when the width of the container is larger than the height as the child overflows the parent as demonstrated in the following snippet

memory
to generalize this approach you could try and check whether the offsettop of an element is greater than the height of the container or the offsetleft is bigger than the width

usability
managing the content via width is a better approach you don t really need to know the height

memory
the code that i have so far seems to work as expected when the x-axis of the wrapper is bigger than the y-axis width height but for some reason when the height of the wrapper is bigger than width it gets all distorted

memory
i add the detail that opening it only with some software paint picasa viewer ... i see the picture squeezed horizontally of about 50 this way width is smaller than height to my eye too

memory
is there a way to change the height so that its smaller than the width to make horizontal rectangles

memory
is the height of the viewport larger than the width

memory
it seems to work by seeing if the width is bigger then the height landscape so it also works on desktop really well

memory
when i set it off height width but i d like it to stretch so it supports other device sizes ....i need the height to stretch as well though which does not happen no matter what i tried height keeps turning out smaller than width

memory
i tried to add class and added the background image for that input.but the height and width is aligned bigger than the text box.on trying to change the height the input size reduced as the background img is inside the input

memory
but with iframe it is a problem - window height is always bigger than width

memory
it seems to work by seeing if the width is bigger then the height landscape so it also works on desktop really well

memory
if a user s screen had a resolution of 1000x800px 100vmin would be equal to 800px and 100vmax would be equal to 1000px as the height here is the smaller unit and the width is the larger unit

memory
it will look at the image height check whether the height is smaller than the width or if the width is smaller than the height and set either one to the smaller height

memory
what is the reason that text s width is smaller than its height

memory
when you are using the orientation landscape you have to consider whether the keyboard popup will change the display once the width size is larger than the height size the css will consider it as landscape

memory
if left is larger than body width or top is larger than body height

memory
if you want it to scroll the width and height must be larger than the width and height of the scrollview itself

memory
i can rotate it to any angle i want but i want to make the rotated square squashed making the height 2 3 smaller than the width

memory
i believe the aspect ratio is defined as width height so does that mean that the vision framework cannot detect rectangles that have a width bigger than height

memory
since the svg s width is much larger than its height every 1px change in the height of the svg is causing the width to change by about 10px

memory
landscape orientation is that one where the width is bigger than the height

memory
since the width of your image is larger than the height you need to basically reverse these three lines of code

memory
even though you ve given your header a fixed height of 10vh if one resizes the browser whereby the header s width gets smaller eventually a height 10vh might not be tall enough to contain all of header s content thus it overflows

memory
width and height of the canvas element need to be as big or bigger than the width and height of the image which i wasn t setting when i created the image object

memory
and the height 100 if the image height is bigger than width

memory
that is why width is bigger than height

memory
if the screen is layout is changed to landscape as you know the height is smaller and width is longer in landscape mode

memory
and i don t why appears in this format width larger than height

memory
i want to know if the device screen width is larger than height

memory
portait in a mobile device is that orientation where the width is smaller than the height

memory
the height is 3 times larger than width which is unexpected

memory
the diameter of the dot shall not exceed half the height of the aggregation diamond and shall be larger than the width of the line

memory
it works well when height is bigger than width but it does not work when width is bigger than height

memory
as you can already see from these dimensions the captured image s width is smaller than its height whereas the uiimageview s width is larger than its height - the proportions are different

memory
with this gives you a figure of which the height is 300x smaller than the width

memory
you just should separate the x and y axis during distance comparison if the y distance is smaller than the width and the x distance is smaller than the height than there is a collision

memory
assuming width is bigger in size then height scale the image width to the holder width

memory
portrait height is bigger than width

memory
height 110px | width relevant to the height if the width is bigger than height

memory
if you set the width and height of the element and set the offset to any size the same size for both left and right or top and bottom it will be centered because the element cannot get any larger than its width and height attributes

memory
when the window is resized the background image shrinks in height once the window is adjusted smaller than the width of the actual photo

memory
the images can be of any resolution size and the height sometimes is bigger than the width and vice versa for both images

memory
but the video height and width is smaller then then device screen height width

memory
but the measurement is reverse row height shows bigger number than column width

memory
in that font the zero width space is taller than verdana characters are causing added height requirements

memory
even though you ve given your header a fixed height of 10vh if one resizes the browser whereby the header s width gets smaller eventually a height 10vh might not be tall enough to contain all of header s content thus it overflows

memory
for any frame with width values larger than the height a 1 ratio the leg will begin to stretch unproportionally

memory
i was wondering how to get the height and width of an image if i m rendering it react style so i can process it to flip it to portrait mode if the width is larger than the height

memory
in this case you create a document of which the width is smaller than the height the mediabox is defined as a rectangle in portrait but you rotate that page adding a rotate entry equal to 90 to the page dictionary

memory
i suspect ios just sets the landscape flag if the usable width is larger than the usable height

memory
scale does not work for images where the height is larger than the width

memory
what should i modify to make the background image s width 100 when it s width is larger than the height and vice versa

memory
the basic idea behind the approach is that you map the coordinates of the images to the interval by dividing by the width assuming the width is the larger dimension but it does not matter if it is smaller than the height

memory
but the problem is because the screen height is bigger than the width is makes image looks expanded in height like this

memory
so its width is the width of the user s browser minus as much as possible without making them larger than 90 height of the viewport

memory
the following code is working without any error but my problem is when i create a thumbnail some times thumbnail are non understandable one some conditions such as width is very larger than height i also tried a code for calculate height automatically.but it won t perfectly works

memory
so how can i set the image to load as a square and be 100 width if the width is smaller than the height and 100 height if the height is smaller than the width

memory
if you wan to account for all the possible options real height width bigger smaller than virtual height width and to make sure that the best configuration is delivered the rescaling occurs such that the available space is maximised it is not so straightforward

memory
it breaks in case of views with width comparatively larger than height

memory
pass a value for width that is much larger than that for height and you will get a very wide figure

memory
although the uiimageview is square the uiimage s height is much larger than the width

memory
if the height is bigger smaller than width don t draw or set visibility false

memory
and when the width is bigger than the height the height 100 width auto

memory
the image is exaggerated in that it s width is normally bigger than its height

memory
chrome however stops displaying the canvas when the height becomes larger than 8130 pixels the width is constant - 834 px

memory
in landscape the height is smaller than the width

memory
just check if the height is bigger then the width thus portait

memory
it depends what is your default stylesheet like if you want to tell the browser that when the width is smaller than 700px apply these styles but as soon as the height goes smaller than 600px over ride these styles with these new values

memory
for some of them the width is much more bigger than the height for some of them the height is much more bigger than the width and for some of them height and width are almost the same

memory
the canvas height is slightly larger than the width

memory
if width is bigger than height this code won t work

memory
if the width of the browser window is larger than the height body width will be equal to the window height

memory
however if the image width is far smaller than the height the image is centered which crops the top

memory
it works well when height is bigger than width but it does not work when width is bigger than height

memory
ps the image source width and height is always bigger than the width and height parameters and the width and height ratio is being preserved

memory
also make it so it ll always be centered horizontally and vertically and the width will always be 1.5x bigger than the height

memory
ps the image source width and height is always bigger than the width and height parameters and the width and height ratio is being preserved

memory
if your height is bigger and width is smaller than container width will be stretch to 100 and height will be trimmed from both side

memory
one way you can do it is to check if the position of the mouse is within the div boundaries if the x position is smaller than the div s width minus the width of the image as you don t want the image to cross the div s border and if the y position is smaller than the height of the div minus the height of the image

memory
essentially what this does is check whether your image view s width height is smaller that the screen s width height and if so create an inset of half the screen s width height you could probably make this larger if you want the image to go out of the screen bounds

memory
if the height is larger than the width the window is in portrait mode

memory
so basically the small and medium sizes are a vertical layout as the height is bigger than the width

memory
i brute forced it a bit with forcing the height of the box to always be larger than the width

memory
if the height is larger than the width the ratio will be y x instad of x y and minimum will be multiplied by ratio for x instead of y

memory
so it needs to downsize the image so that both the width and height are larger than the width and height of the target maintaining aspect ratio

memory
in other words to check if the height is bigger then the width

memory
in case your image s width height is smaller than form contentpane s width height you might as well do not scale it since the image will fit the screen

memory
guys after spending too much time looking around for an easier way to do this i combine the info from research to do it like this simply using the getimagesize function -if the height is larger than the width echo an image tag with a style having a height of 100 else echo the same image tag but with a style having a width of 100

memory
the pixel height is larger than the pixel width

memory
and i just recently found out that the above applies only to image whose width is larger than height

memory
if the background image s height is bigger than it s width it s height must be 100

memory
if the height is bigger than the width it is portrait

memory
but the screen always gets rotated to landscape instead of being set to portrait when the width is smaller than the height

memory
i know emacs tries to be intellectual and opens its helper buffers depending on which dimension of the window is bigger so it may appear in vertical split window if current width is bigger than height and in horizontal split otherwise

memory
with this code image will be stretched if image container width is bigger then image actual height

memory
now this works on my desktop machine in firefox if i make the width smaller than the height

memory
if the width is larger than the height itâ s in landscape mode

memory
bottle thumb height is much bigger than width are only partly visible

memory
solved it will resize only if width is larger than 800px or height is larger than 600px

memory
one where height is bigger than width and one where width is bigger than height

memory
if the width size is more than height size then the device is a tablet otherwise is a phone

memory
i tried changing the screen resolution in a virtual machine orientation change is really just a screen resolution change that results in width being larger than height or vice versa and could not trigger any layout events

memory
you can check wether the width larger is than the height which is landscape

memory
the image is placed in a correct height but the width could be bigger or smaller than the height constraints

memory
if image height is larger than width then scaletypes fitstart fitend and fitcenter don t work

memory
if you dont want to crop the image at all or use javascript i think your only choice is to force the text element to have the same proportions as the image with width approximately being 50 larger than height and then adjust the font-size text elements to fit the container

memory
if the aspect ratio is 1 then width is larger than height so you then need to assume a square the same size as height as it s the smaller value

memory
landscape pages can be created in 2 ways set a width larger than the height or set the page rotation to 90 or 270 degrees for a portrait page

memory
the reason why i m struggling is that sometimes the width is bigger than the height and sometimes the height is bigger than the width

memory
if the height is larger than the width a portrait image the image should be scaled to fit the height of the phone and width should then adjust to keep the aspect ratio i ve had a bit of trouble getting this to work here s what i ve done so far though any help would be greatly appreciated

memory
all of the labels have the same aspect ratio the width is 3.5 times larger than the height so i m trying to find contours that have a minarearect with that same aspect ratio

memory
in your xml the tag specifies height bigger than width hence the oval

memory
if the width gets smaller the height should get larger accordingly to display the whole content

memory
as the image width is always bigger than the height this condition always is true

memory
this is for the case when the height of the image is larger than the width

memory
i m not interested in the height only the width they won t be the same - the size will be dynamic but i can presume the height will be larger than the width

memory
now pen style thumb width is much bigger than height show correctly

memory
if i set the page format with height is smaller than width it is treating it as a4 paper and feed the bottom of the paper

memory
photoshop opens it and shows it vertical mac preview does too but getimagesize keeps telling me width is bigger than height

memory
if the width is larger than the height then width and height are swapped and the angle is corrected

memory
right now i scale by height which works to some degree however as the width gets smaller the image gallery will be cut off as the container has overflow hidden on some smaller widths as it is adjusting by the height of the container to stay in proportion but doesn t consider the width of the container too essentially the width is longer than the container width

memory
if height is larger than width

memory
i want to add media queries for a div to change position when the screen width is smaller than 820px and or height smaller than 615px so i made this

memory
first if a notification image is displayed from my firebase database and the height is larger than the width and also the height exceeds the maximum image height for the notification iâ m not sure specifically what this is the image is compressed vertically and the aspect ratio is incorrect

memory
i have an image where the width is bigger than height

memory
one that maintains the aspect ratio one that makes sure the width is no larger than the maximum and one that makes sure the height is no larger than the maximum

memory
if width is larger than height

memory
and i need the height to always be a little bit smaller than the width

memory
this method works great except for one thing if the new height is smaller than the new width the new height and new width successfully get modified but after the imagetoadd.draw rectanglef the size of the imagetoadd still has the new width value instead of the cropped width that is if i can assume that if i draw an image with -20 as its x-value the width gets modified with -20 as well

memory
not only is height of keyboard so large how can height be larger than width

memory
i ve tried using vmin but that does not help as the height of the window is almost always smaller than the width

memory
it will look at the image height check whether the height is smaller than the width or if the width is smaller than the height and set either one to the smaller height

memory
i want set page orientation to portrait with width size is higher than height size

memory
i m trying to set the height of a image to 150px if the image width is larger than the height and if the image height is larger than the width the width of the image changes to 150px

memory
check it out it doesn t matter the width you set to the #content because naturalsize checks the ratio and the container s width and sets a smaller height for the video than the original preventing the black bars appearing in original video height with a smaller width

memory
i m currently using a before element with padding-top 56.25 which works only with respect to the width of the outer div and overflows the outer div if the width is much larger than the height

memory
this is used in a situation that view s width height is bigger that its parent s width height

memory
so how can i set the image to load as a square and be 100 width if the width is smaller than the height and 100 height if the height is smaller than the width

memory
in your case in the 3rd circle the height and width of .bublina not same height is smaller than width thats why border-radius 100 is not making it circle

memory
portrait mode sets the smaller side as the width and larger side as height for example 9 16 landscape the sets the larger side as the width and smaller side as height 16 9

memory
scott suggested to remove the transform -50 -50 which makes perfect sense if you wanted the div centered in the first place but if you wanted that in there still and have it centered as a square in a rectangle height is smaller than width then 45 by -290

memory
this can be done using pure css using the vw viewport width vh viewport height vmin relative to width or height whichever is smaller vmax relative to width or height whichever is larger length units

memory
i need to apply a condition in the case that an image s width is bigger than equal to or smaller than height but i m in trouble when i try to compare the variables

memory
if you rotate the device the width becomes the height and we can ignore the change but if the height gets dramatically smaller while the width remains the same it is safe to assume there is a keyboard being shown and we throw a show keyboard event

memory
if you think about a moment this is exactly what you want - to know if width is smaller than height portrait the opposite landscape or if they are the same square

memory
you ll need to change the width and height settings so that the width is larger than the height

memory
...then using the animate on click event you could give the height a value and animation time the width a delay equal o bigger than the height animation time and then it s value...that should do the trick but it s more stiff than actually using the ui

memory
width should be smaller than height at about 100px - the all works fine

memory
i only want it to fit the width 100 and wish to become bigger than the height but not leave the certain container

memory
but the measurement is reverse row height shows bigger number than column width

memory
if image width is larger than height landscape then scale the height to 1024 pixels and scale the width to appropriate value to maintain aspect ratio

memory
note what i observed is the margins appears only when image width is larger than height

memory
but the problem is on resizing an image with 1920 x 1200 pixels as the height is much smaller than the width

memory
edit actually you resize the one that is the biggest if width is bigger you resize that and if height is bigger then you resize that

memory
as the image width is always bigger than the height this condition always is true

memory
so something happens with the images that their width is smaller than their height or images that are tall

memory
i need to resize an image so that if its height is smaller than its width i ll set its height and vice versa

memory
second if a notification image is displayed from facebookâ s database and the height is larger than the width and also the height exceeds the maximum image height for the notification the entire image will be resized to fit the maximum allowable height for the notification image leaving white vertical bars on either side

memory
i am using liquid fun library for my android project when i have my glsurfaceview width equal to or bigger than the height everything works well but when i set height bigger than the width the particles rendering doesn t work well

memory
if you want it to scroll the width and height must be larger than the width and height of the scrollview itself

memory
i am trying to resize the image based on if the height is larger than the width or width height

memory
so at first this looks ok but is actually is not all pixels in the image are not square but elongated with their height being bigger than their width

memory
is the width of the viewport larger than the height

memory
i wouldn t scale the image every single time in the paintcomponent method but do it once if the width and height have been changed since the last call and in that case recreate a bufferedimage containing the image which you blit every single time before calling the superclass paintcomponent scaled up to the right size use something like image scaling does not work when original image height width is smaller the scaling height width

memory
therefore if console window height or width is larger than buffer height or width argumentoutofrangeexception is thrown in .net there is no argumentoutofbounds exception type

memory
â if the height is bigger than the width i switch the style to max-width 100 and height auto

memory
i m not fully sure how this should work on desktops but i m pretty sure that when you resize the browser the orientation should change provided the height was bigger than the width and after resizing it s the other way round

memory
how to set the size of img so that it s max-width is set to 200px if the width is smaller than height the image height is auto in this case to preserve aspect ratio and set max-width to 200px if the width is bigger than height

memory
i figured that if the image was actually in landscape then it was appearing stretched and truncated because it s width was larger than its height

performance
i wrote a detailed description of the sstable format on scylla s site scylla is a more efficient c++ re-implementation of cassandra to which i contribute

performance
anyway i just prefer not to use it because gecko is slower then webkit

performance
anyway i just prefer not to use it because gecko is slower then webkit

memory
gecko is often considered to consume less memory than webkit but this depends a lot on how the browser is implemented

memory
my understanding is webkit is pretty good smaller than gecko

performance
at best it is a computationally expensive hash function like whirlpool that for example is five times slower than md5 and thus allows only a fifth of the number of hash operations in opposite to md5

memory
you should also adjust your conditionals to check for a low high range as it should quickly get smaller as your median value approaches the real value

usability
in the cases where auto can be used it is more concise than decltype as you don t need to provide the expression from which the type will be inferred

memory
developers community it might seem that laravel has a larger community of developers but during my career with yii i ve found no bottleneck of having a question without an answer

memory
developers community it might seem that laravel has a larger community of developers but during my career with yii i ve found no bottleneck of having a question without an answer

usability
use swing-x components there is a jxtable which is more powerful than jtable

memory
this relates to another question i asked a while back at size of qt containers is qmap much larger than qlist

usability
edit based on the tests done by multiple people and by theory isnull seems to be a better option over coalesce

performance
isnull can only have one input however it s been shown to be slightly faster than coalesce

performance
isnull is marginally faster than coalesce

usability
using coalesce is better option than isnull or case..when for this problem since the input values for the coalesce expression can be evaluated multiple times

performance
you can use isnull also in place of coalesce as isnull is comparatively faster than coalesce

performance
to prefer isnull over coalesce when given the choice is that isnull tends to produce query plans that are more efficient than coalesce

performance
this is pretty much the ifloop answer but isnull is slightly faster than coalesce

performance
isnull is marginally faster than coalesce

performance
isnull is faster than coalesce

performance
isnull will be faster i think because it has lesser function code implementation for itself making it faster than coalesce

performance
you can use isnull also in place of coalesce as isnull is comparatively faster than coalesce

performance
this is pretty much the ifloop answer but isnull is slightly faster than coalesce

performance
in some circumstances isnull is faster than case or coalesce

usability
coalesce will go through the listed values and choose the first one that isn t null it s more portable code than isnull or ivnl etc

usability
- coalesce should be more portable than isnull

performance
i suppose it is because you hide them faster than you show them so for a slight second the overal page height is shorter than it should

usability
also as mentioned elsewhere show is a better option to css visibility as hide sets display none and not visibility

performance
things like cmd c dir don t know why - and yes i do cmd c dir in cases i am in some kind of shared network folder with thousands of files and ls is significantly slower than dir

performance
i wish program with armadillo and openblas is faster than with only armadillo

memory
does tinyint in mysql take up more space than boolean

performance
however a linkedhashmap is faster as seen here treemap has o log n performance for containskey get put and remove according to the javadocs while linkedhashmap is o 1 for each.

performance
linkedhashmap is faster for insertion because it wonâ t have to unnecessarily compare values while inserting like treemap as stated by ejp

performance
it sounds like you need a treemap which has iteration which is not much slower than linkedhashmap and does what you really want

performance
alarmmanager should also be more efficient than timertask

memory
the framespace for the uiviewcontroller becomes smaller because uinavigationcontroller manipulates the view by adding a uinavigationbar which is 44.0f in size

performance
shortly put running some benchmarks on a page doing some database operations and serving static dynamic content has shown that plain cherrypy was twice as fast than nginx and memcached and about half faster than lighttpd

usability
i actually found the setup of nginx much easier than lighttpd not to mention that you can install a macport of nginx port install nginx +ssl that does not contain the ssl-breaking bug that lighttpd suffers from here

performance
nginx seems to be the webserver getting the majority of the buzz lately it may be able to serve faster than lighttpd maybe not

memory
3.14 is pretty close but a little smaller than pi and sin 3.14 is thus pretty close but a little bigger than 0 cos 3.14 is thus pretty close but a little smaller in absolute terms than -1 so tan 3.14 is a little less than 0

performance
or maybe flip them on my machine sin seems faster than cos

performance
so if we have a vector and want to calculate a component-wise function over it say sin and cos it is faster to use vvsincos from accelerate because it will pipeline the calculations of sin and cos for all the entries in the vector which is faster than using a for-loop over the vector

performance
after reading a question related with the performance of sin cos why is std sin and std cos slower than sin and cos

performance
first of all sqrt x should be faster and more accurate than pow x 0.5 why do you think it s in the library

performance
my question is is fast implementation of pow x 0.5f faster than fast sqrt x

performance
i have made an app similar to yours for android we use boofcv whose surf is much faster than opencv

memory
check out sorcery it s more lightweight and less obscure than devise

performance
i realized that emacs would load slower than vim but this seems ridiculous for a fresh install

performance
and i tend to think that after a moderate amount of customisation of either one vim will still start up faster than emacs

usability
emacs is more powerful than vim it s scripting engine is far more flexible and there are far more scripts modes and the likes built around emacs

usability
i am starting to understand that even though emacs is more powerful than vim vim is at least 10 times easier to use less keystrokes and requires way less modifications

usability
for example emacs s macro shortcut f3 and f4 is easier than vim s qq and q

usability
personally i m using emacs right now which i find easier than vim for searching and navigating the code but everyone has their taste

usability
you might want to try emacs - it has an inbuilt tutorial and some people like me find it easier over vim no flames pls

performance
unless you re doing very heavy processing working with a single frame is probably faster than transferring it to the server as far as i know emgucv in c# isn t considerably slower than opencv in c c++

performance
as in title why is multiplication much faster than subtraction in this example

performance
multiplication is slower than subtraction

performance
subtraction operations and usually significantly faster than multiplication and division

performance
yes joomla takes more time in cooking the resulting html when compared to wordpress

usability
i seem to be getting the impression that wordpress is more popular than joomla nowadays

usability
imho creating templates for joomla is the easier than most other cms i know typo wordpress modx as you simply have to replace parts of the static version with joomla tags menu content etc. it still needs some time to get used to the system but its not that hard

performance
in terms of speed calloc is likely to be faster than malloc + memset if memory needs to be zeroed out

memory
those answers was that calloc can allocate larger blocks than malloc can and etc

performance
and is as far as i know faster than the combination of malloc and memset on the other hand malloc alone is faster than calloc

performance
this is an enormous amount of extra work and explains why calloc is faster than malloc and memset

performance
if end up using the memory anyway calloc is still faster than malloc and memset but the difference is not quite so ridiculous

performance
it s conceivable that calloc could return address of memory location that is already pre-initialized with zeros thus it may be faster than malloc + memset combo

performance
it would be better to use malloc over calloc unless we want the zero-initialization because malloc is faster than calloc

performance
i remember somewhere i have read that calloc is slower than malloc because calloc performs initialization to zero after performing memory allocation

performance
calloc itself is slower than malloc because you have to spend some time to clear the contents of allocated memory

performance
calloc is faster than malloc + memset because calloc knows that the mmap d pages are pre-zeroed and memset forces the allocation of physical ram

performance
this means calloc can potentially be faster than calling malloc followed by memset since it can skip the memset if it knows it will already by zeroed

performance
malloc is faster since calloc initializes the allocated memory to contain all zeros

performance
also calloc is slower than malloc from operating system memory allocation perspective

performance
if end up using the memory anyway calloc is still faster than malloc and memset but the difference is not quite so ridiculous

performance
and is as far as i know faster than the combination of malloc and memset on the other hand malloc alone is faster than calloc

performance
malloc is faster than calloc reason is that malloc processed single dimensional array to pointer format whereas calloc takes double dimensional array and before processed it converts to single dimensional array then to pointer format

memory
for this reason since calloc uses two arguments of type size_t it can allocate bigger blocks than malloc will ever be able to since malloc takes only one argument of type size_t

security
a clob is a safer way to handle the soap request than an xmltype because the data returned may be longer than 32767 bytes

security
a clob is a safer way to handle the soap request than an xmltype because the data returned may be longer than 32767 bytes

memory
layout-sw320dp-land will pick up drawable from hdpi folder whereas layout-sw720dp-land is mdpi device so it will pick up drawables from mdpi folder which will be smaller than hdpi

memory
and you know your image at hdpi folder so its 1.5 larger than the mdpi

memory
example if using dp unit hdpi device will have 1.5 240 160 times larger than mdpi

memory
ldpi assets will look bad on high density screens but are exponentially smaller than mdpi which is exponentially smaller than hdpi etc

memory
when you put images into hdpi folder their appearance is smaller than from mdpi and ldpi

memory
ldpi assets will look bad on high density screens but are exponentially smaller than mdpi which is exponentially smaller than hdpi etc

memory
images in these different folders should have different physical pixel sizes mdpi has smaller images than hdpi but the images pixel densities aren t used

memory
ideally the hdpi version of your button should be 1.5 times bigger than the mdpi baseline version

memory
images in these different folders should have different physical pixel sizes mdpi has smaller images than hdpi but the images pixel densities aren t used

memory
for example mdpi is basically 72dpi as your computer monitor hdpi resources should be around 1.5 times larger than mdpi resources and so forth

usability
with caliburn it is even easier since you just need to bind a property on your viewmodel to selecteditem

performance
push log files to a central location ftp is faster than smb the windows ftp command can be automated with -s scriptfile

usability
pbkdf2 is arguably a better option than bcrypt scrypt having been much more thoroughly studied and tested

memory
however the qwidget gauge1 is always bigger than the other one.i want to use a qgridlayout because the application has to work on different sizes of a screen

performance
if it s too slow i would ditch the autocompletion part of python-mode because it uses rope which is slower than jedi

performance
as we can see copying manually with memcpy is always slower than realloc because in this scenario malloc is guaranteed to allocate new memory and you re forced to copy the data in every allocation which shows us that realloc is indeed reusing the same address and enlarging the block size in some cases

performance
as we can see copying manually with memcpy is always slower than realloc because in this scenario malloc is guaranteed to allocate new memory and you re forced to copy the data in every allocation which shows us that realloc is indeed reusing the same address and enlarging the block size in some cases

performance
as you can see from the above tests realloc is consistently faster compared to memalloc memcpy and free

usability
fadeout is simpler because it will hide it for you automatically when it is done so you can save that code and it automatically waits for the animation to be done before hiding the element something your current code was not doing

performance
according to this test - hide is slightly faster then fadeout since it doesn t use animations

performance
according to this test - hide is slightly faster then fadeout since it doesn t use animations

memory
kdtree needs less memory than octree and sometimes is even faster

usability
so yes it can be used with flash or rather pure actionscript but it is a little less convenient than with mxml where everything is set up by the framework because it takes more under the hood configuration to be able to run all the necessary parts for remoting

memory
i can see that my skeleton mxml module is slightly larger than my actionscript module 66kb vs

memory
i can see that my skeleton mxml module is slightly larger than my actionscript module 66kb vs

memory
is it because request response handling on wildfly is kind of more lightweight than the jboss 4.2.3

performance
but bfg-repo-cleaner is a much faster solution than git-filter-branch

performance
but bfg-repo-cleaner is a much faster solution than git-filter-branch

memory
like the rest of rest wadl is lightweight easier to understand and easier to write than wsdl

memory
however ico files if stored properly are not significantly larger than png files because since windows vista ico files can store png

performance
i ve read that carrierwave is much faster without using fog

performance
is nsorderedset faster than nsset

usability
do need implementation of qabstractitemmodel that can be more useful than qstandarditemmodel

performance
with typical libraries on common modern hardware sqrt is faster than atan2

usability
it seems openmpi has better support for assigning ranks than mpich but setting up slurm and mpich wasn t trivial due to the cluster setup so i m hesitant to start over with openmpi

usability
i try to fit a gam using the gam package i know mgcv is more flexible but i need to use gam here

usability
mgcv and gam does not depend on each other but since mgcv is more popular than gam many packages has dependency on mgcv for example car

usability
in my opinion swing is easier to start because there are tools like the eclipse windowbuilder which enables you to create your application in a graphical interface but javafx is more likely to be used in the future because it has some great improvements over swing like css skins etc.

usability
in the case of autotools it is slightly more complicated because not everybody who compiles the software would need automake and autoconf installed only those that need to change the build system adding new files counts as changing the build system

usability
with this in mind customizing the css of a wicket app is significantly easier than vaadin for the simple reason that you control the markup

usability
i would say vaadin would be easier over wicket as the default ui elements look really good

usability
with this in mind customizing the css of a wicket app is significantly easier than vaadin for the simple reason that you control the markup

usability
furthermore signed integer types just tend to be more useful than unsigned types

memory
the problem is that the input integer is larger than what would fit in an unsigned long long

memory
instead default argument promotions take place which means that any integer type smaller than int unsigned int gets converted to one of those -- that s not the only promotion but the only one relevant here -- and which also means that there is no automatic conversion to whatever type you specify with va_arg

memory
both of following types are semantically equivalent minimum 64bit integer without sign and with equal or bigger size than unsigned long int

performance
the idea here is threefold readability using operator functions with compatible left and right arguments as well as return value and the use of integer multiplying operators being faster than unsigned operators

memory
error integer constant is larger than the largest unsigned integer type

memory
i do have the guarentee that the signed integer is always bigger or equal than the unsigned integer in bytes so no data should be lost due to lack of space

memory
on your system unsigned int is apparently larger than uint16_t int is a greater ranked integer type than short in the standard 6.3.1.1 even if they are of the same size

memory
1 as chux has noted in a comment if unsigned is larger than uint32_t arithmetic on uint32_t goes through the usual integer promotions and if not it stays as uint32_t

memory
going too high gives the error integer constant is larger than the largest unsigned integer type

performance
in case of unsigned integer division this problem does not arise which is why generally integer division works much faster for unsigned types than for signed types

memory
an implementation that has no such unsigned type say because pointers are bigger than any integer type won t provide it

reliability
you can indeed execute scripts on almost any page using content scripts that can manipulate the dom allowing you to add an onsubmit event listener to a form more reliable than onclick on a button as it is fired however the form is submitted - hitting enter

performance
my speed test claims that svg is significantly faster than canvas at least snap.svg seems to be significantly faster than fabricjs

performance
typically mergesort is slower than heapsort and quicksort but that s usually under the assumption that comparisons are fast

performance
heapsort tends to be slower than mergesort for the same reason.

performance
what baffles me is that my mergesort seems to be slower than heapsort in both of the languages

performance
normally quicksort is faster than mergesort which is faster than heapsort

usability
bower packages are simpler than npm equivalents and don t have subfolders with module dependencies

usability
on the project i m using bower to manage dependencies because i found that it has way more available versions than npm does

performance
glassfish seems to be slower than resin

performance
if you use shellsort no extra memory is needed at all though shellsort will be much slower than quicksort

usability
using just the keyfn return a comparable value that matches your requirements is much easier than implementing comparator

usability
it should be mentioned that sinon provides many more features for smart stubs spies than jasmine so both can be used together

performance
some browsers implement the mouseenter mouseleave events that i ve noticed are more accurate than mouseout

performance
sublimetext 3 needs much more time several seconds more then scite before the opened file shows up and i suppose it is because sublimetext does some pre-evaluation of the file content like detecting areas suitable for folding there are fold triangles available depending on indentation of non-white characters in the file

usability
if the latter is what you want you could use rtf which is somewhat easier than the doc format

usability
if the latter is what you want you could use rtf which is somewhat easier than the doc format

usability
there s a post on the subject on the birt world blog here specifically relating to xls emitters although the tribix emitters mentioned should also enable output to rtf a microsoft format readable by word that is much more concise than doc

usability
bazaar is imho easier to learn than git

performance
an incredibly rough eye balling of the numbers they posted showed bazaar to be 2-4x slower than either git or mercurial in the use cases tested

usability
note most recently i have been using bazaar and hg with fully powerful regexps so may be looking for stuff more powerful than git provides

performance
i hear all this stuff about bazaar being slower than git

performance
mercurial is significantly faster than bazaar it s slower than git though by a much smaller difference

usability
bazaar is easier to extend in an api way git is easier to extend in a unix way pipes

performance
a lot of articles about bazaar will tell you it is a lot slower than git or mercurial

performance
after looking it s seems that hmac is much faster and better in term of security even if the underlying hash function sha1 is broken which is not the case when using rsa-sha1

performance
in some cases on embedded platforms where a fast hash function may not be available these may be more efficient than hmac

usability
it looks like the onload function is a more modern convenience method and the old way of checking the result is using onreadystatechange instead

usability
it looks like the onload function is a more modern convenience method and the old way of checking the result is using onreadystatechange instead

memory
thanks mikushi for the comment another possibility that i haven t used much is the the xhprof extension it also helps with profiling can generate callgraphs -- but is lighter than xdebug which mean you should be able to install it on a production server

security
in few words strncmp is safer then strcmp but it is slower too

security
in few words strncmp is safer then strcmp but it is slower too

security
strncmp is a little bit safer than strcmp because you specify how many comparisons will be made at most

security
note strncmp is safer than strcmp

security
also have a look at strncmp which is safer version of strcmp

security
the only case where strncmp would be safer than strcmp is when you re comparing two character arrays as strings you re certain that both arrays are at least n bytes long the 3rd argument passed to strncmp and you re not certain that both arrays contain strings contain a 0 null character terminator

performance
is strcmp slower than strncmp as one can give pre-calculated string length to it but strcmp does not receive such information

security
you should use strncmp to compare your strings it s safer than strcmp

security
also have a look at strncmp which is safer version of strcmp

memory
an unsigned char is an unsigned value which is typically smaller than and is guaranteed not to be bigger than a short

performance
btw on some processors unsigned short is much slower than unsigned int because the c standard requires that operations on unsigned types wrap

performance
btw on some processors unsigned short is much slower than unsigned int because the c standard requires that operations on unsigned types wrap

memory
as unsigned short int is in some implementations smaller than unsigned int

memory
but i wrote this code to check if we compared an signed int x 0xdeadbeef and unsigned short y 0xffff then after converting the unsigned short to int we should have 0x0000ffff in y at the comparison which should be smaller than the unsigned value of x

performance
in the experiments and discussion below i find that cufft is slower than fftw for batched 2d ffts

performance
i am working on a code which needs to be time efficient and thus using cufft for this purpose but when i try to compute fft of a very large data in parallel it is slower than cpu fftw and the reason i find after finding the time for every line of code using high precision timing code is that cudamalloc taking around 0.983 sec while the time for rest of the lines of code is around 0.00xx sec which is expected ..

performance
however for a variety of fft problem sizes i ve found that cufft is slower than fftw with openmp

performance
ironpython has had more time to focus on performance improvements but ironruby has made significant performance improvements as of late

memory
also i believe the ironruby team is smaller than the ironpython team

memory
also i believe the ironruby team is smaller than the ironpython team

performance
however as things stand right now ironpython is much more mature and has much better performance than ironruby so you may prefer to use that

performance
i have found one benchmark in which yii is faster than codeigniter and another benchmark in which codeigniter is faster than yii

usability
i am currently looking at yii and while its more complex than codeigniter the documentation is much more informative and therefore understandable than cakephp s

performance
i have found one benchmark in which yii is faster than codeigniter and another benchmark in which codeigniter is faster than yii

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

usability
even though git-svn is easier to start with here are some further reasons why using the kde svn2git instead of git-svn is superior besides its flexibility

memory
safari makes child block s height larger than google-chrome

performance
this seems to me like a bandwidth error or something like that originally i ve got the error when i played with the html 5 audio api and if i loaded the audio file 10-15 times sequentially then i ve got the error but now i ve discovered that i get the error without the audio api too just by reloading the site a lots of times also safari gives me the error much faster than google-chrome wtf

performance
the one used by google-chrome and is slower than mobile safari s nitro javascript engine

performance
if i try to do a google search for website loading slower in google-chrome than in safari i get a lot of results about how safari is slower than google-chrome

performance
conclusion diff1 is faster in firefox opera and safari diff2 is faster in ie and google-chrome

performance
the one used by google-chrome and is slower than mobile safari s nitro javascript engine

memory
total width of button in safari web inspector 6px larger than in google-chrome web inspector

performance
my ipad 1 safari js benchmarked 38 times slower than google-chrome on my pc

memory
safari will display fonts without a specified size significantly smaller than in google-chrome

memory
safari 5.1.10 6534.59.10 middle handles a smaller viewport but in sort order with a smaller viewport computes new image sizes even smaller than google-chrome

memory
2 if your host machine laptop doesn t have more ram then you might want to find alternative android-emulator like genymotion bluestacks which takes less memory than android-emulator

reliability
scala does not provide an alternative and any alternative that was provided would likely be less reliable as typesafe does not have the resources that sun oracle ibm etc

memory
i am using view flipper to show bunch on images like a slider where i implemented the functionality of swipe left and right to switching images now some of my images are larger than the screens size in terms of height are getting hidden

memory
i ve already built a view that can take a drawable can use focused pinch-zoom and drag can auto-scale images can switching images dynamically and takes images larger than the screens

memory
the point of such an architecture is because i have news with some text between which i want to be able to switching with paging effect but the news text can be bigger than the screens

memory
the panels must be side by side for a large screens but they must be responsive and as the screens gets smaller and switching to vertical orientation

memory
when the screens size is smaller i have it switching flex-direction to column which works well except i cannot figure out how to make the 2nd row trending down start where the trending up stops where ever that may be

memory
when the screens size is smaller i have it switching flex-direction to column which works well except i cannot figure out how to make the 2nd row trending down start where the trending up stops where ever that may be

memory
but when the screens is smaller than 900px we switching from fixed to liquid via media query switching to a liquid width will allow our images to scale down our text to wrap and a whole bunch of other great things

memory
when the switching gets bigger than a couple of screens full split it into functions that handle each state using a state table to look up the function directly

performance
according to many benchmarks uwsgi seems to provides better performance than gunicorn and if the performance doesn t change significantly you ll be able to focus your investigation on nginx or ec2 configurations

performance
llvm compiles code faster than gcc may create code that runs faster and the clang frontend provides more accurate error messages than gcc â so there are definitely reasons for switching

usability
good options are llvm libc++ static library fewer features more compatible with clang and gnu stl static library more features i had an issue that required me to turn the clang optimizer to -oz to prevent a segfault

memory
edit2 okay i just see that if the angle is bigger than 180â it s concave so i have to change the shape for be simple than a triangulation

memory
for a counterexample i think scheme programs ran faster and used less memory than the lisp programs that preceded them mdash

usability
i ve also found scheme ides much more user-friendly than lisp s plt scheme is a good one

usability
it s popular it s actively developed it has many libraries offering the features of a modern programming environment and scheme is somewhat simpler not to say better just simpler than common lisp

usability
i ve noticed that the common lisp approach is more conservative than the approach scheme has

usability
i don t see why sbcl should be so fast - scheme is a far simpler language than common lisp

usability
it s popular it s actively developed it has many libraries offering the features of a modern programming environment and scheme is somewhat simpler not to say better just simpler than common lisp

usability
scheme is also a good language for that purpose and it is simpler smaller than lisp

memory
scheme is also a good language for that purpose and it is simpler smaller than lisp

usability
it s popular it s actively developed it has many libraries offering the features of a modern programming environment and scheme is somewhat simpler not to say better just simpler than common lisp

usability
scheme is intentionally more compact than common lisp and you ll find that you can learn the language very quickly

usability
i ve noticed that the common lisp approach is more conservative than the approach scheme has

usability
however gambit scheme has smoother access to c c++ code libraries which far outnumber common lisp s libraries

memory
so if your document bson is larger than 16 mb mongodb throws exception

usability
mongodb stores everything in memory anyway and works in a similar vein being a key-value based system however i believe mongodb is more flexible as it allows for storing bson objects within themselves

usability
qtoolbutton is much more complex under the hood than qpushbutton

memory
qtoolbutton has smaller default internal margins than qpushbutton

memory
qtoolbutton has smaller default internal margins than qpushbutton

performance
i m running unicorn which is about 40 faster than thin on celadon cedar

performance
in production it is much better to use a more sophisticated server like phusion passenger or unicorn since they have better performance than thin mongrel or webrick

memory
you can remove the transform s and the margin-left and add a width set as 0 here smaller than the font-size 16px here to the get the effect

memory
as you can see the font-size of the text is bit larger than the width of the noisy lines

usability
i also checked prolog and it seems a pretty cool language easy to do relations between data and easier than lisp but i d like to hear what you think

usability
testng has more capabilities and can be helpful with integration tests junit is more focused on unit tests

usability
testng offers you more options and possibilites how to run your tests and in which order especially something junit can t

memory
in case if you have flexibility to choose another testing framework you can try with testng which has bigger feature set than junit

memory
in case if you have flexibility to choose another testing framework you can try with testng which has bigger feature set than junit

usability
i know this can be achieved with junit but in my experience it is easier with testng

usability
testng is more flexible than junit and have multiple advantages like support for parallel testing for example

usability
to be perfectly honest i junit is way more popular than testng at least here where i work and live

usability
if you are familiar of using junit it is easier to switch into testng

usability
if you have to do a lot of this honestly testng is more flexible but you can absolutely get it done in junit

usability
to be perfectly honest i junit is way more popular than testng at least here where i work and live

usability
if you re doing non-unit testing testng might be a better option than junit

performance
is sqlcmd always that much faster than ssms

usability
a webclient is much easier than a webrequest

usability
a webclient is much easier than a webrequest

usability
webclient is simpler to use than webrequest

usability
update i ve created a webhelper class that takes the place of webclient but provides more access to the necessary features of the underlying webrequest

usability
webclient is sometimes easier to use than webrequest

memory
we started with ehcache terracotta server array cause it s well-known backed by terracotta and has bigger community support than hazelcast

memory
we started with ehcache terracotta server array cause it s well-known backed by terracotta and has bigger community support than hazelcast

performance
in some applications tcp is faster better throughput than udp

usability
keep in mind that implementing udp traversal is easier than tcp

memory
yes udp is much much lighter than tcp

performance
please note however that this architecture implements tcp which is much slower than udp and will not work for any type of fast-paced data intensive games but should accomplish your goals given your description above

performance
udp sockets have much lower overhead than tcp because packets are not acknowledged by the recipient

performance
i suppose this is one of the reasons for the misconception that udp is slower than tcp

performance
tcp is much slower than udp but when the two machines are not on the same lan udp is not reliable

performance
udp communication requires much less overhead than tcp due to the number of messages exchanged

performance
tcp is much slower than udp but when the two machines are not on the same lan udp is not reliable

performance
also see this other so answer about the misconception that udp is always faster than tcp

reliability
udp is way lighter and faster but somewhat less reliable than tcp

memory
udp just has a smaller overhead than tcp but that comes at the cost of reliability

performance
tcp is a slower more reliable protocol than udp is

performance
apart from that tcp packets by themselves are not slower than udp packets and data transfer with a simple tcp connection can be faster than with a simple udp connection because flow control and reliable transfer is already integrated and you don t have to reinvent everything again and often worse

performance
one can say udp has a lower overhead than tcp because its packets have a smaller header and therefore take less bandwidth to send the payload the data

memory
the problem is that tcp creates bigger packages of data while udp uses 8 kb of data blocks

performance
is sending packets via an established tcp connection after all hand shaking has been done a method to be faster than udp

performance
maybe one of you guys already sees a problem in the code snippets or have any other suggestion or hint for me why my udp transmission is slower than tcp

performance
i was going through internet and so and understood that web sockets are encapsulations to tcp which by itself is slower than udp ofcourse at the cost of reliability but i couldnt find much info if websockets or udp would be ideal to implement such a server

performance
i was expecting that udp would be faster but tcp is on average two times faster than udp

performance
if the network between the two point have a very high quality udp is absolutely faster than tcp but in some other case such as the gprs network tcp may been faster and more reliability than udp

reliability
tcp is a slower more reliable protocol than udp is

performance
in that sense reliable udp cannot be faster than tcp

performance
udp is not always faster than tcp

memory
udp gives smaller latency with many many issues to discuss here of course tcp gives bigger latency

memory
udp gives smaller latency with many many issues to discuss here of course tcp gives bigger latency

memory
tcp has bigger overhead than udp because it needs to add more data to your payload but you are guaranteed that your data will be received in it s destination in the order you sent it and not corrupted

usability
+ consider that the implementation of tcp stack is much more complicated than udp more instructions are executed there

performance
udp should be much faster than tcp because there are no acknowledge and congestion detection

performance
that among other things is why tcp is considered more reliable but slower than udp

performance
http is an application layer protocol which could be encapsulated with a protocol that uses udp providing arguably faster reliable communication than tcp

performance
in some applications tcp is faster better throughput than udp

performance
tcp is slower assures data arrival udp is faster data corruption may be possible

security
i know tcp is a safer choice but let s assume i can only use udp and i need to ensure i can send packets over at a high rate with no missing packets what should i do

usability
but with the udp protocol in particular this is easier than for tcp

performance
there is a perception that udp is faster than tcp but i think it depends on the situation - take a look at this discussion for some further discussion on speed reliability etc between udp and tcp go down through all the high scored answers

performance
udp is generally faster than tcp as it does not have to do the overhead checking of consistency that tcp must deal with

usability
as such traversing a nat through udp is much easier than tcp

reliability
tcp ip is supposed to be more reliable than udp ip see this comparison

performance
only when packets can be discarded unordered can udp be faster than tcp

performance
i though that udp was faster than tcp but do you think that tcp will be faster due to the congestion

performance
i read in a case where a stream of 300 byte packets was being sent over ethernet 1500 byte mtu and tcp was 50 faster than udp

performance
the reason udp is faster than tcp is because there is no form of flow control or error correction

usability
as such traversing a nat through udp is much easier than tcp

performance
in a native application i would use udp for the most data player position ... because it s way faster than tcp and it s uncritical when it is lost

performance
udp is extremely faster than tcp which is suitable to stream a user s voice input

performance
use socket for tcp and datagram for udp its a lot faster than tcp but less connection oriented

performance
udp is much faster then tcp but tcp has flow control and guaranteed delivery

performance
i m aware of the differences in general the facts like tcp is more accurate while udp is more fast

performance
from experience i can tell you udp is about 10-15 faster than tcp on dedicated and udp-tuned networks

performance
in some applications tcp is faster better throughput than udp

memory
tcp sockets- guaranteed delivery bigger payload than udp cumbersome to setup for web based solutions

usability
+ consider that the implementation of tcp stack is much more complicated than udp more instructions are executed there

performance
udp is faster than tcp and the simple reason is because its nonexistent acknowledge packet ack that permits a continuous packet stream instead of tcp that acknowledges a set of packets calculated by using the tcp window size and round-trip time rtt

reliability
udp is less reliable on a wide area network but in a closed environment of a vm talking to its host you can safely skip all the tcp reliability stuff

performance
this is the reason why udp is much faster than tcp

usability
but there are some cases especially in iot domain udp is more popular than tcp for its bigger transport overheads

performance
what s currently baffling me is in my results tcp finishes almost 2x faster than udp

usability
also sending receiving data over udp is much simpler than over tcp and it does not require any connections

performance
please note however that this architecture implements tcp which is much slower than udp and will not work for any type of fast-paced data intensive games but should accomplish your goals given your description above

usability
if you can t afford lost packets then tcp is probably a better option than udp since it provides that guarantee out of the box

performance
i know that in practice this would only happen with a great amount of connection given that processing time of an udp connection is faster than tcp but it could potentially happen

performance
for example i read an experiment in which a stream of 300 byte packets was being sent over ethernet 1500 byte mtu and tcp was 50 faster than udp

performance
in some applications tcp is faster better throughput than udp

performance
generally speaking udp has less overhead than tcp allowing you to receive more data but this is not a strict rule and is almost negligible in this context

performance
tcp is reliable but slower than udp while udp is not safe and i have to implement my own fault-handling codes

performance
tcp mounts are more reliable and you know you have a network problem much faster than with udp

performance
if the network between the two point have a very high quality udp is absolutely faster than tcp but in some other case such as the gprs network tcp may been faster and more reliability than udp

performance
udp is faster than tcp because packets are sent without guarantee of delivery nor order

performance
it seems like udp will more efficient than tcp

performance
we propose to use udp over tcp since udp is faster than tcp

performance
udp has a much lower overhead than tcp

performance
udp is really faster than tcp and the simple reason is because it s non-existent acknowledge packet ack that permits a continuous packet stream instead of tcp that acknowledges a set of packets calculatd by using the tcp window size and round-trip time rtt .

performance
in some applications tcp is faster better throughput than udp

reliability
that among other things is why tcp is considered more reliable but slower than udp

performance
this is the reason why udp is much faster than tcp

usability
udp is simpler protocol than tcp and you can still simulate features of tcp using udp

usability
udp is significantly easier do you really need tcp btw

usability
it was introduced since the nat traversal for tcp is much more complicated than udp

performance
tcp is a bit slower than udp but more failsafe

reliability
what i have thought of so far is that tcp is going to be more reliable than udp and in rmi corba we want network reliability

memory
i am confused why tcp throughput is bigger than udp

usability
a udp stack is considerably simpler than a tcp stack

performance
udp is significantly faster than tcp and is why it is or was used for video and various things back in the day

performance
tcp has to do a lot of error checking to ensure that your packets don t get dropped and so tcp is much slower than udp

performance
most importantly you can easily supplement udp with some reliable delivery hand-shaking that s less overhead than tcp

performance
if they are connected over the internet you could try to use the examples for tcp but tcp has more overhead than udp

performance
udp is significantly faster than tcp and is why it is or was used for video and various things back in the day

performance
in some applications tcp is faster better throughput than udp

reliability
tcp mounts are more reliable and you know you have a network problem much faster than with udp

memory
i am confused why tcp throughput is bigger than udp

performance
4 tcp is a slower than udp

performance
udp should be much faster than tcp because there are no acknowledge and congestion detection

performance
i m trying to avoid tcpclient because udp is faster but would this work in tcp since it s streamed

reliability
tcp is certainly going to be more reliable than udp since udp doesn t guarantee packet delivery which is probably why you application is hanging on the receive

usability
udp is simpler protocol than tcp and you can still simulate features of tcp using udp

reliability
and there are no handshakings required udp are pretty much faster but less reliable than tcp

performance
if you were attempting to beat the performance of tcp by shifting to udp keep in mind that part of the reason you get lower performance with tcp is because tcp tracks and redelivers the lost packets for you

performance
don t think of it as udp is faster and tcp is slower because that s just wrong

usability
c++ is not my first language and this is small part of code i can t figure out i ve chosen udp because it is always much simpler than tcp

performance
udp is generally faster than tcp as it does not have to do the overhead checking of consistency that tcp must deal with

performance
udp communication requires much less overhead than tcp due to the number of messages exchanged

performance
i am using udp because it is much faster than tcp but sometimes i need the know for sure if the packet reached to the other side in my program i can not use tcp at all so i am sending ack packets

memory
tcp has bigger overhead than udp because it needs to add more data to your payload but you are guaranteed that your data will be received in it s destination in the order you sent it and not corrupted

usability
a udp stack is considerably simpler than a tcp stack

performance
udp is extremely faster than tcp which is suitable to stream a user s voice input

memory
the package is bigger than udp s package but smaller than tcp s package

performance
only when packets can be discarded unordered can udp be faster than tcp

performance
because there is no confirmation on udp packets it s slightly faster than tcp

usability
you can use udp as well but if you are dealing with firewalls it is probably going to be simpler with tcp

usability
it was introduced since the nat traversal for tcp is much more complicated than udp

performance
tcp is a slower more reliable protocol than udp is

performance
tcp has to do a lot of error checking to ensure that your packets don t get dropped and so tcp is much slower than udp

performance
udp is really faster than tcp and the simple reason is because it s non-existent acknowledge packet ack that permits a continuous packet stream instead of tcp that acknowledges a set of packets calculatd by using the tcp window size and round-trip time rtt .

performance
as an additional note my suspicion is that you d need to indulge yourself in some pretty sophisticated benchmarks before you could conclude that udp is actually going to have higher performance than tcp for web services

performance
udp has less overhead than tcp and is therefore faster

usability
udp is more popular in nat punching because provides much better results than tcp

performance
if i d directly say that udp is faster comparatively than tcp that it is used for such applications

usability
keep in mind that implementing udp traversal is easier than tcp

performance
for instance zeromq can leverage udp multicast to run faster than any tcp protocol but the application programmer doesn t need to learn a new api

performance
i know udp is faster than tcp for various reason

performance
udp is faster and requires less bandwidth than tcp

performance
if i d directly say that udp is faster comparatively than tcp that it is used for such applications

performance
udp will almost always provide better performance than tcp at the cost of reliability

performance
certainly tcp has more overhead than udp

memory
udp just has a smaller overhead than tcp but that comes at the cost of reliability

memory
the problem is that tcp creates bigger packages of data while udp uses 8 kb of data blocks

performance
as a general rule udp is faster than tcp due to less protocol overhead

reliability
tcp - more reliable than udp but this comes with some overhead there is a distinct connection a better match for games which require less frequent data transmission such as turn based games as is your game

performance
with tcp its slightly slower than udp and has more features

performance
in some applications tcp is faster better throughput than udp

performance
if the data is critical you should go for tcp which is slower as compared to udp which in fact doesn t guarantee the packets will arrive in order or even if they d arrive or not

performance
in a congested network yes udp will send its packets faster than tcp this is because tcp takes then congestion into account using a mechanism called congestion control

performance
in some applications tcp is faster better throughput than udp

performance
tcp as you know udp is faster than tcp even if udp may miss some

performance
theoretically udp should be be 30-50 faster than tcp because it s missing the extra trip for the ack and has a smaller header overhead however in reality there are many cases where tcp would outperform udp just because of congestion control

usability
first of udp s datagram is simpler than tcp s one

performance
tcp is slower than udp and you ll have to mitigate that in realtime multiplayer

performance
also see this other so answer about the misconception that udp is always faster than tcp

performance
i don t think you should make the assumption that udp is faster than tcp

performance
in some applications tcp is faster better throughput than udp

memory
udp is way lighter and faster but somewhat less reliable than tcp

performance
for example i read an experiment in which a stream of 300 byte packets was being sent over ethernet 1500 byte mtu and tcp was 50 faster than udp

reliability
tldr tcp ip is more reliable than udp but not a 100 iron-clad guarantee that nothing will ever go wrong

usability
udp packets are easier structured than tcp packets but sacrifice security for their size

usability
also sending receiving data over udp is much simpler than over tcp and it does not require any connections

performance
because of tcp requires connection and provides security it is slower than udp and therefore it should not be preffered during a video streaming

performance
i assumend that the transmission using udp have to be much faster than using tcp but in fact my tests proved that the udp transmission is about 7 to 8 times slower than using tcp

performance
in doing so the tradefoff is that tcp becomes slower compared to udp

performance
one often finds the argument that udp is faster then tcp

performance
the problem with using tcp is obviously that it is a lot slower than udp

performance
i assumend that the transmission using udp have to be much faster than using tcp but in fact my tests proved that the udp transmission is about 7 to 8 times slower than using tcp

performance
maybe one of you guys already sees a problem in the code snippets or have any other suggestion or hint for me why my udp transmission is slower than tcp

performance
at my company we have found memory mapped files to be much faster than loopback tcp ip for communication on the same box so i m assuming it would be faster than udp too

security
i know tcp is a safer choice but let s assume i can only use udp and i need to ensure i can send packets over at a high rate with no missing packets what should i do

reliability
you could get them to do a udp multicast within a lan environment to identify the programs using protocol messages then have a stored cache of each other s identity and then use tcp to connect and do main exchanging of messages which is more reliable than udp

performance
one often finds the argument that udp is faster then tcp

performance
the reason i asking this is because i read tcp is slower than udp because tcp ensures order of packets

usability
in my experience udp based code is generally less complex than tcp based code

memory
like matzi suggested udp gives you lower latency and lower packet overhead as the header is smaller than tcp but on the downside the delivery of the packet to the destination is never guaranteed ie

usability
you ve struck lucky with the requirements - because you re going from udp - tcp it s actually a lot simpler than doing udp - udp

performance
udp protocol is unreliable but much much faster than tcp which is most commonly used for communication

memory
if you can do everything with udp it is lighter than tcp

reliability
tldr tcp ip is more reliable than udp but not a 100 iron-clad guarantee that nothing will ever go wrong

memory
udp just has a smaller overhead than tcp but that comes at the cost of reliability

performance
try to increase timeout value tcp is slower than udp

performance
udp is much faster then tcp but tcp has flow control and guaranteed delivery

memory
des code is 8 times larger than rsa

performance
by comparison des see section 3.2 and other block ciphers are much faster than the rsa algorithm

memory
based on my understanding i hope that is because the size of the tablet screens which is smaller than the desktop that makes the strokes to get hidden inside the area that was not visible on the tablet however the area is visible in desktop

memory
my aim is to use a bootstrap 3 dropdown to display links at mobile screens size and use a list to display the same links when the screens is bigger desktop and tablet size

memory
basically my layout has 1200px grid width but i figured that there will be a problem with 1024px screens resolution 20 of the population bla bla so i created media queries when the screens size is smaller than 1199px the grid to change its width to 960px and so on for tablet phones etc..

memory
splitactionbar works only on phones because the screens size is much smaller than tablet and it takes space at the bottom for extra space for your action items

memory
however the number of people using these giant tablet is much smaller than the number of people with small screens laptops

memory
for example when the screens size becomes smaller to a tablet or mobile you could do this as an example

memory
the screens is much smaller so you can not present your app the same way as you can on a tablet

memory
in fact when a tablet has a larger than standard screens size the tablet with detachable keyboards available these days mobile versions of the site can look over-optimised for space which is the reason why browsers allow tablet users to opt to display sites in desktop mode

memory
having different ones based upon screens size is reasonable bigger margins on tablet though the mix then would be something like res values dimens.xml and res values-sw720dp values.xml

memory
having different ones based upon screens size is reasonable bigger margins on tablet though the mix then would be something like res values dimens.xml and res values-sw720dp values.xml

memory
this tablet has a bigger screens yet is still showing only 2 child views in the row

memory
in fact when a tablet has a larger than standard screens size the tablet with detachable keyboards available these days mobile versions of the site can look over-optimised for space which is the reason why browsers allow tablet users to opt to display sites in desktop mode

memory
twitter desktop accomodates screensizes from around 1048px wide when you are on a screens that is smaller then that you are probably on a tablet or smartphone and if you open twitter from a browser on your phone you are instantly redirected to and prompted to download the twitter app

memory
what i would like to do is use css media queries to have the title be above the tabs when the screens gets smaller or on a tablet or iphone

memory
in my actual code i ve set the display to none if the screens width is larger than tablet size because that s the only time i feel like i need the button

memory
my aim is to use a bootstrap 3 dropdown to display links at mobile screens size and use a list to display the same links when the screens is bigger desktop and tablet size

memory
inside the container i have a panel with the text set to left but when the screens gets smaller then a tablet to something like a phone i want the text in the panel to center

memory
if the screens is bigger than 1024px it should be green my tablet screens is but the background stays yellow

memory
this only happens when the window is on a computer in full screens mode but when the screens is made smaller to a phone tablet size the divs function how they should

memory
splitactionbar works only on phones because the screens size is much smaller than tablet and it takes space at the bottom for extra space for your action items

memory
in my actual code i ve set the display to none if the screens width is larger than tablet size because that s the only time i feel like i need the button

memory
this will only be added if the screens width is smaller than 480px else the tablet version would show the mobile version

memory
twitter desktop accomodates screensizes from around 1048px wide when you are on a screens that is smaller then that you are probably on a tablet or smartphone and if you open twitter from a browser on your phone you are instantly redirected to and prompted to download the twitter app

memory
that hopefully explains why a typical 320dp phone screens is always smaller than a 720dp tablet screens although the smaller screens can have more pixel than the larger

memory
inside the container i have a panel with the text set to left but when the screens gets smaller then a tablet to something like a phone i want the text in the panel to center

performance
lxml is the faster parser and can handle broken html quite well html5lib comes closest to how your browser would parse broken html but is a lot slower

performance
the standard html.parser option handles broken html less well than other options while the html5lib option is closest to how a modern browser would handle broken html albeit at a slower rate than lxml would handle html parsing

performance
lxml parser is generally faster html5lib is the most lenient one - this kind of difference would be relevant if you have a broken or non-well-formed html to parse

performance
lxml is the faster parser and can handle broken html quite well html5lib comes closest to how your browser would parse broken html but is a lot slower

performance
b magma runs always slower than lapack sequential around 10 times slower

performance
b magma runs always slower than lapack sequential around 10 times slower

performance
for formatting a single numeric value tostring is marginally more efficient than string.format because string.format has a bunch of overhead to parse the format string out of the curly braces and then pass it to tostring

performance
for formatting a single numeric value tostring is marginally more efficient than string.format because string.format has a bunch of overhead to parse the format string out of the curly braces and then pass it to tostring

usability
web.py has a templating language of it s own it looks easier than django s

performance
i like the auto-complete feature of pycharm but from my experience it is slower than spyder

memory
since fp addition shifts the smaller operand s mantissa until both operands have the same exponent you can add a certain magic number to force it

memory
since fp addition shifts the smaller operand s mantissa until both operands have the same exponent you can add a certain magic number to force it

performance
and how do the differences make liblinear faster than libsvm

performance
liblinear is considered faster than linear libsvm and often used for large scale data set

performance
and i ve read that using liblinear is far faster more memory efficient for such tasks as such i ve ported my libsvm classifier to accord net like so

performance
and i ve read that using liblinear is far faster more memory efficient for such tasks as such i ve ported my libsvm classifier to accord net like so

performance
liblinear is considered faster than linear libsvm and often used for large scale data set

usability
see but if you are using a linux distro there may be shortcut instructions that make it simpler under ubuntu for example there are shortcuts in

usability
although if you aren t interested in using adobe cs you can use ubuntu distro which is easier than other linux distro and quiet popular so you won t have any problem finding solution

usability
also i would recommend doing a dual boot to ubuntu it s much easier to work with opencl in a linux cli fashion

performance
i m testing some simple benchmarking calculations on win7 and linux ubuntu 16 to compare the timings and being wonder win appears to be much faster than linux

performance
i don t know why arch linux is slower than ubuntu on your machine

usability
even if you re on linux it s much easier to get a precompiled version sudo apt install r-cran-rgl on ubuntu if you have the appropriate cran repositories set up

performance
bcrypt is considered the most secure way to implement password hashing with salt because it is slow - much slower than an md5

reliability
instead of dropbox i could use key value store as rest web service which i want to do later but have no time for this for now in my opinion my solution is more reliable than icloud and which is very important i have full control on how itâ s working mainly because itâ s my own code

performance
from my experience collapse filtering is much faster than grouping

performance
from my experience collapse filtering is much faster than grouping

memory
note that the effective key size of aes is larger than triple des

performance
using des assuming it s a little faster than aes and requires a smaller key and

performance
though it s unrelated to your actual question des is generally slower than aes at least in software so unless you really need to keep the key small aes is almost certainly a better choice

performance
if aes is negotiated it s faster than des and 3des used by default by older applications

performance
des is usually substantially slower than aes on modern hardware and has keys that are far too short for modern use

performance
aes can be even much faster than des or 3des when the cpu supports aes-ni

memory
note that the effective key size of aes is larger than triple des

performance
though it s unrelated to your actual question des is generally slower than aes at least in software so unless you really need to keep the key small aes is almost certainly a better choice

performance
this shows that the timings are sensitive to buffering and that aes is faster than des

performance
des turned out to be even slower than aes but for my current requirements a much simpler algorythm rc4 is sufficient

performance
aes will indeed yield a considerably faster result than des

performance
because bellman-ford runs in time o mn the overall asymptotic runtime is still o mn + n 2 log n so if m o n 2 note that this is little-o of n this approach is asymptotically faster than using floyd-warshall

usability
the first thought is that you could build a uiview showing image and text then attach a uitapgesturerecognizer to it which would be more flexible than uibutton

memory
if i set a pixmap to a qgraphicsscene that is larger that the window it will add scrollbars so is it possible to get what is displayed in the qgraphicsview

memory
by default when you scale a qgraphicsscene larger than the qgraphicsview in which it is displayed it will show the necessary scroll bars

memory
edit as gregs points out in the comments you cannot be sure that the private exponent of the key you want to encrypt is smaller than the modulo of the key you want to use to encrypt with

memory
the private exponent is always smaller than the modulo so you should be able to encrypt it using the raw rsa operation if you make sure to remove the prepended zero

performance
using the pow function and passing a modulo value is faster than computing the full exponent and then taking the modulo because the modulo can be applied to the partial products at each stage of the calculation which stops the value from getting too large 10 6 to the power of 10 6 has 6 million decimal digits with a modulo applied at each step the values never have to grow larger than the size of the modulo - about 13 digits in this example

memory
i must also add that designing the rsa key so that the private exponent is substantially shorter than the modulo to speed up operations is a security risk if the exponent is smaller than 29 of the modulo length then the key can be cracked

memory
the private exponent is always smaller than the modulo so you should be able to encrypt it using the raw rsa operation if you make sure to remove the prepended zero

memory
in rsa signing a message m means exponentiation with the private exponent d the result r is the smallest integer 0 and smaller than the modulo n so that

performance
multiplication is a relatively complex operation and is likely to be slower than say addition or comparison

performance
also addition is faster than multiplication and multiplication is faster than division

performance
in any case if addition is faster than multiplication a better solution might be to use a table and index by it

performance
i don t understand why the division multiplication in c++ is so much slower than addition subtraction where the managed c# version is more reasonable to my expectations

performance
not sure about this but multiplication should take more time than addition so it s slowing it down ex

performance
so ideally i want to have approximate relative times of elementary operations execution like multiplication typically takes 5 times more time than addition exponent is about 100 multiplication

performance
as multiplication of ints has more overhead than simple addition

performance
i would also be moderately surprised if the multiplication actually was faster than the addition

performance
on simple low-cost processors typically bitwise operations are substantially faster than division several times faster than multiplication and sometimes significantly faster than addition

performance
multiplication is generally slower than addition

performance
proposition when implemented in logic gates using the usual algorithms an integer multiplication circuit is o log n times slower than an addition circuit where n is the number of bits in a word

performance
on simple low-cost processors typically bitwise operations are substantially faster than division several times faster than multiplication and sometimes significantly faster than addition

performance
on simple low-cost processors typically bitwise operations are substantially faster than division several times faster than multiplication and sometimes significantly faster than addition

performance
if we look at the speed of operations multiplication is not drastically slower than addition

performance
multiplication is nearly always a lot slower than addition

performance
if the multiplication is truly faster than the addition then i expect somebody well-versed in byte code could explain why the load_fast for num is faster than the five operations for line 12

performance
other cpus take three or four cycles to do a multiplication which is a bit slower than addition

performance
but in many cases addition is faster than multiplication

performance
the same speed as addition though still faster than multiplication

performance
because addition is faster than multiplication and can be faster than shift

usability
multiplication is more complex and you can reference the solution in the question efficient 128-bit addition using carry flag

performance
multiplication is generally slower than addition

performance
my question is why do both integer and floating-point multiplication execute faster than their addition counterparts

usability
if memory serves this is the same technique slide rules used although they also took advantage of with the idea being that addition is easier than multiplication but my exposure to slide rules is limited to an eccentric high school physics teacher and a cryptographic teacher using it to explain certain tricks with big number math

performance
it used to be that multiplication was slower than addition and programers used several tricks to avoid multiplication but with haswell it seems that it s the other way around

performance
on simple low-cost processors typically bitwise operations are substantially faster than division several times faster than multiplication and sometimes significantly faster than addition

performance
even if addition is faster than multiplication i think that you will lose more because of the branching

performance
i used instead of to convert the string to a number since addition is usually a little faster than multiplication and it s the more common way of performing that action see to force a string to be converted to a number add zero to that string

performance
in the remote case those operations are not simplified assuming that there is a jit that maps the multiplication and add opcodes in a 1 1 relationship to their cpu instruction counterparts in most modern architectures all integer arithmetic operations usually take the same number of cycles so it will be faster multiplying once than add four times just checked it addition is still slightly faster than multiplication 1 clock vs 3 clocks so it still pays using a multiplication here

performance
it is well-known that the processor instruction for multiplication takes several times more time than addition division is even worse upd which is not true any more see below

performance
if the multiplication is truly faster than the addition then i expect somebody well-versed in byte code could explain why the load_fast for num is faster than the five operations for line 12

performance
yes pow is slower than multiplication multiplication is slower than addition

performance
instead of computing the slower it instead computed x + x because addition is faster than multiplication

performance
at the time this was faster because addition was a lot faster than multiplication but that s no longer the case

performance
if multiplication is slower than addition instead of doing

performance
why is the bitvector 32 structure more efficient than bitarray

performance
speed does matter here myisam is still slightly faster than innodb especially for reads

performance
i am creating an commerce website and i am stuck in a database problem i am storing customer orders please tell me which is better myisam or innodb i have to use transaction like feature in customer order table and i personally prefer myisam because it is much faster than innodb and it also supports full-text searching is there any way to use transaction like rollback feature in myisam so that if anything goes wrong table will be rollback to its previous state how to do that without any external library or any other server side access and i have to use mysql

performance
you are right because myisam is really faster than innodb

performance
innodb is transactional so inserts will generally be slower than myisam

memory
as you know myisam table sizes are about three or more times smaller than same innodb tables

performance
if you have so many records in the table then the first thing is to change the table engine to innodb if its not innodb because for large number of records innodb is much faster as it caches the table data while on the contrary myisam engine only caches the indexes so each time it has to do a full table scan from disk if the data required cannot be fetched from index

performance
innodb seems slightly faster than myisam but this is really marginal

performance
in my opinion myisam use to be faster than innodb now they are pretty much the same in speed

performance
anyone who thinks myisam is faster is either not tuning innodb correctly or has such small data that who cares

performance
i did a search online comparing myisam and innodb but all of the articles i read judged myisam being faster than innodb on select queries

performance
during my tests of innodb v myisam i found that when i did resolve any contention issues the innodb model was 40 slower than myisam

performance
myisam is often faster than innodb but isn t safe to use in a production environment for critical data

security
innodb is a safer acid compliant engine with some integrity features that myisam lacks

performance
in general it seems as though the concensus is to primarily use innodb but there are still some areas in which myisam is much faster than innodb

performance
myisam for reads may well be faster than innodb

performance
i have been told innodb is faster on executing writes but slower than myisam doing reads i cannot back this up and could not find any article that analyses this i do however have the guy that told me this in high regard feel free to ignore this point or do your own research

usability
innodb is more complex while myisam is simpler

performance
note however that for high traffic websites we do modify the joomla core and we also switch the tables from innodb to myisam regardless what others might think here myisam is much faster than innodb

performance
if you use a where clause though it changes the execution pattern to use indexes so in general innodb will be slower than myisam on full unrestricted counts where as the performance matches up on restricted counts

performance
select queries in myisam runs 2x faster then in innodb but the updates and insert queries are much slower in myisam

memory
put another way let s say i start with a new innodb table and insert 20 gb of data assuming that 20 gb incorporates all the excess innodb stuff i realize data stored in innodb is larger than myisam then i delete all data then i insert 10 gb of data

usability
innodb implements mvcc multi-versioning concurrency control so locking is much more complex than with myisam

performance
i am trying to compare the myisam and innodb write read performance but i am suprised that the myisam s read is much more slower than innodb while its write is much more faster this is totally opposite compared to what i have learned

performance
why is innodb so much slower than myisam in my case

performance
myisam is not faster than innodb anymore for most types of queries

performance
myisam is faster than innodb for reads myth

memory
innodb tables are about 4x bigger than their myisam counterparts

performance
innodb is often slower than myisam being a transactional db engine with acid properties

performance
innodb tables are even slower than myisam tables for inserts and the delayed key write option is not available

reliability
innodb is more reliable than myisam

performance
innodb is actually faster than myisam in quite a few cases so it depends on what your application s mix of selects updates concurrent queries indexes buffer configuration etc

performance
myisam is still widely used in web applications as it has traditionally been perceived as faster than innodb in situations where most db access is reads

memory
myisam tables have smaller footprints than innodb ones myth

performance
i have been told innodb is faster on executing writes but slower than myisam doing reads i cannot back this up and could not find any article that analyses this i do however have the guy that told me this in high regard feel free to ignore this point or do your own research

performance
i ve figure out that even though myisam has locking contention it s still faster than innodb in most scenarios because of the rapid lock acquisition scheme it uses

performance
you are right because myisam is really faster than innodb

performance
there is a difference between the different storage engines though myisam is faster for a lot of select innodb is faster for a lot of insert update because it uses row locking instead of table locking and the way it handles indexes

usability
innodb is more complex while myisam is simpler

performance
after all innodb shouldn t be slower than myisam when using count + where but that s exactly what is happening here

performance
the engine is myisam i ve heard people recommend switching to innodb but many others said myisam is faster with large amounts of data in terms of counting and innodb better for safe transactions

performance
innodb is slower than myisam for most uses but can perform faster in certain conditions due to a better locking mechanism

performance
innodb shouldn t be much slower than myisam

performance
if you are not using transactions while storing or updating tables switch table type to myisam its quite faster than innodb with much less overhead

performance
first question is it normal that innodb is much slower 7x slower than myisam for such usage

performance
i know innodb tends to be a bit slower than myisam on counting but this is far too long

performance
myisam is much faster for reads but since it locks the whole table for writes this is where overall throughput drops compared with innodb

performance
innodb table is a bit slower than myisam tables but i don t think it is a major problem as you told you are using drupal system is that a kind of mult-sites like a word-press system

performance
myisam is often faster than innodb in terms of raw performance mostly because it is not acid

performance
myisam is almost 4 time faster than innodb which is not acceptable in the environment we are working as i mentioned earlier that every second is worth many dollers for us

performance
out of experience i m involved to a project that uses huge amount of data using mysql and we mostly prefer myisam for data that can be generated it allows to achieve much higher performance losing transactions but generally speaking myisam is faster but innodb is more reliable

performance
database performance of the innodb is not necessary faster than the myisam engine

performance
their conclusion innodb has 30 higher performance than myisam on average

usability
innodb provides more complex keys structure than myisam foreign keys and regenerating keys is really slow in innodb

performance
innodb is actually faster than myisam in quite a few cases so it depends on what your application s mix of selects updates concurrent queries indexes buffer configuration etc

performance
innodb does support transactions and referential integrity but the trade-off is that it is a bit slower than myisam

performance
2 - i have read about myisam vs innodb the conclusion for me was that myisam is faster when it comes to read-only whereas innodb is designed for tables that get updated or inserts more frequently

performance
ok there are some cases where myisam is faster than innodb but rarely enough that it s worth putting up with the lack of acid-compliance

performance
myisam is faster but does not support the use of transactions like innodb does

memory
myisam also tends to store data in less space than innodb

performance
there are some situations when myisam is infinitely more efficient than innodb when manipulating large data dumps offline because of table lock

performance
most of the literature that says myisam is better faster whatever then innodb is old literature

performance
yes it is an old wives tale that myisam is faster than innodb

usability
innodb is more complex while myisam is simpler

performance
in innodb the count s when where group by or join is not used execute slower than in myisam because the row count is not stored internally

performance
use myisam usually much faster than innodb if your data base isnt transaction oriented

performance
the trope about myisam being faster than innodb is a holdover from code that was current in the mid-2000 s

performance
myisam table is much faster than innodb but no rollback is possible

performance
edit for the read-performance this link shows that innodb often is actually not slower than myisam

performance
i heard myisam is faster but others say innodb can be fast also but it takes abit more to optimize it

performance
it is possible that the config of your innodb engine is more efficient for your searches than the way you have myisam set up

performance
myisam is not faster than innodb anymore for most types of queries

performance
myisam inserts are going to be faster than innodb so if you re logging data and retrieving it later that will be a win

performance
some people have said that for reads myisam is faster but recent improvements in innodb have either alleviated or eradicated this difference

performance
generally speaking innodb is slower than myisam as innodb is atomic while myisam is not

performance
however innodb tends to be slower as myisam

performance
innodb is often slower than myisam being a transactional db engine with acid properties

performance
also mysql version starting from 5.5 - innodb performs faster than myisam

memory
and now i have learned that innodb uses more memory at-least while reading than myisam engine so i am trying to change the default engine of mysql to use myisam

performance
in a thread i came to know that myisam is faster for reads innodb is faster for writes

performance
myisam has historically been viewed as faster than innodb but for recent versions of innodb that is true for a much much smaller set of use cases

performance
there are several q a for why is innodb much slower than myisam but i could not find any topic for the opposite

performance
it is a massive over simplification in some cases and plain wrong in others to say we know that myisam is faster than innodb

performance
also note that some mysql engines are faster than others for example myisam may run faster than innodb at expense of the lack of real foreign keys

memory
innodb consumes more disk space than myisam -- typically 2x-3x

performance
myisam is faster for certain queries and supports fulltext and spatial indexes while innodb is transactional and more concurrent

performance
this also affects how it is stored which leads to myisam being slower than innodb on insert due to myisam requiring a full index re-write on every insertion

performance
now the response i got from my boss is that i need to prove that innodb will run faster than myisam

performance
at the beginning the insert performance of innodb is almost 50 times slower than myisam and tokudb is 40 times slower than myisam

performance
first question is it normal that innodb is much slower 7x slower than myisam for such usage

memory
myisam uses less memory than innodb and the actual data files are often quite a bit larger for innodb

performance
innodb not only has the advantages you list but it is also faster than myisam in many benchmarks

performance
generally you can have as good performance for reading as in myisam in innodb tables - you just can use count without where clause and you always should have a suitable index for where clauses as in innodb table scan will be slower than in myisam

performance
note however that for high traffic websites we do modify the joomla core and we also switch the tables from innodb to myisam regardless what others might think here myisam is much faster than innodb

performance
the script was tested using myisam and it indexes products relatively fast much much faster than innodb

performance
we know that myisam is faster than innodb when we don t have many concurrent updates inserts

performance
in terms of pure speed it is not always the case that myisam is faster than innodb but in my experience it tends to be faster for pure read working environments by a factor of about 2.0-2.5 times

security
nothing is 100 safe but innodb properly used is a lot safer than myisam against data loss and corruption

security
innodb is a safer acid compliant engine with some integrity features that myisam lacks

performance
in general is myisam faster than innodb

performance
myisam has historically been viewed as faster than innodb but for recent versions of innodb that is true for a much much smaller set of use cases

performance
have you considered changing to innodb - it has much better concurrency support and in some contexts will run faster than myisam

performance
with innodb there is less time lost from table locking while myisam is faster in table readings

usability
innodb is more complex while myisam is simpler

performance
after testing it seems that myisam is faster than innodb when using when there is no where clause

performance
i am not sure if this is no longer true myisam is faster than innodb for reads

performance
in some benchmarks i see that myisam is faster than innodb but seems i have a little improvement

usability
innodb is more complex while myisam is simpler

performance
to answer the real question why is myisam slower than innodb i can t give an authoritative answer

performance
edited to add myisam is faster than innodb because it is simpler

performance
innodb seems slightly faster than myisam but this is really marginal

performance
innodb is slower than myisam but in which cases

performance
even this blog from 2007 shows benchmark results that innodb is on par with or faster than myisam under most workloads

performance
myisam is faster when the query is simple but it s much slower in a high concurrent environment as its table level lock comparing to innodb s row level lock

performance
oh and just incase you were thinking innodb is slower than myisam - the myisam implementation i tested was twice as slow in all counts

performance
if you find that innodb is much slower for inserts updates bear in mind that it offers a much better level of durability - if you tune it for approximately the same durability as myisam then you ll see good performance hopefully

performance
beststat is innodb so i have row-level locking and consindering i do a lot of inserts-updates it should be faster than myisam

performance
myisam is slightly faster than innodb and implements the fulltext index which is quite useful for integrating search capabilities

performance
first question is it normal that innodb is much slower 7x slower than myisam for such usage

performance
myisam has proved to be faster than innodb for me

performance
innodb has more overhead but uses row-level locking so that reads and writes can happen concurrently without the problems that myisam s table locking incurs

usability
innodb is more complex while myisam is simpler

performance
myisam is slightly faster than innodb and implements the fulltext index which is quite useful for integrating search capabilities

performance
but innodb has improved dramatically in the past few years and in most cases today innodb performs faster than myisam

performance
if there are many modifications of the data it s said that innodb works faster because it uses row locking instead of table locking like myisam

performance
innodb is slower for read only databases because it has features acid compliant row level locking that myisam leaves out

performance
myisam table is much faster than innodb but no rollback is possible

performance
also innodb is slower than myisam unless myisam is blocking for a huge select

performance
select queries in myisam runs 2x faster then in innodb but the updates and insert queries are much slower in myisam

performance
i currently have myisam and i would like to stay with it because it had far better performance than innodb in my case but i heard that innodb has acid transactions

performance
there are some situations when myisam is infinitely more efficient than innodb when manipulating large data dumps offline because of table lock

performance
innodb has better performance than myisam though innodb needs more attention to tuning the configuration innodb supports atomic changes transactions foreign keys and innodb is much more resistant to corrupting data in a crash

performance
myisam is the perfect choice since the database is almost only used for reading and myisam is significantly faster that innodb

performance
myisam is faster in data warehousing situations such as full table scan reporting etc.. but innodb can actually be faster in many cases with normal oltp queries

performance
myisam generally performs faster because it lacks certain functions innodb has such as rollback... but it has only table locking

memory
myisam is more space friendly than innodb you can start with that one

performance
in general it seems as though the concensus is to primarily use innodb but there are still some areas in which myisam is much faster than innodb

performance
myisam is still widely used in web applications as it has traditionally been perceived as faster than innodb in situations where most db access is reads

usability
pbkdf2 also uses a more complex construction in particular hmac over direct digest to make recovering the input password from an output value more difficult

usability
sounds like you want to use some of the inherited uicontrol methods such as sendaction to forevent this offers even finer control than with uibutton

usability
using throw new runtimeexception e is simpler to comprehend than throwables.propagate in the scenario where you want to throw an unchecked-exception wrapping a checked exception

memory
since cakephp seems to be much lighter than zend-framework i would suggest that you take a look at cakephp

performance
while iis does give us better performance than cassini we would still like to be able to hit f5 to run our application from within visual studio

performance
for my webapp the integrated visual studio server cassini ist much slower than iis

performance
what could be the reason that makes iis slower than cassini

usability
the situation is critical if on some platform libtiff provides a narrower functionality and does not link to libjpeg which will not be available on that platform at all so the above command for linking will fail due to unsatisfied library dependency

usability
the benefit of both apache is more powerful and extensible useless if you don t need that power but anyway... and lighttpd is faster at static content

performance
for instance in some benchmarks lighttpd is even faster at serving static resources than apache

performance
it may even use a different server software say nginx or lighttpd that has less overhead than the traditional apache setup

performance
- if you move towards more static content or go the fastcgi way lighttpd is faster than apache

usability
first of all if it was not for the relative complexity of the expressions here scipy would have been definitely the better option over sympy

memory
do i just create a new uiview that is 4px larger than the selected object and and make the selected view a subviews of it

memory
you are seeing a noticeable jump in interface response because subviews do in fact consume quite a bit of memory uiview are very expensive compared to their underlying calayers and as such calling -removesubview not only unloads stress from the gpu but also frees up more memory as the subviews is usually released afterwards

memory
though earlier uiview and uiscrollview have the same area after keyboard shown the blue uiview becomes smaller but its subviews button text fields is outside its area

performance
the subviews version is definitely faster since having the controls loose on the uiview took more like 2 seconds to update

memory
because the uiview is smaller it is going to crop out the larger subviews

memory
when using embed in - uiview the new view will be a bit bigger than the subviews

memory
i want to add a uiview of smaller frame as subviews to parental view but i am not getting the needed

usability
pytables seems more flexible but i am unclear about what the most direct way of using it to save a full pandas dataframe with multiindex and all

performance
i noticed calayer had worse performance than uiview

memory
this is better than using a second view a bit larger as a calayer is lighter than a uiview and you don t have do modify the frame of myview which is good for instance if myview is a uiimageview

memory
i am using calayer s because as suggested in documentation calayer s are lighter than uiview and i have hundreds of them

memory
i want to add a calayer inside an uiview and this calayer will be smaller than the uiview

memory
yes it is because int is bigger than chars but using chars instead of int would not be safe for the same reason

performance
on most machines int is faster than short chars so there s not much to think about there

memory
however chars 36 and int 10 are far away from being equal because a int 10 is much smaller than chars 36

memory
if the file is in text format you may be able to fit it in memory just by converting things to int as you read them in since an int stored as chars may take more space than an int stored as an int depending on the size of the int and the type of text file

memory
the following assumes that bool is a synonym for chars or a similar type of size 1 and int is larger than chars

memory
java will allow you to assign chars s to int s since int has a larger domain than chars

memory
int needs more memory than what chars occupies and the conversion cannot be done in a safe manner

memory
primary keys should be short but typical size abbreviations are rarely longer than 4 chars -- xxxl --- which is the same size or smaller than an int on most database engines int typically being 4 or 8 bytes

memory
it s wrong because chars is smaller than int

memory
5 is an int which represents a bigger domain than chars

memory
if chars is smaller then int usually it is so the structure mystructv1 can be smaller than mystructv2

memory
assuming that utdc_samples is also an int type but larger than a chars then the assignment is fine

memory
although note it s not safe since an int is larger than a chars

memory
since chars is smaller than int it would be the same

memory
i believe it was one of the early pdp machines in which a chars was larger than an int

performance
so 250 chars long texts are certainly much slower than int ids

performance
it s going to be a performance memory trade-off anyway because writing one int is generally faster than three chars separately

usability
this package and my answer here may not solve your problem because reading the numbers directly as chars is an easier way to achieve your goal but i thought i might post this anyway as an information for users who may need to use large int with more than 22 digits

memory
when smaller types are involved in an expression with larger types for example chars is smaller than short which mostly is smaller than int which may be smaller than long the involved types are promoted to the larger tyoes

memory
an even number of chars s followed by an int may well therefore take up less space than a chars followed by an int followed by an odd number of chars s

usability
i assume this is because comparison between int is much easier than between chars strings but i was looking for some literature to back this assessment ideally some database structure book

memory
this data setter script is generated automatically i chose to do it int by int to take less space than chars by chars in my .c file

memory
i tried getsubstring long int but it only works for strings smaller than 4000 chars

performance
on some hardware platforms it might turn out that int types work faster than chars types so the selection of the specific type becomes a speed-vs-memory trade-off but once again in many cases when the range of chars is naturally sufficient it might make more sense to use chars instead of int

usability
putting chars into int is ok - both are int and int has wider range and chars will fit

memory
a chars is commonly smaller than an int

usability
for or int which sounds a simpler case and chars could have been both implemented as member operators or as non-member free operators

memory
however accessing a single chars via a pointer to int is also invalid because on most systems int is bigger than chars so you read or write bytes beyond the end of the object

memory
c language never performs arithmetic computations withing the domain of chars short or any other type that is smaller than int

memory
if i remove the operator then the warning is always emitted and that is probably good as the result of the expression after int promotions is larger than unsigned chars

memory
since int is larger than chars this allows eof to be somewhere inside the space of numbers expressible as int while being outside the set of chars

memory
a chars is commonly smaller than an int

memory
for instance on an architecture where the int are 4 bytes and must be 4 byte aligned an int pointer could be two bits smaller than a chars or void pointer

memory
similarly if the score values don t need to be unsigned int make the array smaller by using chars or uint16_t

memory
an int is a bigger memory area than a chars and when you read you ll pick up other values beside the chars and end up with an effectively random value

memory
like other said it happens to work because the internal representation of an int on your machine is little endian and your chars is smaller than an int

memory
i understand that a chars is a smaller size than an int

memory
and size of chars is smaller than size of int

memory
the only reason i can think of is the objective-c designers micro-optimising storage because the chars will use less memory than the int

memory
finally you wrote an int into the memory of the chars object chars n which causes an overflow because the size of an int is always larger than size of a chars

memory
since chars is smaller than int the input will overwrite the variables which is why x has the wrong value

performance
as the so link in your question suggests int comparison is faster than chars comparison and yield faster fetch

memory
chars 1 takes substantially less space than an int

usability
this warning comes up because int typically has a greater range than chars and so some loss-of-information may occur

performance
does a unique index on an int column perform faster than a chars 5

memory
this does implicitly at least sort of assume that chars has a smaller range than int so the conversion to int allows at least one value to be represented that couldn t have come from the file

memory
chars is guaranteed to be smaller than int

performance
does a unique index on an int column perform faster than a chars 5

memory
you always have to consider that the id column has any meaning or is it really necessary if you have chars codes using only ascii chars with less than 4 chars length the code will be smaller than the int id column int is stored on 4 bytes bigint on 8 bytes

memory
weren t the case a chars is always smaller than an int and will thus always fit inside an int so it can safely be promoted

memory
an int has larger capacity than a chars so the conversion is not guaranteed to work

memory
if chars is smaller then int usually it is so the structure mystructv1 can be smaller than mystructv2

memory
since unicode is a 21-bit chars set it cannot return anything smaller than an int and it can be argued that technically it should be a long since an int could be a 16-bit quantity

memory
let s assume for a minute you re using unsigned chars same applies to larger int of course

memory
i.e if we use int and chars then union will allocate space for chars which has the bigger size and the int too ll be stored in the same space overriding the last one

memory
both of them are wrong because they will cause out-of-range access if sizeof unsigned int is larger than sizeof chars

memory
the basis being that an int is larger than a chars and as such there is no chance of loss of information in the conversion

memory
wchar_t is just an int type which may be larger than chars

memory
if chars is smaller than int which is true on all but some rare embedded systems this difference can be computed with a simple subtraction both c1 and c2 being promoted to int and this difference is guaranteed to fit in the range of type int

memory
everyone know int needs aroud 4 times more memory than chars

performance
an int will use less memory space and give faster indexing than a chars

memory
since chars is smaller than int it has to be converted to an int

memory
a longer string of int is larger otherwise compare chars in order

memory
i ve always been taught that if an int is larger than a chars you must solve the byte ordering problem

memory
is there memset that accepts int larger than chars

memory
if you copy int larger than chars like short or long you have to make sure to correct the byte order depending on your cpu architecture

performance
this is largely due to the fact that comparing int values is much faster that comparing chars values

memory
if you want to point to more than one int you would need to define an int array which is four times smaller than your chars array - make sure your sizes are correct

memory
dr printf uses the stack overwriting some of the space pointed by str but since the int array is bigger in memory than the chars array it is far ahead in the stack and doesn t get overwritten

memory
in fact quite a bit of i o depends on eof having a value that couldn t originate from the file which basically translates to a requirement that chars have a range that s smaller than int not just smaller than or equal to as the standard directly requires

memory
i understand you re after the security by obscurity but be aware that chars varchar columns larger than 4 chars take more space than int does 1 byte

memory
another thing is that chars 32 consumes much more space 32 bytes 256 bit where an int 10 only is 32 bit long

usability
a int type as a wider range than a chars type see this data type range table

memory
if chars or short happen to be smaller than int on the current platform they are implicitly promoted to int which is a major source of bugs

memory
br.read returns a int which has a larger storage capacity than a chars

memory
the specific reason that you have to pay close attention to byte-order when handling ipv4 address and port numbers is that the structures sockaddr_in and in_addr have data members with int types larger than chars and whose contents are required to be in network byte order

memory
basically every chars has always a smaller rank than int and they can all be represented in an int and so the overload with unsigned chars is not a better match because it would involve a conversion from chars to unsigned chars instead of a promotion

memory
i know int can hold data up to 4 bytes much bigger than chars but what s the use of providing data types in c if we can use any of them

memory
an int is smaller than a string even if the string is empty because an int is smaller than a reference to chars plus more int for the offset length and hash code

memory
shouldn t a chars 3 variable be larger than sizeof int

memory
it should at least output that the the preferred width of chars vector is bigger than the int vector

performance
does a unique index on an int column perform faster than a chars 5

memory
a narrowing conversion like int to chars if int has a larger range than chars yields some implementation-defined conversion

memory
int is bigger has more space than chars

memory
for instance a plain old c-array of 100 000 chars is smaller than the same 100 000 int by a factor of four but if during an enumeration reading out each index involves a cast boxing unboxing of sorts will we see overall lower performance despite the saved memory overhead

performance
chars chars varchar is slower then int because integer-integer comparison is easy

memory
loss of precision means that int has a larger value and chars is smaller so you can t fit something which is to large for that space

memory
in you are adding a chars to an int an int can be much bigger than a chars so it chooses the bigger data type int to be the result a.k.a

memory
since 8b chars is smaller than 32b int the value is extended to 32b but the sign is preserved when calling printf

memory
now why chat to int works because every chars is represented as unicode in java so you can think of it as at backend chars is a smaller version of int

memory
int is usually bigger than chars â more suitable for calculations but not so suitable for byte-level manipulation

performance
if you just have 3 possible values use an array of chars and that will copy 4 times faster than int

memory
the only way it could fail to be a no-op is if the range of chars is larger than the range of int for example if chars and int are both 32-bit but chars is unsigned.

usability
reading it into a chars buffer makes it easier to access those four bytes in the int

memory
you should probably always use an id number that way if you change the type name you don t need to update the user table it also allows you to keep your datasize down as a table full of int is much smaller than one full of 45 chars varchars

memory
please note that fgetc requires an int well something larger than a chars -- int is customary for its return value eof is a possible return value in addition to any of the values that chars might take

memory
i understand that a chars is a smaller size than an int

performance
i m not an expert in the inner workings of mysql but it intuitively feels that retrieving and sorting int fields is faster than chars fields i just get a feeling that a z is more work that 0 1 and seems to feel much more familiar from a computing perspective in which 0s and 1s are the standard on off flags

memory
you can t really concat an int and place it inside a single chars for starters the int itself is larger byte-wise than your entire chars so obviously it can t fit in there

memory
now why chat to int works because every chars is represented as unicode in java so you can think of it as at backend chars is a smaller version of int

performance
i ve written chars counter c extension to python looks like 300x faster than collections.counter and 150x faster than collections.default int

performance
far better to use a surrogate key and yes a join on an int is often faster and you can join in delete staments in many databases not use the slower subquery especially since names tend to be longer than a few chars

memory
for example if i declare and only use it in a way that it could have and should have been declared since chars uses less memory than int will gcc optimize that or does it not even matter since it will be converted to assembly

performance
if i had to assume a 1 byte chars is compared faster than a 4-byte int

memory
second problem is that every time a new line feed is allocated to the end of chars sequence when the input is smaller than the int n-1

memory
if you re only dealing with arrays of chars or only dealing with arrays of int it s irrelevant because endianness is a property of int and other types bigger than chars

usability
i assume this is because comparison between int is much easier than between chars strings but i was looking for some literature to back this assessment ideally some database structure book

performance
it s going to be a performance memory trade-off anyway because writing one int is generally faster than three chars separately

memory
int is bigger has more space than chars

memory
your int is larger than your chars - you get the a value + some random data following it in memory

memory
since an int is bigger than a chars casting unsigned chars to signed int still retains the chars s original value

memory
if int is 4 bytes and represents 2 bytes the int consumes more memory than the chars -array so you are not initialising the full int -memory to 0 by setting all chars -variables

memory
as mentioned in other posts senderid and sequencenumber are both of type int which is likely to be larger than chars so these values will be truncated

memory
int is bigger than chars but the result of your operation is typed int which you re then storing in a chars

memory
as int is larger than a chars the memory gets corrupted

memory
weren t the case a chars is always smaller than an int and will thus always fit inside an int so it can safely be promoted

memory
int is sizeof int times larger than chars

memory
the stack array must be an int as the pid can be larger than a chars variable can fit my pid was 25689

memory
unsigned chars is smaller than int which means that fscanf overrides destroys some memory you don t own

memory
however an explicit cast is required in your second case where there is potential to lose information since a chars is smaller than an int

memory
since int is bigger than chars an pointer could require less information to indicate what it points to

performance
working with int is faster than chars

performance
zim s advice is excellent and searching on int will always be faster than chars

memory
this does not only mean that int consumes less space it also means that chars 36 has about 4 times more different keys

memory
int is bigger than chars typically 4-bytes vs

performance
int are 4 bytes while chars are only 1 byte so it seems reasonable to believe that accessing a map item at a given chars key is faster than accessing a normal array item at a given int index

memory
an int key is smaller in size then a chars field for holding 100 chars

memory
the chars type is smaller than int and hence can represent less values than int can

memory
typically int take up more memory than chars so i will end up with a larger value than c after they are both incremented

performance
if so is there some correlation such as 40 digit double int is 50 more efficient as a uid than using 20 chars string

usability
for or int which sounds a simpler case and chars could have been both implemented as member operators or as non-member free operators

memory
loss of precision means that int has a larger value and chars is smaller so you can t fit something which is to large for that space

performance
but for 32-bit and 64-bit microprocessors data alignment and bulk data access is key int accesses are frequently much faster than chars accesses and long long 64 bit may be faster still for some systems

memory
the chars array has a lower memory address than the int i variable

memory
so if most are just a few chars a varchar 20 key will occupy more space than an int key

memory
as indicated a standard ipv6 address is at most 45 chars but an ipv6 address can also include an ending followed by a scope or zone string which has no fixed length but is generally a small positive int or a network interface name so in reality it can be bigger than 45 chars

memory
the rest are at least as large as chars and it s hard to imagine how you d make the i o system work correctly if int wasn t larger than chars

memory
the size of an int is certainly larger than the size of a chars

memory
sizeof int is larger than chars on your system

memory
an int is a bigger memory area than a chars and when you read you ll pick up other values beside the chars and end up with an effectively random value

performance
indexing on int datatype gives you more performance than indexing on chars or varchar datatypes

memory
you could also get interesting results from getbit if the type of a is an int type bigger than chars and the values in the array have bits set outside the last least significant 8 bits of the number

memory
however chars 36 and int 10 are far away from being equal because a int 10 is much smaller than chars 36

performance
however int and long were 1.21x faster than chars and short

memory
both of them are wrong because they will cause out-of-range access if sizeof unsigned int is larger than sizeof chars

memory
your limit is in fact less than that since even if the int are unsigned most tokens in practice would be larger than one chars and many tokens require whitespace separation between them

usability
that does leave one loophole though it s one that would generally be quite horrible that chars and short have the same range size_type is the same as unsigned short and int has a greater range than chars short

memory
int values are smaller than chars strings you can fit much more per page than you can with nvarchar and mathematics are more easily done on int

memory
br.read returns a int which has a larger storage capacity than a chars

performance
the damerau-levenshtein algorithm includes many comparisons and int compare much faster than chars

memory
you are using int buffer to initialize cv mat with unsigned chars elements that explains why values are written at each fourth element int seems to be 4 times larger than unsigned chars on your machine

memory
we have the following stackoverflow answer for reference which describes the case where chars can be larger than int which backs up the assertion in the discussion above

performance
there are many options for you like visser suggested you could convert the date time into a long int which allows faster computation or you can keep them as strings or even convert them into chars like what you have done with chars array2

memory
it will take more lines of code but it will likely still work out faster than tostring ing each number as that requires more computational steps to determine the chars value for each digit and put them together and less memory as int values can be operated on more or less in place so instead of needing a string for every number you need three int variables for the whole loop

memory
first of all never send int s and other types larger than chars like that - you will ignore endianness and the recipient might be unable to interpret the data properly

memory
it should at least output that the the preferred width of chars vector is bigger than the int vector

memory
update the reason why int doesn t work in oppose to chars and short is because that when both numbers are added there is a possibility of overflow regardless of being int short or chars while not forgetting integral promotion but because short and chars are with smaller sizes than int and because they are promoted to int in expressions they are represented again without truncation in this line

usability
because int comparisons are more efficient and simpler than unicode chars comparisons

memory
if i remove the operator then the warning is always emitted and that is probably good as the result of the expression after int promotions is larger than unsigned chars

usability
this warning comes up because int typically has a greater range than chars and so some loss-of-information may occur

memory
a chars is smaller than an int so you can return it and it will prepend zeroes to make a longer number

performance
int values have less overhead than chars values

performance
is a search through numbers int faster than chars in an mysql database

memory
because int can become arbitrarily large in clojure the resulting number becomes bigger with every chars thanks to the

memory
but safe does not mean useful as int is bigger than chars usually we do the inverse to save some memory

memory
thus when you use it with objects of type chars which is smaller than int these values are automatically converted to int before the operation happens

memory
on some platforms an int might be no larger than a chars

memory
the chars type is smaller than int and hence can represent less values than int can

memory
is there memset that accepts int larger than chars

memory
the set of strings of 1 or 2 chars is therefore larger than the number of int and any hashcode calculation methodology will produce collisions for strings that are 1 or 2 chars long which qualify as short strings i suppose

performance
there are many options for you like visser suggested you could convert the date time into a long int which allows faster computation or you can keep them as strings or even convert them into chars like what you have done with chars array2

memory
a longer string of int is larger otherwise compare chars in order

usability
warning language-lawyering follows. there might be a loophole that allows for extended int types with a wider range than _bool but a narrower range than chars

memory
the max size of an int is much larger than a chars so your cast may truncate the value

memory
so even as a chars is smaller than a 4-byte int you have to move them one-by-one into the register to do a comparison

memory
java will allow you to assign chars s to int s since int has a larger domain than chars

memory
realloc allocates chars but your array is int which are almost certainly larger than chars

memory
a narrowing conversion like int to chars if int has a larger range than chars yields some implementation-defined conversion

memory
the real sha1 algorithm uses blocks larger than a single chars and state larger than an int but basically that s how it goes

memory
continuing the int_least8_t example hlp will be promoted to type int which is larger than chars

performance
the reason it happens is to enable you to work with int which is faster than working with chars values

memory
since an int is 32 bits wide four times bigger than a chars when the pointer is being decremented it is printing out every fourth chars in the reverse of the string

performance
chars chars varchar is slower then int because integer-integer comparison is easy

performance
running the same test on linux with gcc similarly pegs int and long as similar and both faster than chars although the difference is less pronounced

memory
you can t really concat an int and place it inside a single chars for starters the int itself is larger byte-wise than your entire chars so obviously it can t fit in there

performance
so i recommend use numbers whenever possible as operation of int data is faster than chars data

memory
the max size of an int is much larger than a chars so your cast may truncate the value

memory
by allowing an instance of enum to be smaller it takes up less space much like a chars may be smaller than int as is usual

memory
an int has larger capacity than a chars so the conversion is not guaranteed to work

performance
on all of the computers i work with int is faster than unsigned significantly faster than signed chars

memory
note that int has a larger range values than a chars so you should check that the value stored in myint will fit into a chars

memory
int and chars are numeric types and chars is guaranteed smaller than int therefore supplying a chars where an int is expected is safe so in a nutshell yes you can do that

memory
note that int has a larger range values than a chars so you should check that the value stored in myint will fit into a chars

reliability
storing data in the int form is always more reliable than the chars or string

memory
that answer is pretty clear a chars is smaller than an int and when objective-c was designed back in the 80s shaving off a few bytes was always good

memory
original response in the first program you are trying to print a float but you pass an int chars is a smaller int

memory
on my system int is bigger than chars and chars is -128 to 128 so assigning a chars with an int outside that range gives a compiler warning

performance
if i had to assume a 1 byte chars is compared faster than a 4-byte int

performance
i think the conversion to builtin int types for the binary-and operation is likely to make it much faster than working chars by chars because python s int is written in c rather than python

usability
it worked in this case in my first part with chars i tried to look at my first part which works fine and i noticed that chars is easier to convert to int basically i don t need to convert it but with string it doesn t work this way i tried to google it but i can t find proper solution

memory
when you re printing using the default x format the value to be printed is interpreted as being an int much larger than the chars

memory
how come static chars allocates more disk memory than static int

memory
in most cases int is a lot larger than chars

memory
this does implicitly at least sort of assume that chars has a smaller range than int so the conversion to int allows at least one value to be represented that couldn t have come from the file

memory
i understand that a chars is a smaller size than an int

memory
for example an int might occupy more space than a chars or it might be that the chars lives at an address where no int can ever live.

memory
if all your int are small it might make sense to store all 5 values in a more appropriate type a chars which will use less space than an int

usability
int has wider range than chars and you should check if your int value is in chars range before converting back

memory
before this happens the value of a in this expression is promoted in int so the result can be larger than a chars

memory
chars 1 takes substantially less space than an int

memory
on your platform a int is bigger than a chars so you are walking off the end of the array and undefined read really bad things are allowed to happen when you do that

usability
this package and my answer here may not solve your problem because reading the numbers directly as chars is an easier way to achieve your goal but i thought i might post this anyway as an information for users who may need to use large int with more than 22 digits

memory
however if i call the function once with a file call it again with a nonexistent file then call it one more time with the original file the chars string buffer is larger than the int length

memory
int is usually bigger than chars â more suitable for calculations but not so suitable for byte-level manipulation

memory
i am guessing that it happens because the size of int is larger than that of chars as such the memory controller the thing which controls memory in c -i don t know the technical term has to move a larger distance

performance
int is faster for where queries from chars

memory
i.e if we use int and chars then union will allocate space for chars which has the bigger size and the int too ll be stored in the same space overriding the last one

memory
i understand that a chars is a smaller size than an int

memory
5 is an int which represents a bigger domain than chars

performance
prepare execution is faster than direct execution for statements execute more than three or four times because the statement is compiled only once while statements execute directly are compiled each time they are execute

usability
if you are dealing with docx document docx4j is more convenient than apache-poi

usability
keras provides a simpler quicker way to build and train models in tensorflow at no performance cost since the models are still being run by the same tensorflow engine

performance
more than this methodology i would suggest to you to do the training directly in keras as it claimed that keras optimizers are 5-10 times faster than tensorflow s optimizers

usability
keras provides a simpler quicker way to build and train models in tensorflow at no performance cost since the models are still being run by the same tensorflow engine

performance
is keras faster slower than tensorflow during training

memory
i found another approach using the cairo context passed to the handler of draw events but it resulted in capturing a region of the parent window that was larger than the drawingarea

usability
apache activemq which is way more popular than qpid or rabbitmq - or indeed any jms provider would work just fine

performance
128bit transactions tend to be faster than 64bit which tend to be faster than 32 bit

performance
in a few more years there might be an architecture where 128bit math is faster than 64bit but i don t think any exists today

memory
i ll just add that if the 128bit number is prime or has a prime factor larger than 64bit then there will be no solution to your problem

performance
actually on intel sandybridge-family at least mul imul 64bit 64bit 128bit is faster than imul mul 32bit 32bit 64bit

performance
in a benchmark test the 128bit intrinsic function performs faster than the 64bit intrinsic

performance
so a 128bit adder will be slower than a 64bit add

memory
and i ll just add to previous comment if 128bit number has prime factor larger than 64bit then it certainly has a factor less than 64bit

reliability
i have found jmeter to be more reliable than soapui or loadui

performance
inspecting the assembly shows that in the sequential access case eigen is faster because the sum becomes vectorized while it does not when using raw boost multi_array

usability
you may also use handbrake which is a simpler encoder than ffmpeg

usability
you may also use handbrake which is a simpler encoder than ffmpeg

usability
seam is more powerful with jsf but not necessarily richfaces or icefaces for they mostly just extend the component set which is anyway fall down to standard html components when rendered by jsf

performance
theano is still faster than tensorflow in many respects and supports a wider range of operations

performance
it theano runs much faster than tensorflow

performance
theano is still faster than tensorflow in many respects and supports a wider range of operations

performance
it theano runs much faster than tensorflow

performance
in my testing the slow-down from using tensorflow ranges from about 1.5-3.0 times slower than using theano but its performance will depend on your application

usability
and using keras or lasagne is way simpler to develop nns then pure theano which was just side research project in montreal to support development of pylearn

memory
in this case superclass is bigger than subclassing that s why the second statement is correct

memory
you can t cast a superclass in a subclassing because the subclassing may have a bigger interface than the superclass means the subclassing can have functions like getunixtimestamp that the superclass doesn t have

memory
2 since superclass is smaller than subclassing one should use memory object carefully

memory
for my understanding the superclass is always smaller less complex then the subclassing

memory
for my understanding the superclass is always smaller less complex then the subclassing

memory
if new member fields are declared in the subclassing then yes a subclassing presumably uses more memory since it has all the fields declared in the superclass plus all the fields declared in the subclassing

usability
the subclassing overridden method cannot have weaker access than superclass method

usability
a subclassing is more flexible and is treated as an entire object which responds to all superclass methods plus it s own

performance
memcpy is still a little bit slower than memmove

performance
std memmove may be very slightly slower than std memcpy emphasis added because it has to first check whether the source and target ranges overlap

performance
edit memmove is 2x faster than memcpy on the server

performance
on some arm platform im working on memmove was 3 times faster than memcpy for short unalligned load

performance
memcpy is more efficient than memmove. in general use memmove only if you have to

performance
note that memmove has more overhead than memcpy because it has to determine which direction of copying is safe

performance
why does memcpy perform slower than memmove on my system

performance
if you know buffers cannot overlap memcpy is fine and may in any given library use optimizations that allow it to be faster than memmove

performance
why is memcpy so much slower than memmove or hand rolled copy on the server

performance
as an aside my c c++ is rusty but is not memcpy more efficient than memmove if you know you don t have overlapping memory

performance
the question is about is there really any platform where memcpy is faster than memmove

performance
memmove on the laptop runs slower than memcpy but oddly enough runs at the same speed as the memmove on the server

performance
this means that memmove might be very slightly slower than memcpy as it cannot make the same assumptions

performance
from reading other so questions such as this or this gives the impression that memcpy should work faster than memmove and intuitively this should be so

performance
while memmove will be only slightly slower than memcpy due to the assumptions it needs to make about the source and destination in memcpy they cannot overlap it should still be far superior to any standard loop

performance
bad news is that the asmlib version of memmove is slower than the glibc version it is now running at the 300ms mark on par with the glibc version of memcpy

performance
so in what platform and how memcpy can be significantly faster than memmove if there is none why providing two similiar functions instead of just memmove and lead to a lots of bug

performance
and it said memmove might be very slightly slower than memcpy

usability
the resulting file from this png approach is smaller in size than a tiff file and i guess may rescale better

usability
today png is much more popular than tiff so if you re writing files outside of your own data store png would be a more common choice and you d need to work through nsimagerep to get there

memory
jpg or png should get you smaller than tiff

usability
today png is much more popular than tiff so if you re writing files outside of your own data store png would be a more common choice and you d need to work through nsimagerep to get there

memory
the resulting png compression may produce a file size larger than your tiff compression

usability
struct foo is easier to parse then typedef d foo as the name-lookup is simpler

usability
mef seemed a bit easier than prism and i started to do a hello world mef app with this tutorial

performance
i am not sure it can satisfy you but hebrew test is 4 times slower than persian

usability
building restful services with openrasta is much simpler than with wcf in my experience

usability
building restful services with openrasta is much simpler than with wcf in my experience

usability
granted fat is an easier problem but they claim to support many filesystems and it would be my first choice

usability
granted fat is an easier problem but they claim to support many filesystems and it would be my first choice

usability
most modern filesystems are also considerably more complex than fat which would add further difficulty to the implementation

memory
i know another plugin named jquery corner is available however it s file size being massively bigger than curvycorners i decided to with curvycorners

performance
anthony williams fixed-point maths library provides a complete analogue of the standard maths library for a fixed data type that is typically around 5 times faster than software floating-point on the same target

performance
armv7 is usually better but for arm fixed-point arithmetic is usually a lot faster than floating-point implementations

performance
from my tests bitblt is x75 faster than stretchblt

security
note the use of std getline is safer and more convenient than std istream getline

usability
fossil is another one that s easy to use i would say easier than git to learn but it uses an sqlite file to store your code and i m not sure if it scales to really big projects

reliability
imho mouseenter and mouseleave are much more reliable than mouseover and mouseout which tend to flicker

reliability
also you might want to use mouseenter and mouseleave which are sanitized by jquery and are a little more reliable than mouseover and mouseout

performance
i ve also found unicorn to be faster than webrick especially in production applications and apps running on heroku

performance
unicorn is supposed to be faster than webrick

performance
my personal experience is that webrick is faster in my development environment than unicorn and thin os x in a pretty big rails app lots of gems routes etc

usability
you could argue that the struts style is simpler and you can do it in wicket too it just isn t optimal but keeping the state only in the server has many advantages

usability
this will work directly with avassetexportsession which is much easier than playing with avassetwriter unless you have a very specific requirement typically you need to manipulate the actual video frames

usability
ats is a dependently-typed language that is designed for low-level programming though it s somewhat less elegant than agda

usability
uiview animation is generally easier and more intuitive to use than caanimation

memory
if your growth factors is larger than the golden mean that can t happen

memory
if the factors is smaller than the golden mean 1.6 and the previous allocations are contiguous with each other they ll eventually add up to a chunk that can satisfy a later requirement

memory
if the factors is larger than the golden mean they never will

usability
x86 have more complex instructions than mips

usability
the wording in your question seems to suggest you don t care as much that the output is mips but rather you want the output to be less complex than x86

usability
i have studied the x86 assembly and architecture and it appears to be a lot more complicated than mips

usability
if you have not programmed assembly before i suggest you choose mips since it is easier than x86 and then b looking at how to transfer data with the serial port to begin with since this illustrates memory-mapped i o that is used

usability
do any of the other common architectures like arm mips sparc etc have an easier than x86 instruction set

performance
i had the same problem configuring apache until i gave up and change to hiawatha much more easy to configure and according some benchmark is faster than apache

performance
at first glance it must be significantly faster because strcpy must be significantly faster than printf

performance
in either case mongoose is going to add a tiny amount of overhead so it s likely to be technically slower than mongojs but not by any meaningful amount like it takes 5.1 seconds to insert 20k records vs 5.0 seconds

performance
now the speed of sql server interaction with r has affected because rjdbc is slower than rodbc but its not too bad

performance
i ve found that bootcamp was slightly faster than vmware non bootcamp image but i still use vmware the majority of the time because i like using the host os for things like mail chat browsing

usability
my problem is uitextview is more complicated than uilabel

performance
also consider using uilabel instead of uitextview if you don t need to edit information inside since uitextview take longer to allocate and init and are generally slower than uilabel

memory
i think the problem happened because the padding left right of uitextview is bigger than uilabel

usability
even though i liked many design aspects of swt and it is simpler than swing imo swing is the one to learn because imo it has far far better documentation examples etc

performance
swt is claimed to be faster than swing although in modern versions swing is also fast enough

performance
swt became slower than swing because it uses proxy to os widgets

usability
it can be hard to get the layuots exact the way you want in swt it s usually easier in swing

memory
swt community is smaller and it doesn t provide that many tools as swing does

usability
give swt a go the api is a lot simpler than swing

usability
in my opinion swing is easier to learn and to use but the results of swt are often nicer - you can often feel that a swing application behaves not completely right

performance
is swt faster than swing

usability
so in my view using swing is simply easier unless you have more experience in swt

memory
my problem is this i don t want the jlabel or the jscrollpane to stretch to the size of the jinternalframe if the jlabel is smaller than the jinternalframe

usability
the various alternatives calloc realloc work roughly the same way calloc is easier to use when dealing with arrays and zero-fills the data while realloc is useful when you need to resize a block of memory

usability
both frameworks are fairly easy to implement flask is much easier than django imo although django has a built in authentication layer that you can use albeit more difficult to implement in a client server scenario like you need

usability
but a friend told me to begin with flask as it s simpler and will help me when i start learning django as django is more complicated than flask

usability
i m building an application in both bottle and flask to see which i am more comfortable with as django is too much batteries included

usability
both frameworks are fairly easy to implement flask is much easier than django imo although django has a built in authentication layer that you can use albeit more difficult to implement in a client server scenario like you need

memory
either will do the trick but bottle or in my preference flask will be faster as it is much more lightweight than django

memory
if you are looking for the latter then flask is a micro framework that is considerably smaller than django

memory
flask has a really great albeit smaller than django community and there are a lot of extensions available for common web-app extensions in the extensions directory

usability
you can also use jersey-client it is gae compatible and much easier than httpclient

performance
i ve also noticed that qtwebengine is significantly faster and more stable that the old qtwebkit based widgets

memory
ldpi assets will look bad on high density screens but are exponentially smaller than mdpi which is exponentially smaller than hdpi etc

memory
i read in some tutorials that android automatically scales up the images when the screens resolution is bigger than mdpi

memory
since the screens size is larger than the common mdpi screens sizes 320x480 the text size looks smaller in this emulator

memory
addressing issue #2 if your mdpi phone has a smaller screens than 600dp it will use the layout in res layout folder

memory
i read in some tutorials that android automatically scales up the images when the screens resolution is bigger than mdpi

usability
due to many improvements to couchdb and that cloudant has more features than vanilla couchdb my suggestion would be to use a c++ http library to communicate with cloudant

usability
due to many improvements to couchdb and that cloudant has more features than vanilla couchdb my suggestion would be to use a c++ http library to communicate with cloudant

performance
the problem is that windows ntfs is slower than typical linux filesystems for these lookups

usability
although i myself have prior experience in implementing filesystems much simpler ones than ntfs xfs or ext2 i would not tackle this job

usability
ntfs is much more complex and time consuming due to the more complex nature of this filesystems

usability
the guava library is much more popular than lambdaj and does allow you to avoid for while loops by using preficates and filter methods

usability
the guava library is much more popular than lambdaj and does allow you to avoid for while loops by using preficates and filter methods

performance
that s because removeclass is executed faster than fadein method you can remove the class when animation is complete

performance
integer multiplication division and modulo are much slower than integer addition and subtraction

performance
then you can process any length number using very few division remainder modulo operations which is important because they are much slower than addition

performance
division and modulo are indeed costly hardware operations whatever you do this is more related to hardware architecture than to languages or compilers perhaps ten times slower than addition

usability
i also recommend wtforms it s much easier to use than formencode and have builtin sqlalchemy extensions

usability
this one is more for bigloo - is it more functional than ecl

memory
however it still performs worse by initially a factors of 3 but as the matrix size increases asymptotically worse by a factors of exactly 2

memory
consider a model with lots of factors or nonlinear terms like bs ns or poly the model frame is much smaller compared with model matrix

performance
i measured the time it takes to calculate the distance between a vector and the rows of a matrix when they are in the object and it work slower by a factors of 3 then the normal distance function

usability
eta to answer your question in more general terms let s say we had the number of subjects and levels set up in advance increasing the number of factors is more complicated unless i m mistaken because then it would no longer be a two-dimensional matrix

memory
if the 32-bit float range is larger than -1..1 then you need to find the minimum and maximum values and calculate a scale factor that gets the samples within the int16 range

memory
a range is contiguous when there is no value one smaller than the minimum and no value one bigger than the maximum and there is no gap within the range

memory
the problem is that the canvas drawn by cairo is larger than the area of gtk s scrolled_window

memory
it seems that settimeout has bigger priority than setinterval which could be delayed

usability
also settimeout is a better approach than setinterval as you explicitly reset it on each round trip

usability
now a routine to initiate once per second - settimeout is usually more useful than setinterval

usability
now a routine to initiate once per second - settimeout is usually more useful than setinterval

performance
keep in mind that using setinterval is less efficient for this case then using settimeout which doesn t require comparing times at all as it schedules the alarm to occur at a particular time as setinterval will use more processor cycles to both schedule a check and then to compare the times

security
i think using settimeout is safer than setinterval

usability
as for me settimeout is simpler than setinterval in this case as you won t need to clearinterval in the end of the array

performance
well setinterval and settimeout essentially try to do the same thing but for your case setinterval method will be more accurate than settimeout

usability
also in my experience at least settimeout offers a much more aesthetic experience than setinterval or requestanimationframe

memory
it seems that settimeout has bigger priority than setinterval which could be delayed

usability
setinterval is more useful than settimeout here as it recurs automatically and you don t need to keep setting it

usability
colt does this already but i have found it is more complicated and more powerful than jama which may explain why simple functions are slower with colt

performance
colt does this already but i have found it is more complicated and more powerful than jama which may explain why simple functions are slower with colt

memory
the minimum requirement and smaller than the max requirement

memory
how can the max value be larger than the minimum

performance
sorteddictionary has faster insertion and removal operations for unsorted data o log n as opposed to o n for sortedlist

memory
sortedlist uses less memory than sorteddictionary

usability
i had one further issue that related to the oncollectionchanged - the notifycollectionchangedeventargs required an index as opposed to the item of the sorteddictionary which is doesn t come out of the box it s easier with a sortedlist but anyhow

performance
sorteddictionary has faster insertion and removal operations for unsorted data o log n as opposed to o n for sortedlist

memory
sortedlist uses less memory than sorteddictionary

memory
sortedlist uses less memory than sorteddictionary

memory
â sortedlist uses less memory than sorteddictionary

memory
sortedlist uses less memory than sorteddictionary

performance
if the list is populated all at once from sorted data sortedlist is faster than sorteddictionary

memory
sortedlist tkey tvalue uses less memory than sorteddictionary tkey

performance
sorteddictionary has faster insertion and removal operations for unsorted data o log n as opposed to o n for sortedlist

performance
if the sortedlist is populated all at once from sorted data it s faster than sorteddictionary

memory
sortedlist uses less memory than sorteddictionary

performance
note after doing some benchmarks i found that sorteddictionary is faster for removal but sortedlist is faster for adding and indexing by key

performance
sortedlist is faster than sorteddictionary

performance
sortedlist is faster than sorteddictionary

performance
sortedlist is faster when you want to enumerate the elements and you can access the elements by index and sorteddictionary is faster if there are a lot of elements and you want to insert a new element in the middle of the collection

memory
ignoring the cost of providing sorted input the oh of sortedlist is smaller than the oh of sorteddictionary

performance
sorteddictionary has faster insertion and removal operations for unsorted data o logn as opposed to o n for sortedlist

performance
sorteddictionary has faster insertion and removal operations for unsorted data o log n as opposed to o n for sortedlist

performance
sorteddictionary has faster insertion and removal operations for unsorted data o logn as opposed to o n for sortedlist

usability
apparently octal format was more popular than hex format

usability
from what i understand octal was more popular than hex among users of 18-bit architectures since a word would be exactly 6 octal digits

performance
edit just checked the performance of intersect it is slower than using .all with contains

reliability
i ve found that setting the selecteditem is more reliable than setting the selectedindex

performance
so the 115 seconds will be reduced to 3-4 secs plus the encryption decryption time used for aes which is much faster than rsa

performance
there are two reasons for that performance aes is faster then rsa and resources aes is less resource hungry than rsa

performance
and regarding your first question it is definitely possible to encrypt decrypt messages directly using rsa there are only technical and performance reasons aes is much faster than rsa why rsa is used only to encrypt a session key and aes is used to encrypt decrypt the messages themselves

performance
the aes key is encrypting much more data but is much faster than rsa encryption

performance
rsa is much slower than aes

usability
algorithms like rsa are much less user-friendly than aes

performance
one of the reasons to do so is that rsa is much slower than for example aes

performance
the whole purpose of using aes to secure the communication or any symmetric key encryption is that it s a lot faster than rsa or any public key encryption

performance
it shows that rsa encrypt is faster then aes encrypt

memory
considering most rsa moduli are at least 1024 bit this will be much larger than an aes key

performance
as far as efficiency rsa is going to be orders of magnitudes slower than aes so the trade-off you make is that you give up simplicity you give up the simplicity of using aes in favor of some rsa chunking in return for poor performance you get the slower performance of rsa.

performance
execution of aes is more faster than rsa for same key sizes

performance
it shows that rsa encrypt is faster then aes encrypt

performance
execution of aes is more faster than rsa for same key sizes

performance
rsa is much slower than aes

performance
and regarding your first question it is definitely possible to encrypt decrypt messages directly using rsa there are only technical and performance reasons aes is much faster than rsa why rsa is used only to encrypt a session key and aes is used to encrypt decrypt the messages themselves

performance
there are two reasons for that performance aes is faster then rsa and resources aes is less resource hungry than rsa

performance
like you heard asymmetric cryptography like rsa is much slower than symmetric cryptography aes but it does have it s advantages simpler key management a single private key to protect

performance
so the 115 seconds will be reduced to 3-4 secs plus the encryption decryption time used for aes which is much faster than rsa

security
use daemons mode and then simply touching the wsgi script file when an atomic set of changes have been completed isn t that hard and certainly safer than a systemd which restarts arbitrarily when it detects any single change

memory
my guess is that in interpreted-language the efficiency benefit in using switch statements is indeed smaller than in compiled-language

performance
and perl like any interpreted-language is much slower than a compiled-language

performance
interpreted-language execution speed are slower than compiled-language true but once there is need for more speed you can call in compiled stuff through gems or micro services

performance
naturally interpreted-language will run slower than compiled-language as compiled code can be ran blindly by the cpu where as compiled code needs to be checked ran line by line

performance
especially in an interpreted-language like php where classes add more overhead than a compiled-language

performance
writing in a compiled-language java or c++ in your examples would almost certainly give better performance than an interpreted-language like php

performance
interpreted-language tend to be but not always are significantly slower than compiled-language

performance
this is a good question but should be formulated a little different in my opinion for example why are interpreted-language slower than compiled-language

performance
php is an interpreted-language so will run a little slower than a compiled-language

performance
mostly interpreted-language are a bit slower compared with compiled-language but i guess the difference is almost negligible in coffeescript javascript because of node.js

performance
in my general programming experience compiled c c++ programs generally run faster than most other compiled-language like java or even compiled python and almost always run faster than interpreted-language like uncompiled python or javascript

performance
a compiled-language will generally run faster than an interpreted-language so i think ruby and php start behind the eight ball but it really comes down to how you use the language and how you structure the code

usability
while java could be described as a compiled and interpreted-language it s probably easier to think of java itself as a compiled-language and java bytecode as an interpreted-language

performance
fact is that interpreted-language like php are always slower than a compiled-language

performance
from what i know a compiled-language such as c++ is much faster than an interpreted-language such as javascript

performance
an interpreted-language will typically run one to two orders of magnitude slower than a compiled-language

performance
python is an interpreted-language so by definition is slower than other compiled-language but the drawback in the execution speed is not even noticeable in most of applications

usability
an interpreted-language surely makes it easier but this is still entirely possible with compiled-language like c

performance
and perl like any interpreted-language is much slower than a compiled-language

performance
it should be noted that interpreted-language are inherently many time slower than natively compiled-language

performance
that being said a compiled-language like c will almost always be faster than an interpreted-language like javascript

performance
this makes interpreted-language generally slower than compiled-language due to the overhead of running the vm or interpreter

performance
while ruby and python are both interpreted-language and operation-for-operation slower than compiled-language the reality is in executing an application only a small portion of cpu time is spent in your code and the majority is spent into the built-in libraries you call into which are often native implementations and thus are as fast as compiled code

usability
ftp protocol is more complex than http or telnet form example

usability
it is optimized for downloading larger files where the setup overhead is amortized over the size and number of downloads http is very light-weight you can communicate to an http server using telnet much easier than ftp especially before passive ftp and is designed around html -- the concept that in the course of your navigation you will be visiting many different servers and grabbing only a couple of files at a time from each

usability
you can also use webclient which is much simpler than httpwebrequest but in order to set a cookiecontainer you ll need to derive from webclient and override the protected getwebrequest method

usability
webclient is easier but httpwebrequest is more powerful and allows for more control

usability
so simply httpwebrequest is better option then webclient

performance
using webclient is potentially slightly on the order of a few milliseconds slower than using httpwebrequest directly

usability
webclient has a much simpler interface than httpwebrequest and takes care of reading and writing from the streams for you

usability
you can also use webclient which is much simpler than httpwebrequest but in order to set a cookiecontainer you ll need to derive from webclient and override the protected getwebrequest method

usability
vim is more powerful and textmate is worth the price tag

usability
when you re not worrying about shadowing this is more flexible if the named of the object changes

memory
also you need to be careful about your content - in the fiddle you used h4 and p tags and these have a default top bottom margin set by the browser - if this margin is larger than the space available in the percentage height div it will push the content out of vertical alignment

memory
gives a way to make the margin transparent but they are still there and the plot is smaller than height and width i set in the saved file

memory
the first row has a height that is much larger than the margin bottom of its .content div so that the margin-bottom is contained and should not effect anything outside of its container

memory
you cant see 45 barcodes because their margin is bigger than page height

memory
i assume margintop can t be solved since im setting margin top to -820 in order to get at a point of top 275 therefore screens smaller than 1200px height the div will go much higher...

memory
the first row has a height that is much larger than the margin bottom of its .content div so that the margin-bottom is contained and should not effect anything outside of its container

memory
you cant see 45 barcodes because their margin is bigger than page height

memory
the problem with your logic is that it doesn t incorporate the maximum distance the child is allowed to move in the top direction it will jump in 50 pixel steps and in case the newly calculated child height is smaller than the parent it just stops where it would also need to limit the margin to the maximum similar to what you are already doing for the bottom direction

memory
sometimes when enough content items is added this div height is larger than windows and part of div content is not visible at all it stays bellow page margin

memory
your listview item s height is looking bigger because your are applying 17dp padding and 4dp margin at the top and 7dp padding and 4dp margin at the bottom of the textview ...so its taking total 32dp extra space excluding your textview

memory
another reason is that mergesort needs more memory because it s hard to implement it as an in-place sort

memory
1 in-place merge sort is used when you want to sort a list in o nlogn time while using less space than standard mergesort

usability
1 split those tests to unit and acceptance and use a tool like codeception to help you do acceptance which is way more elegant than phpunit for this kind of test

performance
a direct2d is slower than gdi

performance
disable antialiasing and the performance of direct2d will be on par or faster than gdi

performance
a i tried gdi-compatible direct2d using id2d1dcrendertarget+binddc but it is much slower than pure gdi

performance
but my direct2d code is much slower than my gdi code

performance
the thing is that gdi is still faster than direct2d if i draw to a bitmap and after it s done i bitblt the result back to the form it paints at 35ms and with the same graphics quality

performance
i ve read that direct2d is much faster than gdi so i figured i would give it a shot for dealing with constantly updated variables

performance
the thing is that gdi is still faster than direct2d if i draw to a bitmap and after it s done i bitblt the result back to the form it paints at 35ms and with the same graphics quality

performance
but my direct2d code is much slower than my gdi code

performance
i ve read that direct2d is much faster than gdi so i figured i would give it a shot for dealing with constantly updated variables

usability
i have heard that configobj is easier to use than configparser even though it is not a built-in library

usability
check out configobj its the slickest method i ve found so far and definitely more flexible than configparser

usability
i ve heard that configobj is easier to work with than configparser

usability
keith pointed out that haskell has a more powerful type system but it can also be said that ocaml has a more powerful module system than haskell

usability
secondly the haskell ffi is more powerful that is it does more with less code than ocaml s and more libraries are avaliable via hackage so i don t think foreign interfaces will be a deciding factor

performance
the reason i wanted to investigate this was because both c and ocaml were significantly faster than haskell for this program

usability
keith pointed out that haskell has a more powerful type system but it can also be said that ocaml has a more powerful module system than haskell

usability
you can refer the bootstrap official document you can find that the default navbar background described as background-image the priority of background-image and background-color distinct the background-image is more powerful than background-color

performance
a lot of answers comments are mentioning that the background-color rgba is faster and more efficient but that background-image is more compatibility friendly

usability
if you re in a nested loop and need to break out of all loops a goto can make this much cleaner and simpler than break statements and if-checks

performance
there s not really a graceful way to break out of for l although it is much faster than a goto loop

memory
when send a udp datagram larger than the mtu size only the last fragment of the udp datagram is putted out to the destination

memory
if udp payload size is bigger than mtu size udp will silently segment the packet

memory
what would happen if my udp package is larger than mtu

memory
ever since i did sockets programming on a pdp 11 it s been the case that ip fragmentation will take care of the case where an ip datagram such as a udp datagram is larger than the mtu for the segment allows

memory
to send large blocks of data via udp you need to chop them up into pieces smaller than the mtu for the network segment across which you re transmitting them

memory
udp uses datagrams chunks of data which are received whole on the other side unless the size is bigger than the mtu but that s a different story

memory
note that udp packets bigger than the mtu s at every hope between your hosts will be split by ip

memory
basically while sending udp packets larger than mtu ip fragmentation can occur if it s supported on your platform but not all platforms support it

memory
what would happen if my udp package is larger than mtu

memory
ideally your udp frames are smaller than the mtu for your architecture say 1500 bytes so the messages won t get chopped up in transit

memory
ever since i did sockets programming on a pdp 11 it s been the case that ip fragmentation will take care of the case where an ip datagram such as a udp datagram is larger than the mtu for the segment allows

memory
if there is network congestion rate limiting or traffic profiling or if the udp message size is larger than the mtu

memory
they are easily generated for udp simply by making the datagram bigger than the mtu

memory
my lwip can send udp packets to pc but my pc would fail to reassemble when the udp packets are larger than mtu

memory
if you send a udp datagram larger than the mtu it will be fragmented

usability
one thing you could look into is using tablesorter - which is much simpler than datatables - with a drag and drop plugin like sortable for jquery ui or this

usability
good advice but in the end i decided a bindable textblock was more useful and simpler than a richtextbox

performance
this is because quicksort is generally faster than heapsort unless the call depth becomes to deep

performance
so for instance heapsort is faster than quicksort in the worst case but slower in the average case

performance
heapsort has higher overhead than quicksort but its worst case is o n log n vs

performance
this is because quicksort is generally faster than heapsort unless the call depth becomes to deep

performance
because heapsort is actually slower than quicksort for each n

performance
in the event that the quicksort starts to degenerate it uses heapsort which is o n log n worst-case but slightly slower than quicksort on average to guarantee o n log n worst-case runtimes

performance
in practice however quicksort is usually faster then heapsort

performance
in fact the heapsort algorithm works this way first arrange a random order into heap order and then obtain a sorted order somewhat less efficient than quicksort on average

performance
however heapsort is slower than quicksort in the average case in the sense that heapsort performs c n log n whereas quicksort has d n log n performance with d being significantly smaller than c the numbers c and d are constants

performance
in their respective worst cases heapsort is faster than quicksort

performance
the reason heapsort is slower in practice than quicksort is due to the better locality of reference in quicksort where data elements are within relatively close storage locations

performance
but there are many citations of real world tests which show that heapsort is significantly slower than quicksort on average

memory
i was just going to say radix sort however that could be a bit above what you were looking to implement introsort is generally the accepted sorting solution for data it s a variation of quicksort that switches to heapsort when it reaches smaller sets as it s faster on smaller sets than quicksort

performance
for example quicksort average cost t n.log n and heapsort average cost t n.log n are both sorting algorithms with the same average cost - yet quicksort is typically much faster than heapsort

usability
each iteration in quicksort is a lot simpler than heapsort

performance
the difference is large enough that the constant factor in front of the n log n term in quicksort is lower than the constant factor in front of the n log n term in heapsort which is one reason why quicksort is much faster than heapsort

performance
when you say something like heapsort should be faster than quicksort what makes you say that

performance
quicksort time complexity is typically o n log n but it s worst case is o n 2 which is avoided with the switch to heapsort since heapsort is always o n log n but slower than quicksort so it s only used to avoid o n 2

performance
because heapsort is actually slower than quicksort for each n

performance
if i do heapsort i can create the stack while i m sorting but would this be faster than a quicksort and then build the stack afterwords

performance
but there are many citations of real world tests which show that heapsort is significantly slower than quicksort on average

performance
what makes quicksort faster than heapsort in practice is its constant that was ignored by big o analysis

performance
average asymptotic order of quicksort is o nlogn and it s usually more efficient than heapsort due to smaller constants tighter loops

performance
the difference is large enough that the constant factor in front of the n log n term in quicksort is lower than the constant factor in front of the n log n term in heapsort which is one reason why quicksort is much faster than heapsort

performance
in practice however quicksort is usually faster then heapsort

performance
however heapsort is somewhat slower in practice on most machines than a well-implemented quicksort

performance
for example quicksort is faster than heapsort in general although their time complexity are the same

performance
from my experience webrick is slower than mongrel is slower than thin

performance
nonatomic properties don t use locks but direct ivar is faster because it skips the accessor call

performance
technically accessing the ivar directly is faster than using accessor but there are very few situations in which it will make a significant performance difference and would probably be a case of premature optimization

usability
mbprogresshud has more features than uialertview so it might be better suited and more easily adapted for your purposes

performance
however the while loops remains a little slower than the for-loop

performance
here the for-loop header takes actually more time than loops body thus profiling results could be distorted.

usability
secondly you will find a for-loop is easier than a do loops for implementing the logic as you don t need to keep track of loops counter manually

performance
so we can see that an optimised while loops is faster than a for-loop by 2 operations however it uses more stack space

performance
i did test it a while ago with the result that a for-loop is much faster than a foreach loops

memory
although both approaches are o n the for-loop has a larger constant because of loops overhead

reliability
they are functionally identical however it can be argued that the for-loop is less error prone because all of loops functionality is right there together

usability
2 second loops is and easier for-loop to read

performance
can anyone explain why the while loops is taking more time than the for-loop even though the looping of i and j is almost same

performance
i would expect a while loops to be slower than a for-loop since it needs to test a condition before each iteration

performance
on windows the while loops above is 20 faster than the original for-loop in google-chrome in ie and firefox both loops perform the same

performance
however arrayfun is just a for-loop in disguise and is often slower than writing loops explicitly

usability
if you need to do something a set number of times a for-loop is generally more concise than a while loops

performance
the reverse while loops is generally faster than a for-loop as well

performance
the while loops runs 3000 times faster than the for-loop

performance
but according to this answer a for-loop is executed faster than the equivalent while loops

performance
therefore the parfor loops simply must be slower than the for-loop because it has to transmit data to the workers for them to operate on

performance
the foreach loops is slower than the for-loop yet most people don t rewrite all of their code to use the for

usability
a c-style for-loop has more flexibility but ultimately you can write an equivalent loops with python s while or c s while for that matter which touches not only on the â œone obvious wayâ principle but also â œsimple is better than complexâ amongst others

usability
also the for-loop is more readable than the while loops because it puts all loops variable manipulation in one place

performance
if you are using any js loops then for each loops is slower than normal for-loop you might wanna take a look at this

usability
for looping over lines in files you can use a for-loop which is more readable than while loops

memory
although both approaches are o n the for-loop has a larger constant because of loops overhead

performance
because i heard that for-loop is much faster than foreach loops

memory
i have the impression that the implementantion has something to do with a for-loop and some kind of adaptive delay that gets bigger as loops count increases

usability
i find lapply loops easier than a for-loop in your case as initializing the list and using the counter can be avoided

performance
even if a foreach loops were faster than a for-loop there are still operations being carried out that wouldn t be in your manual example

performance
if you are using any js loops then for each loops is slower than normal for-loop you might wanna take a look at this

usability
i think you can best use the for-loop this gives you a little bit more control over loops

performance
the reverse while loops is generally faster than a for-loop as well

usability
and last if you know the number of loops it is much easier and better to read when you use a for-loop instead of a while loops

performance
says that enhanced for loops is 3x faster than the regular for-loop well that great and its easier to write anyways but what if i need the index

performance
the decremented while loops is still faster than the for-loop or the incremented while loops with length upper limit comparison by a fair margin

performance
the nested loops version is the slower of the two due to the extra the interpreter overhead of the for-loop

performance
if the above is true doesn t this mean that the foreach loops is much slower then the common for-loop since it involves making copies of each element of the arrays

performance
having said i am really not sure why you are getting unexpected behavior i ran your code both in eclipse and intellij ide and i always got for-loop approach as faster than while loops

performance
also the native for-loop is faster than any other jquery loops method

performance
since i am using two for loops it is consuming more time and is affecting the execution time of my entire program which already had a for-loop

performance
but the the foreach loops takes more time than a the for-loop

memory
the result amazed me in the way that as loops goes over bigger range the performance of c# decreases as compared to c..for smaller range c# shown well performance over c....but as upper range of for-loop increases the c# performance degrades as compare to c..

usability
instead of using a while loops it is easier to use a for-loop

performance
max_size must be big enough because a for-loop is slower than lapply you want to do as little loops through the for as possible but not too big or the list extension overhead will make the program slower

performance
the for-loop is faster than the while loops when n 1000000 each takes roughly 0.105544 and 0.2389421

usability
now assuming that your inner loops is more complex and the simple for-loop is slower let s look at how much memory we save by avoiding broadcasted data in a parfor with 4 workers and a dataset with 50 million rows for about 760 mb in ram

performance
is the foreach loops slower than the for-loop

performance
loops recur is faster - it s one of the most efficient constructs in clojure done correctly it should match the speed of an equivalent for-loop in java code

performance
i did this with for-loop too and while loops was clearly faster than for-loop again

performance
even if the hypothesis of the while loops being faster than the for-loop were true and it s not the loops you d had to change optimize wouldn t be the outer ones but the inner ones because those are executed more times

performance
hey guys can anyone tell me why my code in this jsperf seems to indicate that a for-loop is actually faster than a while loops

performance
a basic for-loop is slower than a for - loops with simplified test condition

usability
to achieve the actual goal you maybe able to use plain for-loop which provides more flexibility in controlling loops instead of using while

performance
some people use array.prototype.slice to do that but i m not a fan and i think a for-loop is faster in most browsers - but either way i have nothing against for loops and the slice often feels like a hack to me

usability
the class of problems you can solve with while loops is strictly more powerful than those you could have solved with the strict for-loop found in pascal

performance
here the for-loop header takes actually more time than loops body thus profiling results could be distorted.

performance
the decremented while loops is still faster than the for-loop or the incremented while loops with length upper limit comparison by a fair margin

performance
the other option is to use a foreach loops which is slightly slower than a for-loop but works almost equivalently for all practical purposes

usability
even if you use a lowly for-loop it s much easier to loops over the elements of a list than it is to construct variable names with paste and access the objects with get

usability
lastly whenever you want to iterate x amount of times a for-loop is always more readable than a while loops that uses a counter variable

performance
and normal for-loop is faster than for-in loops

usability
using for-loop is much simpler if you use condition as limit for breaking loops

performance
the other advice i have is that a for-each loops is faster than a for-loop

performance
the other option is to use a foreach loops which is slightly slower than a for-loop but works almost equivalently for all practical purposes

performance
the while loops with decrements was approximately 1.5 times slower than the for-loop

performance
it might be better than a for-loop in the terms of readability maintainability but keep in mind that linq usually slower than plain loops tl

performance
based on this not created by me the while loops is 22 slower than a for-loop in general

performance
i just wanted to point out my answer since i know for-loop is faster then loops

performance
in some cases hand-writing a for-loop is much faster than the equivalent accelerate functions because the compiler can optimize your loops better than the function

performance
in my tests i found that one of the loops i tested titled for-loop is astronomically slower than the other loops

performance
for-loop is faster then foreach and foreach is faster then for in loops

performance
i ve done a small experiment as will be shown below and it looks like that a while loops is faster than a for-loop in perl

performance
this conclusion would follow from a logic if an unrolled loops is faster than a for-loop executing a lot of unrolled loops should be faster than executing a lot of for loops

performance
foreach or for-loop is somewhat slower than an equivalent while loops or tail recursion the benchmark i linked to above shows a 15x performance difference with 1000+ iterations though it will likely depend on the version of scala and the version of the jre...

performance
a loops using a callback function like the standard foreach was approximately 10 times slower than the for-loop

performance
a for-loop is faster than a foreach loops

usability
this is one of the few cases where a while loops can be clearer and simpler than a for-loop

performance
and the results is that foreach loops is 5-6 times faster than the for-loop

performance
this is happening because of speed of for-loop which is faster than your time .as loops iterates in time of less than miliseconds and generates values.you can only call it when you want to insert single value to database and don t iterate for values

performance
finally we concluded after we put print statement inside for-loop that it will take much more time than loops in the first case without print statement

usability
a while loops is more readable than a for-loop

performance
if you won t be changing the string in loops it is better faster to store the value in and then include it in the for-loop

performance
the for-loop is slightly slower than the foreach loops

usability
loops in c++ are most basic than python the for-loop is more simpler it is based on the three expression initializer expression loops test expression and the counting expression

performance
so why while loops is faster than for-loop and why need bunch of lists

performance
why simd for-loop only 14 faster than foreach loops

performance
in example sendp method included in for-loop which is slower than making other loops to send packets

performance
the multiprocessed loops is slower than doing the for-loop

performance
a single for-loop is generally faster than using 2 nested for loops to traverse the image with x y counters

performance
my view is that option 1 is clumsy code and involves unnecessary creation of an arrays even though the for-each loops is more efficient than the traditional for-loop in option 2

performance
-in the same laptop but using the hpc cluster of my department with 30 workers the parfor loops is much much slower than the for-loop and than the parfor loops using the local cluster with 12 workers

performance
i have an expensive for-loop that is taking more time than it should due to dynamic casting overhead inside loops

performance
foreach can simplify the code in a for-loop but it is a heavy object and is slower than a loops written using for.

performance
for-loop is faster then foreach and foreach is faster then for in loops

memory
the result amazed me in the way that as loops goes over bigger range the performance of c# decreases as compared to c..for smaller range c# shown well performance over c....but as upper range of for-loop increases the c# performance degrades as compare to c..

memory
the main problem i know is the while loops the logic behind it is not correct because last didah is always bigger than n for-loop counter

memory
a becomes 10 while it is still inside of the for-loop and gets larger than 10 when the while loops goes for a second run

performance
update i made some changes to my code but was already suspecting what others here have already pointed out sure the enhanced for-loop is slower but outside of very trivial tight loops the cost should be a miniscule fraction of the cost of the logic of loops

usability
also as an aside objective-c has a foreach loops that is more convenient than manually setting up a for-loop with a counter

performance
as the simple for-loop is faster than a foreach loops

memory
alternatively you could initialize i outside of the for-loop but then it s scoped larger than loops itself

performance
i just wanted to point out my answer since i know for-loop is faster then loops

performance
one place where the enhanced for-loop is faster than a naively implemented traditional loops is something like this

performance
can you explain me why in this case the parfor loops is slower than the for-loop

usability
i think using for-loop is much more easier than using foreach loops to do this

usability
you should use a for-loop which is more convenient to loops in an arrays

usability
to my mind a for-loop is simpler to understand than traversing the list backwards with a while loops

performance
i prefer using for-loop instead of foreach loops for-loop is preferably faster than foreach loops when you do not have to do something to each element and can solve your problem by just using the index as follows

performance
if the above is true doesn t this mean that the foreach loops is much slower then the common for-loop since it involves making copies of each element of the arrays

performance
is for-loop is faster than while loops

performance
the only browser where the while loops was slower than the for-loop was in opera

performance
to explain why a for-loop is faster than a for in loops is basically understand the underlying data structures used to store the data in memory

performance
because i heard that for-loop is much faster than foreach loops

performance
arraylist - for-loop is about more than 2 times faster speed than foreach loops

performance
you could also use a for each loops to handle this though that type of loops is slower than a standard for-loop depending on application

performance
i prefer using for-loop instead of foreach loops for-loop is preferably faster than foreach loops when you do not have to do something to each element and can solve your problem by just using the index as follows

usability
for-loop is easier to read than a while loops

performance
i think in terms of performance using a single for-loop is faster am i right 3 linqs will be eventually converted to 3 loops

usability
further as a for-loop it is easier to read as everything initialization loops condition expression to be executed after each iteration are all on one line

usability
a while loops is imo more complicated to read than a for-loop

performance
a for-loop is usually faster than a while loops and it is more difficult to build an endless loops than it is by using a while loops

performance
bottle is rather faster than flask

performance
bottle is rather faster than flask

memory
try with 1 column-count and as text get bigger than available height it will auto split in to second column - columns 1 150px

performance
functionally a multiplying will always take more time than an add because it combines a true multiplying along with a true addition step

performance
its the multiplying that historically was slower than the add

performance
as of a few years ago multiplying was 3x slower than add

performance
add is faster than mul but if you want to multiplying two general values mul is far faster than any loop iterating add operations

performance
however multiplying is faster than adding even though less clock cycles are used to add verses multiplying according to what my particular cpu s datasheet says about the instructions being used

performance
on a cpu with a fast multiplier multiplying may only be on the order of 4 times slower than add but on normal hardware it s 16-32 times slower for a 32 bit operation

performance
i know that xlsxwriter is way faster than xlwings and have functionality to add border but it is just a writer it can t update already existing spreadsheet

performance
i know that xlsxwriter is way faster than xlwings and have functionality to add border but it is just a writer it can t update already existing spreadsheet

usability
getline is far more flexible handling the allocation of space for you with fgets it is up to you

security
one more edit if you want to use getline instead which you asked about in the comments - and it s even safer than fgets since it will increase the buffer size as needed you would change to change the code a little bit

performance
but i heard that xlsb loads way faster than xlsm so i would not like to change the fileformat

performance
there exists a simd fork of pillow which claims to have much better performance than imagemagick or plain pillow but there are no comparisons to opencv

memory
which is basically the same thing as the factories then depend on sub-factories but at least they are lighter than presenter views services and they don t need to load the sub-factories until they are needed

usability
nsurlsession is much more powerful tool than nsurlconnection

performance
it s not my experience that nsurlsession is any slower than nsurlconnection is

usability
nsurlsession is much more powerful tool than nsurlconnection

usability
although madprogrammers comment to use a gridbaglayout is an easier solution but knowing about glue and struts can be helpful for customizing the layout of a boxlayout

usability
boxlayout is far easier than gridbaglayout because you don t have to learn how to specify constraints

usability
boxlayout is far easier than gridbaglayout because you don t have to learn how to specify constraints

usability
although madprogrammers comment to use a gridbaglayout is an easier solution but knowing about glue and struts can be helpful for customizing the layout of a boxlayout

performance
the origin server would get the images from s3 process them using graphicsmagick since it s much faster than imagemagick then serve them

performance
graphicsmagick converted much faster than imagemagick although i did not test conversion with cuda processing

performance
graphicsmagick also seems to be faster than imagemagick using better multitasking

performance
i successfully compiled graphicsmagick with q8 but after all it seems about 30 slower than imagemagick 0.3 secs

usability
phpunit is more popular and up to date as simpletest hasn t had a new release for some time though for testing webforms it s still very useful as phpunit does not have good support for that

usability
i found simpletest was even easier than phpunit to set up

usability
simpletest is slightly easier to grasp but phpunit is the best in my opinion at least so if you want to start learning and using a framework start with the one you re going to use when you ll be a master in tdd

usability
the youtube approach seems much more efficient as far as amount of code and simplicity of understanding which makes me wonder why vimeo would use promises in this simple fast case

usability
the youtube approach seems much more efficient as far as amount of code and simplicity of understanding which makes me wonder why vimeo would use promises in this simple fast case

usability
if you are willing to limit yourself to vista or later then direct2d would be a little simpler than direct3d

usability
direct3d appears in principal to be easier than direct2d but has poor text font handling in the latest version

performance
my c s-function is faster than my embedded matlab function block in matlab environment but when i use it in rt-lab the embedded is faster

usability
in my opinion this is a more elegant solution than jsf and i think tapestry s ioc container makes it more powerful than wicket

memory
i m using facebox and fancybox both smaller than thickbox

performance
when the data is on disk titan is faster than neo4j cause it has a better disk representation

performance
i don t want to use apc because opcache is around 10 faster than apc

memory
it seems like the draggable element including the margin is bigger than the droppable element and therefore the dropped status is set although the element does not seems to touch the upper droppable yet

memory
but i have a problem dragging to a droppable that is smaller than the draggable

memory
when i made dimension of draggable div smaller than droppable div then drop event triggered successfully

memory
and the size of the draggable div s should be smaller than the droppable div so that they fit in the droppable container

memory
i have a draggable parent element ice cream wrapper which is bigger than the droppable one teeth

memory
when the draggable item is larger than the droppable div for some reason it will always place the appointment in the droppable div box that is directly below the one i am targetting

memory
perhaps you find it strange since the target droppable s size is much smaller than the draggable

memory
apparently the draggable li element is bigger than the droppable div because the li is block size and the div has a 150px width

memory
the draggable div is 3 times bigger than one droppable

memory
p.s this will only work if the draggable is smaller than droppable which is true in this case

memory
it works nicely but from the rich ui perspective it s boring so i was wondering since the draggable image is bigger than the droppable how could i do assuming it s possible to have the droppable container suck the bigger image until if fills its dimensions

memory
i was able to remove the unwanted behavior described above by turning the droppable into the parent of the element and added a margin padding that is slightly larger than the draggable snaptolerance

memory
when the draggable item is larger than the droppable div for some reason it will always place the appointment in the droppable div box that is directly below the one i am targetting

memory
this overlap is somewhat forced when the draggable is bigger than the droppable

memory
it works nicely but from the rich ui perspective it s boring so i was wondering since the draggable image is bigger than the droppable how could i do assuming it s possible to have the droppable container suck the bigger image until if fills its dimensions

memory
i know there are not that many mantissa bits for fractions part for bigger numbers but you did not specify which floating data-type you are using if 32 64 80 128 256 bits or more so hard to say and if the integer part is bigger then your integral data-type used to cut off the non fractions part then you would be in trouble with f-long f

memory
if the number of bits in the mantissa or fractions is larger than the number of bits in your integer type then you ll possibly lose precision when someone types in a number such as

memory
i know there are not that many mantissa bits for fractions part for bigger numbers but you did not specify which floating data-type you are using if 32 64 80 128 256 bits or more so hard to say and if the integer part is bigger then your integral data-type used to cut off the non fractions part then you would be in trouble with f-long f

memory
as python integer is less limited than the float you may get bigger results with the fractions if it makes sense at all

memory
the label s text size of an integer part is bigger than text size of a fractions part

performance
note that is equivalent to i 10 but much faster since modulo is around 10 times slower than multiplication

usability
in dependently-typed languages like idris it s probably more useful than in haskell

usability
zsh is more extensible and has a much greater focus on searching and completion than bash

usability
update turns out that zsh implementation based on builtin compctl is much simpler than the bash implementation based on builtin complete

performance
but the post method okhttp is more slower than httpclient s post always more slower than okhttp s get method

performance
but the post method okhttp is more slower than httpclient s post always more slower than okhttp s get method

performance
it shows that koa is faster then other framework but as this question is about express and restify express is faster than restify

performance
it shows that koa is faster then other framework but as this question is about express and restify express is faster than restify

usability
koa middleware is much simpler and less hacky than express middleware due to the way middleware flows in a stack-like manner

memory
while leaflet aims to be more lightweight than openlayers openlayers is by far the more mature proj

performance
noexcept allows for more efficient code generation in that it does not have to perform rtti on throw exceptions instead if an exception is throw from a call-frame underneath a noexcept-declared function std terminate is called short-circuiting the crazy std unexpected machinery specified by the 98 standard

usability
openpgp is simpler than x509 but more limited especially if you wish to have a strong legal meaning behind the certificates

performance
template engines are rarely the cause of performance problems even if chameleon is slightly faster than jinja2 i doubt the effort of learning a new template language etc

performance
template engines are rarely the cause of performance problems even if chameleon is slightly faster than jinja2 i doubt the effort of learning a new template language etc

reliability
not many layout problems can t be conquered using it and its easy to understand as opposed to springlayout groupedlayout etc and far less code and more robust than gridbaglayout

performance
you might replace the max subquery with a rank max is usually slower only when cus_id is the pi rank might be worse

performance
you might replace the max subquery with a rank max is usually slower only when cus_id is the pi rank might be worse

memory
every time a rank finds a larger number than that stored have it send its new max to the root rank

performance
while i think gbn s answer is probably sufficient i m wondering whether use of an over clause to establish a max date per id attribute with which to reduce the select in a where clause wouldn t be faster than a rank

memory
every time a rank finds a larger number than that stored have it send its new max to the root rank

usability
declarative code is easier to make bug-free than imperative code

memory
traditionally there was a huge difference in speed imperative has fewer overheads because it s more directly like the computer works but some more modern compilers of declarative code seem to be in the top few of the speed tables a lot of the time - compiled verses interpreted makes a much bigger difference than imperative vs declarative which is why python etc are often slower even though they re imperative

usability
declarative programming is not always simpler than imperative programming

usability
declarative sql is usually simpler and faster than imperative pl sql so it s usually best to do most of the work in sql and just glue it together with pl sql

performance
declarative sql is usually simpler and faster than imperative pl sql so it s usually best to do most of the work in sql and just glue it together with pl sql

memory
in terms of performance py4j has a bigger overhead than both of the previous solutions jython and jpype because it relies on sockets but if performance is critical to your application accessing java objects from python programs might not be the best idea

memory
in terms of performance py4j has a bigger overhead than both of the previous solutions jython and jpype because it relies on sockets but if performance is critical to your application accessing java objects from python programs might not be the best idea

usability
android plot and other free chart solutions mentioned here doesn t support annotations the only one is afreechart which is a port of jfreechart for android i am currently using it and it is awesome and has much more features than achartengine

performance
however there are many others ts xts which is generally faster than zoo .

performance
however there are many others ts xts which is generally faster than zoo .

usability
phalcon is more powerful verstile but to get started with it i feel you have to be a better php developer than you do to get started with something like cakephp

performance
instead doing it with lxml which i found to be the fastest somehow even faster than celementtree

performance
as a side-effect of implementing proper parent traversal lxml is a bit slower than celementtree for parsing

usability
when writing code in jscript as i am wont to do as i have never been a fan of asp.net and jscript is infinitely more elegant than vbscript you can call upon the arguments collection

usability
asp with jscript is 100 times better cleaner simpler nicer than vbscript and makes my job a joy rather than a vbscript head ache

usability
...i suggest doing all of the scripting from within the vbscript file and avoiding the use of .cmd .bat files completely if you can as vbscript is much more readable and powerful though i prefer using the jscript language instead but that s just me

usability
the inclusion of jscript code into a batch file is simpler than vbscript and the translation of a small code segment from vbs to jscript is not problematic

usability
when writing code in jscript as i am wont to do as i have never been a fan of asp.net and jscript is infinitely more elegant than vbscript you can call upon the arguments collection

performance
incidentally the scrolling on the windows version of safari is fine albeit a little slower than ie opera and firefox

memory
works in google-chrome firefox a bit weirdish blur effect on hover opera ends look smaller safari ends look smaller

usability
my experience is that designers can use whichever they prefer usually and most agree that verilog is easier to use and the code is shorter fact than equivalent vhdl

usability
vhdl is more popular in europe and verilog is dominating in the us

usability
i m also looking for more examples and explanations of complex combinators more complex than fold in common programming languages

usability
where instead of expected many-to-one is much more complex and partially expressed many-to-many

memory
i would like to split the image into tiles so that each tiles area must be larger than a min tile area eg 1024 bytes and smaller than max tile area eg 2048 bytes

memory
for every insert check if the value is bigger than max or smaller than min if so set them to properly

memory
i am trying to understand what would happen if the max node is somehow smaller than some of the min nodes.

memory
for example the validation i am looking for is when a min value is larger then a max value there needs to be an error but this error can be corrected from either textbox and the error for the textbox needs to be removed when this happens

memory
max is much bigger than min maybe i can minus the gc workers

memory
if the max number is smaller than the min number the number in the max text box will be automatically changed to the same number as the min number in the min text box

memory
so you want to find objects where the min value is smaller equal the passed min-value and the max value is larger equal the passed max-value

memory
when i run the above query the min returned is larger than the max

performance
then i would add min id to see if its any faster than max id

memory
let s check if the first which is equal or larger than min is smaller or equal than max so

memory
however i do not get a 2 2 matrix if i select any value that is smaller than min predictions or larger than max predictions since the data won t have either a false or true occurrence

memory
your interval for variable i is probably wrong max is smaller than min

memory
in the first iteration the min heap holds the larger part and the max heap

memory
by the way you don t need to consider trivial gridpoints outside of your polygon those with x-coordinates higher or smaller than the max min x-coordinates of your polygon and those with y-coordinates higher or smaller than the max min y-coordiantes of your polygon

memory
in the first iteration the min heap holds the larger part and the max heap

memory
warning mt_rand function.mt-rand max 0 is smaller than min 1 in users avsm www pa-include functions.php on line 332

memory
notice how max is smaller than min due the nature of your formula

memory
max age should be bigger than min age

memory
my code should make sure the user doesn t select a min value greater than the max value or a max value smaller than the min value using this code

memory
implement normal different sized circle packing than resize all circles so the biggest is no bigger than planet max size and the distances between them is bigger than min distance x1-x2 2+ y1-y2 2 mindistance for each pair of circles

memory
thus after the loop exits you will be able to tell whether the values of min and max are real or just the initial values that haven t been changed another way to do that would be to test after the loop whether min is bigger than max - if it is then the file was empty

memory
it s interesting that this works since the documentation states that max must be larger than min but it looks like -1 is treated more like an empty or null value

memory
you can check whether the new number is smaller than min or bigger than max and change them if needed

memory
if the window is smaller than max width the content fills 100 of the page unless it s smaller than min width which would make the horizontal scrollbar appear

memory
if the value of min is larger than max a pop-up will occur

memory
negating the min value of int would mathematically give us 2147483648 but since that is one larger than the max value

memory
if min is bigger than max i just return a random character from the entire range

memory
when the min value is larger than the max value the max value gets reset to a value 100 larger than the min value

memory
first of all why your 0 max radius is even smaller than 5 min radius

memory
warning mt_rand max -1 is smaller than min 1 in

memory
and i need to check for every item if min is always smaller than max

memory
the dis min max part sets a range of min and max values this distribution can come up with which means it will never generate a value bigger than max or smaller than min

memory
sigmoid approximates clamp never smaller than min never larger than max

memory
first of all why your 0 max radius is even smaller than 5 min radius

memory
now when you have both max and min you can simply get the index of first element greater than min and last element smaller than max from your minheap

memory
for example the validation i am looking for is when a min value is larger then a max value there needs to be an error but this error can be corrected from either textbox and the error for the textbox needs to be removed when this happens

memory
but he has some constraints like min must be bigger than max and neither of them should be bigger than 100 or lesser than 0

memory
edit correcting the max lenght so it is bigger than the min lenght

memory
produces the same error attributeerror max must be larger than min in range parameter

memory
however i m getting a attributeerror max must be larger than min in range parameter. error when i m trying to plot the normalized data

memory
but continuing i always got attributeerror max must be larger than min in range parameter

memory
max is much bigger than min maybe i can minus the gc workers

memory
that having been said your average is guaranteed to be at least as large as the min value in the column and no larger than the max value in the column

memory
your code take all the td s which their values are bigger than the min value and all the td s which their values are smaller than the max value this mean all the td s

memory
now you could iterate through the objects to find current limits 9min and max or you could even do it while you calculate the measures each time sth smaller than min happens store new min etc

memory
mt_rand max 2 is smaller than min 11

memory
you are doing the opposite causing your loop to do nothing since z is never smaller than min or larger than max

memory
if min is not a number fail if max is not a number fail if min is smaller than max fail

memory
since max is larger than min one of the two will always happen

memory
so you want to find objects where the min value is smaller equal the passed min-value and the max value is larger equal the passed max-value

memory
because the hue value is cyclic i need to process min max values where the min hue might be bigger than the max hue value

memory
i would like the column extrema of my dataframe beeing max2015 if max215 is bigger than max or smaller than min2015 if min2015 is smaller than min

memory
so while max decremented is larger than min â

memory
when the min value is larger than the max value the max value gets reset to a value 100 larger than the min value

memory
and i need to check for every item if min is always smaller than max

memory
2 also i notice that the inverse of the maximum value of a double precision type is bigger than its min value and inverse of its min value is inf way bigger than its max value

memory
you can do the whole job in a single for-loop reading from stdin look if it is larger than the max smaller than the min and so you do not need the arrays

memory
a version which uses a closure over the min and max values with raising an exception if max is smaller than min

memory
is_valid will be true if inputvalue is larger than min or of it is smaller than max

memory
when the min value is larger than the max value the max value gets reset to a value 100 larger than the min value

memory
until all your provinces are larger than min size and smaller than max size

memory
if the max number is smaller than the min number the number in the max text box will be automatically changed to the same number as the min number in the min text box

memory
another problem is you should have instead of || between comparisons you want it to be greater than min and also smaller than max

memory
if min is larger than zero then it belongs to complete category max is naturally larger than zero then

memory
keep in mind that if your new min value is larger than either the current slider value or max value it will not render until the remaining two are updated accordingly

usability
as far as i can tell qt-designer is more powerful than any wxpython counterpart like boa constructor and pyglade

memory
unfortunately using hex consumes way more space and takes significantly longer i m dealing with 500gb of data and around 1 2 million records so i would really like to get the straight binary method to work

usability
hex encoding is far more readable than binary that s why sublime uses it

usability
as others have pointed out hex is much more convenient than binary anyway - you just need to remember how each of the hex digit 0-f looks in binary and replace groups of 4 bits with a single hex digit

usability
hex is somewhat more readable than binary if i happen to be loading a data dump in a text editor etc

usability
hex is easier for most people to convert to and from binary in their heads since binary numbers are usually expressed in blocks of eight because that s the size of a byte and eight is exactly two hex digits but hex notation would have been clunky and misleading in dennis time implying the ability to address 16 bits

memory
those hex values seem a bit odd they re powers of two in decimal but in any case 0x128 the 0x is a standard prefix for hex numbers is the larger of the numbers in magnitude and its binary representation is 100101000

performance
this is still accepted by calls like inet_addr and has several advantages all fields are fixed width there are only 8 characters to update and the binary to hex conversion is usually faster than binary to decimal

usability
and because hex is much more readable and useful than binary - it s often used and shown

usability
as others have pointed out hex is much more convenient than binary anyway - you just need to remember how each of the hex digit 0-f looks in binary and replace groups of 4 bits with a single hex digit

usability
the conversion from hex to binary is even simpler since you can simply expand each hex digit into the corresponding binary for example 0xa4 - 1010 0100

performance
this is still accepted by calls like inet_addr and has several advantages all fields are fixed width there are only 8 characters to update and the binary to hex conversion is usually faster than binary to decimal

usability
- i usually find debugging memory in hex x command is easier than binary so i will not use my solution

usability
hex encoding is far more readable than binary that s why sublime uses it

usability
hex is somewhat more readable than binary if i happen to be loading a data dump in a text editor etc

usability
but when anyone human looks at it they look at it in hex using a hex editor which is much easier than reading binary

performance
ejml looks really good it works almost 2x faster than jama on my data.

performance
the reason is that the modulo is slower than subtraction

performance
that is essentially the one case in which repeated subtraction 0 or 1 times a special case of repeated subtraction can be and commonly is but not necessarily faster than division-based modulo

performance
as you can see modulo is about an order of magnitude slower than subtraction

performance
or is it just that scapy is slower than dpkt

memory
but if your key space is vastly larger than the number of targets you ll have a sizable number of hash-collision where you ll have to check if the target stored there is really the key you re looking

memory
flac is smaller than wav

memory
i like caffe but the amount of gpu memory caffe use is larger than mxnet i test in resnet-50 with mxnet-memonger

memory
i like caffe but the amount of gpu memory caffe use is larger than mxnet i test in resnet-50 with mxnet-memonger

performance
i ve read that painting to a qwidget is sometimes faster than qgraphicsview but it would by a lot of extra work for the mouse handling i think

performance
i ve read that painting to a qwidget is sometimes faster than qgraphicsview but it would by a lot of extra work for the mouse handling i think

performance
there is a project pyquery that is much faster as it uses lxml.html library speed comparasion can be found here

performance
the next solution is faster than using in and except clauses

memory
this can enable the user to download an upgrade patch that is much smaller than the installation package for the entire product

performance
does an eclipse installation perform slower after the upgrade

reliability
here s something that should get you started - this is all based on the assumption that there are only 3 checkboxes on your whole page and that you re interested in all of them - you ll want to make a method like this respond to your checkbox elements onclick events - i ve found that to be more reliable than onchange

usability
although you could tell dancer2 plugin passphrase to use a 4-byte salt it s much easier to just use crypt saltedhash everywhere

memory
malloc often gives you more memory that you ask and stores the actual value in a special location that realloc can access at a later time

performance
the justification of realloc is that it s faster than 2nd malloc manual copy free

performance
a realloc can occur significantly faster than a malloc memcpy and free

memory
that s why realloc can temporarily require more memory than a malloc free pair

usability
freemarker is more powerful than velocity

usability
velocity is simpler than freemarker

memory
it is even slower since i could only upload wav which is way bigger in size compared with ogg and opus

memory
if you are worried about memory then do look into scikit-learn since equivalent models can use significantly less memory than nltk

usability
but native hibernate support regarding inherited mapping is more powerful than standard jpa and single table per class hierarchy or table per subclassing mapping strategies are more suitable for polymorphic queries and associations than table per concrete class strategy

usability
inherited is more useful when a new subclassing wants to change the way a method works if you just need to change the data the class uses to work probably an approach like this would do the trick

usability
display attr function is better to get src attribute

performance
using fgets and fputs is faster than multiple calls to getc and putc all you need is a buffer a little buffer in this case to store the current line

usability
i have an app that uses the public part of the twitter api the on who not requires to login but with the update the login is required so i need to implement oauth i ve seen there are libraries like twitter4j who makes this easier but my app has a lot of code and i don t wanna rewrite it not now so i ve think to use scribe or oauth-signpost but i dont realy know how to

usability
p.s. my recommendation would be to remove jsonobject conversion and instead return an object of actual class as internally spring uses jackson which is more powerful json framework then org.json

usability
the other distributed tools are a lot faster svn is slow as hell even cvs can be faster sometimes have much more useful features than svn are developing rapidly while seeing any new feature in svn takes years

usability
part of the point of svn was to make the use of branches and merging much easier than in cvs

performance
in fact svn does stores binaries a lot more efficient than cvs for more info see the svn-faq

memory
in this case i converted the cvs to svn and found the file size on the hard drive it was on my own laptop at the time but it was much smaller in svn than in cvs but there could have been some compression applied i dont know but everything on the web said svn would actually be bigger than cvs

usability
in addition another coworker said cvs was a lot more popular than svn

memory
wondering mainly if svn uses less disk space or more than the same in cvs

usability
for a one man shop teamcity is far easier to setup and configure than cruisecontrol

usability
with library purrr you can have a prettier more compact form see soto s answer for an even more compact one with dplyr

performance
this would explain why in your case mousedown or click are slower than mouseenter which in a touch device happens as soon as you touch the element being monitored

memory
the datagram is larger than your buffer so it gets trucated you get an error return from recvfrom and getlasterror returns 10040 wsaemsgsize

usability
ibm makes it easier for those who can t afford websphere application developer or rational application developer which are both eclipse flavour to use eclipse

usability
please keep in mind that qmake and qbs are two very different build systems with fundamentally different designs and capabilities and qbs verbosity is in part due to its fundamental architectural differences which make it far more powerful than qmake will ever be capable of

usability
either way applying gain and or attenuation to time-domain sample data as in a wav file is much easier than trying to apply these effects to frequency-domain data as in an mp3 file

memory
for using a fileformat i thought mp3 uses much less memory than wav because all the formats are based on wav but just compressed

memory
if you are still having problems jdk 8 has the ability to play mp3 files which are significantly smaller than wav you may want to try this

memory
for using a fileformat i thought mp3 uses much less memory than wav because all the formats are based on wav but just compressed

memory
i understand that mp3 is much smaller but it has worst audio quality when is compared to wav files

memory
ok i am new to audio with unity but despite reading all the unity posts regarding audio adding 2 short .wav clips i heard wav was smaller than mp3 to my app has added over 200mb

memory
wav files are about 3 times larger than mp3 files so it would need 1.8gb additional space to do the conversion

memory
now i assume you are worried your techno might not read a compressed mp3 which should be smaller than a wav from my memories

memory
you should definitely pick mp3 because they are about 10x smaller than wav files of the same duration

performance
i don t see any reason why filechannel could be any faster than fileoutputstream in this case

performance
qhash is faster but qmap values are sorted by key if you iterate through them

performance
qhash provides faster lookups than qmap

performance
qhash provides faster lookups than qmap

usability
then for reading i find textscan to be more powerful than fread fscanf the differences between them all are summarized here

memory
if the uilabel is larger it will then wrap around the uibutton to the next line

usability
kif makes ui testing really easy and useful with lots of great apis that are less complex than xctest

performance
on ideone the ostringstream is about 3 times slower than std copy + back_inserter + std vector and about 15 times slower than memcpy into a raw buffer

usability
you ll need to convert binary to another base here i use decimal when writing this code because c doesn t have binary constants which would be ten times more useful than octal constants

performance
i read in couple of blogs that in java modulo reminder operator is slower than bitwise-and

memory
at first i tried reading the original pdf with a fileinputstream and finding the signature hex strings to split it into smaller files with a fileoutputstream as i have done with jpgs

performance
also pyquery is significantly faster than beautifulsoup in many cases for processing results

performance
also pyquery is significantly faster than beautifulsoup in many cases for processing results

performance
es2015 module is more efficient than the other formats and can facilitate the creation of smaller bundle size through tree-shaking technique importing just the bits you need instead of importing the whole thing

performance
this platform is probably not representative of your microcontroller but the test shows that on this platform the subtraction is considerably slower than the division

performance
this platform is probably not representative of your microcontroller but the test shows that on this platform the subtraction is considerably slower than the division

performance
this is called a strength reduction optimization because division is stronger slower more expensive than subtraction

performance
this is called a strength reduction optimization because division is stronger slower more expensive than subtraction

usability
it may not be the most elegant method but when you just need to convert something ad-hoc thinking of it as comparison and subtraction may be easier than division

performance
i am a bit suspicious of the performance because modulo tends to use division which is slower than your subtraction operations

memory
the good news is that dexterity content types are more lightweight than archetypes content types and doing raw listing by iterating over folder.contentitems in your template should not be that expensive

performance
if for some strange reason you can do the obvious do.call would be more efficient than mapply

memory
use a radix tree wiki or trie wiki if you are concerned about performance.the radix tree is more memory efficient compared to a trie

performance
the suffix tree is lighter and faster than the trie and is used to index dna or optimize some large web search engines

memory
for cases where each node in the trie has most of its children used the trie is substantially more space efficient and time efficient than th ternary search tree

performance
most likely a trie is more efficient and you didn t sort your dictionary and it doesn t use a binary tree or ternary tree

performance
ps radix tree is usually faster and more compact then trie but suffers from the same side effects of trie comparing to hash tables though less significant of course

memory
the suffix tree is lighter and faster than the trie and is used to index dna or optimize some large web search engines

performance
should i change my project to trie or is there any other good reasons where avl tree woud be more efficient than trie in case of phonebook

usability
most machines now end up with sizeof int sizeof long because 16-bit is no longer convenient but we have long long to get 64bit if needed

memory
on today s desktop systems an int is usually 32 or 64bit wide for a correspondingly much larger range than the 16-bit 32767 32768 you are talking of

performance
in fact for x86 64 processors performing 32-bit or 16-bit operations are less efficient than 64bit or 8-bit operations due to the operand prefix byte that has to be decoded

performance
see also why malloc + memset is slower than calloc

performance
malloc + memset is slower than calloc under certain conditions

performance
my question is why is malloc + memset so much slower than calloc

performance
in all other cases division appears to be several times slower than multiplication

performance
division is faster for unint8 than multiplication in your case

usability
division and square roots for huge number of bits are not much more complex than multiplication

performance
in fact if the intent is to divide by 22 10 or some other real value that isn t necessarily exactly representable in binary floating-point then half the times the multiplication is more accurate than the division because it happens by coincidence that the relative error for 1 x is less than the relative error for x

performance
removing division operations by passing through the inverse into the shader is another useful tip as division is typically slower than multiplication

performance
the tostring should be slower than parse since division is generally slower than multiplication

performance
change the half to 0.5 and you should be golden for the math part also multiplication is faster so use it instead of division when possible

performance
which one is faster is indeed a cpu-specific issue or at least how much faster is cpu specific yes division is typically seen as slower than multiplication

performance
on many machines particularly those without hardware support for division division is a slower operation than multiplication so this approach can yield a considerable speedup

performance
according to stephen canon modern implementations favor taylor expansion over rational function approximation where division is much slower than multiplication

performance
here s one idea which uses one multiplication and one shift so it ll be faster than a division on most systems

performance
in many processors integer multiplication is vastly faster than integer division

performance
according to stephen canon modern implementations favor taylor expansion over rational function approximation where division is much slower than multiplication

performance
the compiler or the jit is likely to convert the first case to the second anyway since multiplication is typically faster than division

performance
can be fast or it can be awfully slow even if division is done entirely in hardware if it is done using a div instruction this instruction is about 3 to 4 times slower than a multiplication on modern cpus

performance
hardware integer division is always slower than multiplication and the gap in the relative latencies of these instructions continues to widen

performance
division is about 20 faster than multiplication

performance
but i wonder why is division actually slower than multiplication

performance
first of all multiplication is faster than division

performance
you always need to know the magic number here 0xaaaaaaab and the correct operations after the multiplication shifts and or additions in most cases and both is different depending on the number you want to divide by and both take too much cpu time to calculate them on the fly that would be slower than hardware division

usability
from what i read on the net multiplication is usually easier to compute than division

performance
i used multiplication for both operations because multiplication is typically faster than division

performance
if multiplication are o n 2 this is slower than long division for large numbers o n 2 vs o n 2 log n

performance
i would also suggest to replace terms like a l1 0.3e1 with as multiplication is faster then division

performance
division is slower than multiplication is generally - and definitely using regular expression matching is going to be slower than multiplication is..

performance
in many processors integer multiplication is vastly faster than integer division

performance
multiplication takes less time then division so you can try this

usability
division though is an iterative process in logic the implementations you see on educational sites verilog vhdl are simply doing the same thing we did with log division in grade school but like multiplication it is much simpler than grade school you pull down bits from the numerator in the long division until the number being checked against the denominator is equal to or larger basically the number can either go in only zero times or one times into the next number under test unlike decimal where it can be between 0 to 9 times

performance
division is per se slower than multiplication however i don t know the details

performance
the double_unit stuff is how random actually does it internally because multiplication is faster than division see floating point division vs floating point multiplication

performance
from the performance side float multiplication is faster than division but i don t think that in the gui code it can create significant difference

performance
multiplication is usually faster than division

performance
division is slower than multiplication due to some reasons

performance
division by 5.0 is more accurate than multiplication by an approximate 0.2

performance
therefore i conclude that division is faster than multiplication

performance
multiplication is much faster than division

performance
multiplication is faster than division

performance
yes division is usually much slower than multiplication

performance
as to why multiplication is faster than division and when the divisor is fixed this is a faster route

performance
both works but division is generally slower than multiplication

performance
i wonder why everybody missed that multiplication is much faster than division

performance
multiplication is usually faster than division

performance
i do not want to know when or if to use shift operators in my code i am interested in why multiplication is faster than shifting bits to the left whereas division is not

performance
integer multiplication is much faster than division

performance
since you re resizing the window make sure to assign the w and h values not as numbers but as products or dynamic numbers multiplication is faster than division but you can also use division

performance
also addition is faster than multiplication and multiplication is faster than division

usability
the cpu operation for float division is much more complicated than multiplication

performance
i wonder why everybody missed that multiplication is much faster than division

performance
is it possible that the division is six times slower than multiplication and

performance
division is inherently a much slower operation than multiplication

performance
on many processors integer multiplication is faster than integer division

performance
i found out that integer division is much slower than multiplication unfortunately

performance
because division is often much slower than multiplication if performance is critical you might keep a table with powers of ten and their reciprocals

performance
the tostring should be slower than parse since division is generally slower than multiplication

performance
i picked c 1 1 8 for this example simply because it is exact in ieee-754 floating-point representation and typically multiplication is much faster than division

performance
i am pretty sure it is not possible to compute polynomial division more efficient than multiplication and as you can see in the following table this algorithm is only 3 times slower than a single multiplication

performance
multiplication is faster than division so the second method is faster

performance
if the latter yes floating point multiplication is generally faster than division

performance
multiplication is faster division is more accurate

performance
if the numbers are huge dividing x by b might be betterâ division is usually slower than multiplication but getting out of the huge-number domain early might help more than avoiding division

performance
the reason to do this is because even though there is an integer division instruction div idiv in the instruction set it s typically very slow several times slower than multiplication

performance
as hroptatyr mentioned the multiplication is quite fast and it s much faster than division

performance
i picked c 1 1 8 for this example simply because it is exact in ieee-754 floating-point representation and typically multiplication is much faster than division

performance
on many machines particularly those without hardware support for division division is a slower operation than multiplication so this approach can yield a considerable speedup

performance
for the division-to-multiplication case you are assuming that multiplication is faster than division

performance
i used multiplication for both operations because multiplication is typically faster than division

performance
multiplication is usually significantly faster than division

performance
this because 1 x is simpler than y x and multiplication is faster than division

performance
hardware integer division is always slower than multiplication and the gap in the relative latencies of these instructions continues to widen

performance
integer multiplication is much faster than division

performance
similar to pmg s solution but still faster because multiplication is faster than division -

usability
for division things are a little more complicated than multiplication see

performance
division is generally on the order of 10x slower than multiplication on most processor families

performance
i was always taught that division is slower than multiplication but i have no real proof of thisâ has anyone got an opinion on this before i start benchmarking and running test

performance
but the research i ve done so far all points to multiplication being faster than division

performance
this can be a major clock-cycle saver since multiplication is often much faster than a division operation

performance
multiplication is faster than division see fog s tables

performance
your friend has a point a division actual division not just writing in c is slower than a multiplication

performance
change the half to 0.5 and you should be golden for the math part also multiplication is faster so use it instead of division when possible

performance
it is well known that integer division is slow operation typically several times slower than integer multiplication

performance
in usual programming practice one wouldn t bother and simply multiplying by the floating-point representation of 180 ï because multiplication is so much faster than division

usability
multiplication is far easier and faster for a cpu to do than division

performance
i found out that integer division is much slower than multiplication unfortunately

performance
multiplication is much faster than division

performance
the compiler or the jit is likely to convert the first case to the second anyway since multiplication is typically faster than division

performance
multiplication is usually faster than division

performance
i would also suggest to replace terms like a l1 0.3e1 with as multiplication is faster then division

usability
the cpu operation for float division is much more complicated than multiplication

performance
even simpler and probably even faster because multiplication is faster than division is dav s answer which is the most natural algorithm.

performance
integer division is about an order of magnitude slower than multiplication on current cpus.

performance
on modern processors float division is a good order of magnitude slower than float multiplication when measured by reciprocal throughput

performance
multiplication is usually faster than division

performance
on most processors division is slower than multiplication for the same data types

performance
according to this author integer multiplication can be 40 times faster than integer division

performance
floating point multiplication is faster than division so if speed is relevant

usability
or is there something about multiplication that is more convenient than division in programming

performance
most optimizing c compilers optimize it out to a multiplication operation which is much faster than division it can be done only if the divisor is constant though

performance
and division may be slower than multiplication or may still be fast

performance
both works but division is generally slower than multiplication

performance
if the latter yes floating point multiplication is generally faster than division

performance
division is about 10 times slower than multiplication

performance
as a rule of thumb multiplication is faster than division on all cpus

performance
i have heard division takes more time then multiplication but beyond that i could not determine whether writing this in one line or multiple assignment lines was more efficient

performance
on some machines division is much slower than multiplication but on most machines j multiplies and j divides will run a lot faster than 2 n-2 multiplication and one division

performance
if the numbers are huge dividing x by b might be betterâ division is usually slower than multiplication but getting out of the huge-number domain early might help more than avoiding division

performance
on some machines division is much slower than multiplication but on most machines j multiplies and j divides will run a lot faster than 2 n-2 multiplication and one division

performance
removing division operations by passing through the inverse into the shader is another useful tip as division is typically slower than multiplication

performance
division algorithms are slower than multiplication algorithms in most cases

performance
in a 64 bit application this code will be a lot faster than in a 32 bit application in a 32 bit application multiplying two 64 bit numbers take 3 multiplication and 3 additions on 32 bit values - however it might be still faster than a division on a 32 bit machine

usability
for example public static void copy reader r writer w throws ioexception is more useful reusable than public static void copy filereader r filewriter w throws ioexception

performance
i had previously sent those commands via bluetooth but the connection fails too often to be useful and is slower than usb

performance
if your watch doesn t have usb support moto 360 and other induction only charging you need to enable bluetooth debugging slower than through usb though

reliability
on the other hand a usb connection is far more reliable better supported and of course has the inherent advantage of speed and since it is well supported does not suffer from all the pitfalls bluetooth connectivity does

usability
it depends on your requirements but setting up a usb connection is sometimes easier than managing a bluetooth connection

performance
here is a recent benchmark of jython 2.5.2 running on jvm 7 where jython is slower than pypy but faster than cpython

performance
however svn protocol is much faster so i suggest using collabnet svn for performance reasons

performance
however svn protocol is much faster so i suggest using collabnet svn for performance reasons

performance
snappy is also significantly faster than lzo for decompression

usability
these formats allow various data compression codecs note that snappy is now much more popular than lzo and can also provide other benefits such as fast serializable deserialization column pruning and bundled metadata

performance
snappy also consistently decompresses 20 + faster than lzo which is a pretty big win if you want it for files you re reading a lot over hadoop

usability
in addition x86 is furhter complicated because there are generally separate documentation manuals for 32 bit and 64bit processors i m not familiar enough with arm to comment here

usability
x86 allows easier debugging - edit and continue is not supported when running in 64bit mode

performance
faster than on x86 32bits but slower than x64 64bit

performance
64bit amd and later intel machines run faster than 32-bit x86 machines because when amd designed the new instruction set they added more cpu registers and made sse math the default

usability
x86 allows easier debugging - edit and continue is not supported when running in 64bit mode

memory
however my tests have shown that on a 64bit system an anycpu prefer 32-bit application which i confirm runs 32-bit can allocate more memory than an x86 one

performance
x86 is considerably slower a few clocks plus a clock or so per function argument while 64bit is much less because most function arguments are passed in registers instead of on the stack

performance
64bit code is not actually faster it is usually a bit slower than x86 code

performance
stringtokenizer is faster than stringbuilder

usability
4 is nvidia cuda technology is easier more flexible than ati brook+ language

usability
even though aurora has better capabilities i prefer marathon due to auroras complexity overhead and lack of ui for control api

performance
if that is so you might find that timsort runs faster than quicksort

performance
a side note since you want all rows using union all is faster since it does not need to perform a distinct to eliminate duplicates

performance
keep in mind that union will return a distinct list - duplicates will be removed but it will perform slower than using union all which will not remove duplicates

performance
union distinct is slower than union all but you may need it for de-dupping.

performance
however the tables are huge and the union all i read its faster than distinct takes forever to execute even with just two tables let alone 6

performance
union all is generally faster than using distinct or grouping

performance
i am currently using union all and a distinct in the outer query as this proved much faster than using union s for the uniqueness of data

performance
union all is generally faster than using distinct or grouping

memory
however for some reason ulkit is making a background-size larger than my background-image

usability
the internal view hierarchy of uialertview is much more complicated than it appears and starting from ios 7 it is not even added to any uiwindow so it s no big surprise that it doesn t participate to the responder chain as you expect

usability
this should handle all cases of setting the properties makes them easier to implement in your inherited classes and cleans things up

usability
multiple inherited makes it easier to compose classes from small mixin base classes that implement functionality and have properties to remember state

usability
now in .net for desktop controls you can use inherited which is much more powerful than the old tag properties anyway

memory
i ve found stripes to be really effective and surprisingly lightweight....it aims to be more lightweight than struts

performance
key derivation algorithms such as bcrypt and pbkdf2 aka rfc2898derivebytes are much slower than standard hash algorithms

usability
among other things the apple template code will include creation of a glkbaseeffect which provides some shader functionality that seems to be required in order to be able to draw with opengl-es 2.0

performance
i want smooth fadeout fadein animations instead setting visibility where fadeout is slower than fadein animation so i ve used enteractions and exitaction of datatrigger

reliability
rdiscount seems to be much faster and more reliable than bluecloth

performance
tcmalloc is faster than the glibc 2.3 malloc.

performance
tcmalloc is faster than the glibc 2.3 malloc available as a separate library called ptmalloc2 and other malloc s that i have tested

usability
restructuring of the database to just add an salt field is better option or the only one really if your going to do it properly but you could use your currant hash field to store the salt as other person posted

performance
you ll probably need to get data anyway so the unique salt is probably faster too because you won t need to calculate the hash over username

performance
you ll probably need to get data anyway so the unique salt is probably faster too because you won t need to calculate the hash over username

usability
prepending a salt is also more powerful than directly setting the seed values because in addition to changing the internal state of the hash if the salt is not a multiple of the digest block size then it can also perturb the alignment with which the input is fed into the hash function

memory
likely not as cheap as xor against n values but seems like there s possibility for better quality results at a minimal extra cost especially if the data being hash is much larger than the salt value

memory
likely not as cheap as xor against n values but seems like there s possibility for better quality results at a minimal extra cost especially if the data being hash is much larger than the salt value

usability
you need to use tolist to convert it from ienumerable because the ilist interface supports more functionality than the ienumerable interface

memory
yes i understand that ienumerable is much more lighter rather than ilist but anyway there is a lot situations where we need to have ilist instead of ienumerable and in this approach we need to cast ienumerable to ilist isn t it

memory
yes i understand that ienumerable is much more lighter rather than ilist but anyway there is a lot situations where we need to have ilist instead of ienumerable and in this approach we need to cast ienumerable to ilist isn t it

performance
i ve found that using a simple for-loop iterating over all elements in the string and comparing using charat performs faster than indexof or regex

usability
old thread but in my experience writing server-side code with ucma is somewhat easier than trying to use ucwa - and all that ucwa really is is a ucma application sitting on your lync s4b server with a rest wrapper

usability
i read somewhere that nemerle s macro service is more powerful than boo s

performance
i have no concrete figures on that but from my own experience i d estimate that instrumented tests are around 100-400 slower typemock seeming to be faster than ms moles

performance
if we put our filter in between these calls either in getter or setter setter is more efficient as it is called only when filters change we modify original filtered list with our filter and return it back through the getter

performance
if we put our filter in between these calls either in getter or setter setter is more efficient as it is called only when filters change we modify original filtered list with our filter and return it back through the getter

memory
why atom-editor uses more memory and takes more time to start as compare to sublimetext editor

performance
sublimetext has better performance than atom-editor

memory
the main advantage of the debian image is the smaller size â it clocks in at around 85.1 mb compared to around 200 mb for ubuntu

reliability
as for debian being more stable than ubuntu for using as server it can be true in very rare occasions where the package is very obscure

memory
the main advantage of the debian image is the smaller size â it clocks in at around 85.1 mb compared to around 200 mb for ubuntu

memory
i believe ubuntu is smaller debian wheezy smaller still or even alpine for tiny start point

usability
textureview will display opengl-es rendering but is much more flexible than glsurfaceview and will follow the normal layout hierarchy in android which allows views to be moved on the display

usability
as for me jboss implementation is smaller than the whole glassfish so i m using

usability
but in my location jboss is more popular than glassfish so i have a idea

memory
jboss has a larger community than glassfish

memory
jboss has a larger community than glassfish

usability
glassfish v3 vs jboss 7.0 in using in production environment i know more people use jboss the application server but glassfish has more features and stability over jboss

performance
for semantic zooming you ll notice that d3.js is significantly faster than protovis

performance
for semantic zooming you ll notice that d3.js is significantly faster than protovis

usability
the team behind protovis has since created d3.js so this is likely a better option than protovis

usability
overall kohana is more flexible than codeigniter and a great base to build a web application and api on

usability
you can use either to create a new memory block which is separate from the original but naturally strdup is simpler since it doesn t require a separate malloc strlen call

memory
you should know that strdup allocates more memory and returns its pointer which you then overwrite the original pointer returned by malloc so it will be impossible to free that memory since you no longer have the pointers

performance
nginx is faster and lighter but many people find it easier to work with apache because of .htaccess support nginx does not have an analog due to performance concern

usability
nginx is actually quite a lot easier than apache in my opinion

performance
for example nginx is much faster than apache

usability
apache is more popular and has more features nginx is smaller and faster and has less features

performance
nginx is faster than apache and the configuration is easier

performance
i would really like not to run both apache and nginx i did switch everything to apache yet found it loaded my proxies slower than nginx

performance
nginx is typically faster than apache but with a low request server it hardly matters

performance
note that in any case for increased security and fast static file css js delivery you might want to add a reverse proxy layer nginx usually provides better performance but apache works as well before the nodejs python server

performance
i know nginx has lower memory footprint and little faster than apache in serving static files

performance
nginx is still faster and i might choose it but apache isn t asleep

performance
is nginx + php-fpm is suppose to do server operations much faster than apache + mod-php due to efficient usage of memory and other resources

performance
and finally from my experience nginx is faster than apache

performance
i have recently read that nginx is faster than apache

usability
for me apache is easier to use but i prefer nginx as it is much faster

usability
also you should consider using nginx as server that s more flexible than apache

memory
nginx uses less memory than apache given the size of your setup i would definitely recommend that

performance
in fact nginx can use select instead of epoll if you compile it with the --with-select_module option and i bet it will still be more efficient than apache

performance
nginx or other server is not much more efficient than apache

memory
also nginx uses a lot less memory than apache

performance
as an added benefit nginx can also serve static files much faster than apache and nginx also uses much less ram and can handle much more connections

usability
however my experience is that configuring it in apache is significantly more complex than configuring it in nginx and even with worker it still is not quite as efficient with nginx

performance
tornadoweb and nginx are popular web servers for the moment and many benchmarkings show that they have a better performance than apache under certain circumstances

performance
serving static files with nginx is much more efficient than with apache

usability
apache is more popular and has more features nginx is smaller and faster and has less features

performance
very fast static assets nginx is faster than apache at serving static assets css js images ... and uses very little memory to do so

usability
nginx can be configured to only respond to requests matching a predefined pattern far easier than with apache

performance
when i was googling info on nginx it appears to be faster than apache and works well in serving static pages

memory
i know nginx has lower memory footprint and little faster than apache in serving static files

usability
i am not going into how to do rewrites on nginx because it is much more complicated than apache

performance
we have a few clients who have very high traffic sites running apache slower than nginx with varnish in front of it and they get way more traffic than you are saying with little to no performance problems

usability
i also know there is nginx and haproxy although i have never used either of them and have a lot more experience with apache

performance
nginx works great by itself and will likely be much faster than apache

usability
id love to know how to solve this since using nginx sometimes is a better option than apache and having this issue with fuelphp framework and not being able to use this two great tools together is awful

performance
for example nginx is considered faster than apache and a nodejs application is considered faster than a php application

performance
next you ll find that the threading model of nginx is much more efficient than apache s for what you re doing

performance
i have configured tomcat with apache web server in past and never slowness problem before and practically speaking nginx is said to much lighter and faster than apache web server

usability
any one of the reverse proxy systems can likely do this nginx is popular too and generally has easier configuration than apache but i ve never used it with https

performance
there seems to be a consensus that nginx serves static content faster than apache

memory
also have a look at nginx for example it is fast and uses less memory than apache to handle client connections

performance
nginx will definitely work faster than apache

performance
serving static files with nginx is much more efficient than with apache

usability
i ve been attempting to upgrade to php 7.1 using phpbrew and elected to install it with nginx as i read everywhere that it was simpler than apache not that simple in my humble opinion

performance
nginx â without any optimizations done â is much faster than apache

usability
but doing that kind of things with apache is rather painfull and is easier with nginx

memory
servers like lighthttp and nginx can handle large amounts of traffic in much less memory than apache if you can sacrifice apache s power and flexibility or if you just don t need those things which often you don t

performance
paradoxally it does not mean that apache is faster than nginx it just means that on 1 2 3 .

performance
not only is nginx supposedly faster than apache at delivering static content but this also offloads your rails application for every image stylesheet javascript or whatever other static content

performance
next you ll find that the threading model of nginx is much more efficient than apache s for what you re doing

performance
hi everyone i need help with this i ve already set up nginx + php and it works great faster than apache my problem is how to setup a multiple projects in one ip

performance
nginx is faster than apache handles slow clients better and is generally easier to use

performance
i will add that i ve often heard that nginx is faster than apache for serving static files to the point that it s sometimes worth using nginx for static files and reverse proxying to apache for dynamic content

performance
i ve read that nginx is faster for static pages but there are questions about its performance with php compared to apache s performance with php

usability
also nginx s configuration is much more flexible than apache and by having it on the front end it gives you a lot of flexibility

memory
nginx is very fast much lighter than apache

performance
for example nginx is much faster than apache

performance
you can serve it from for example nginx varnish which are usually faster than apache

usability
id love to know how to solve this since using nginx sometimes is a better option than apache and having this issue with fuelphp framework and not being able to use this two great tools together is awful

performance
i read that nginx is faster than apache and i want to try it with some of the projects and leave the others with apache

reliability
apache mod_php is much more stable and cleaner while nginx will often deliver http bad gateway error coded in 502

performance
nginx is typically faster than apache but with a low request server it hardly matters

performance
for static file serving i found nginx performance lot faster than apache

performance
i am not an expert in deployment but in my experience nginx is much faster and more friendly to django compared to apache

performance
from my own experience mtl4 is much faster than ublas and it is also faster than eigen

memory
i can t find any way to make the treeview s height smaller or the tabcontrol s larger

usability
getting your project migrated to vb.net is certainly easier when you keep the old vb6 controls

usability
also developing enterprise application is such new languages java c# vb.net rubby is easier that vb6 because they rely on frameworks every body can write c# java code that function but it requires tricks good practices and some of imagination to write vb6 strong and rehusable code

usability
biggest of all is that adding new features to your vb6 application is more expensive than it would be if the application was in a better language like c# or vb.net

usability
yes they are different but you can hardly say that the vb.net version is less capable than the vb6 version

usability
vb.net appears much more complex then vb6 and the learning curve is tough

usability
avoiding them by modifying vb6 is lot easier than fixing the issues in vb.net

usability
quite apart from the fact that the language vb.net is far more feature rich than vb6 the fact that you have developed in vb.net means that you have made extensive use of the .net class libraries including system.security.cryptography that you give as an example

usability
quite apart from the fact that the language vb.net is far more feature rich than vb6 the fact that you have developed in vb.net means that you have made extensive use of the .net class libraries including system.security.cryptography that you give as an example

usability
biggest of all is that adding new features to your vb6 application is more expensive than it would be if the application was in a better language like c# or vb.net

performance
the ipb which has less queries runs slower than mybb with more queries

performance
the ipb one has less queries used only 14 on average but it runs slower than mybb with more queries used average on 20

memory
note that diffseconds can cause an overflow when the difference becomes larger than int32.maxvalue error the datediff function resulted in an overflow

performance
an icmp packet has a header that is 20 bytes and is probably going to be slightly slower than udp

usability
you could use slick2d it is way easier to use and works with lwjgl

usability
i think reductio will make this easier but with raw crossfilter this would look something like

usability
owl has more structure than rdf

usability
i ve created an application with this library instead of jgraph because i thought that jung is easier to learn than jgraph for newbies even if it provide less features

security
however note that post is not much safer than get

performance
but generally post is slower and would be bigger in size than a get request

usability
for eps is the same situation the post script is more readable but you should apply all necessery transformations on object before get its size

memory
so i have a post system and i want the box to get larger as more post come in

security
get method is not safer than post data never trust datas coming from the client side

performance
why get method is faster than post

security
both get post user can put any thing in it and you must filter any input that user make it in your form example the value in textfiled sent to server by post method and that don t make it safer than get method the difference between them that the textfiled value doesn t visible in url

usability
when taking input we can use either get or post.the input is shown in the url when using get but not when post is used.is there a situation where get is more useful than post

security
post requests are no safer than restful requests which are no safer than get requests

memory
to answer part of your second question with .net if the post is larger than maxrequestlength part of the .net configuration but smaller than maxallowedcontentlength part of the iis configuration you can create a custom http module to get at the portion of the post that came through

performance
is type get faster than type post cause i am curious how both work

performance
get is simpler and faster than post and can be used in most cases

performance
why get method is faster than post

performance
i used get because is faster than post if you need it just to get a list of element for suggestions

usability
as a pragmatist i m inclined to use get because implementing it is way simpler than post

usability
using get is much easier than using post for most of developers

performance
post has a higher overhead marginally if we re honest but it all adds up but it doesn t become part of the url so can t be seen by say a casual observer over the user s shoulder - whereas get can

performance
usually in ajax get method is faster as it doesn t involve proccessing post fields and as you are only getting information i would stick it

memory
for example on the blog page of my current project i have two widgets in the sidebar one for latest tweets and one for latest music news however as you can see on this page the content of the blog post all test posts... are much longer than the height of the two widgets and would of course get larger as more post are added

performance
get is slightly faster because the values are sent in the header unlike the post the values are sent in the request body in the format that the content type specifies

memory
the usual wait time of the post is not too long not too larger than get so i don t think that should be an issue and post always gets back with a 200

memory
you ll hit problems with larger submissions and file-uploads as the size limit for a get is much smaller than a post

usability
get would obviously allow for a user to change the value a lot easier than post so suitable checks for existance and ownership of the record would be important

security
get method is not safer than post data never trust datas coming from the client side

security
post request are safer than get but that does not mean are invulnerable

memory
post requests can be much larger than get requests as get requests are limited by the maximum length of a url

performance
you should check this thread why get method is faster than post

usability
a post has broader application and is generally used to send persistent data to a server in fact prescriptively get should not be used for this purpose

usability
get is simpler and faster than post and can be used in most cases

usability
while users can manipulate post it s far easier to manipulate get

memory
a get request will be slightly smaller than a post although using websockets would give a more accurate figure

security
one more thing some guys would misunderstand that post is safer than get as user can not see the sent data

usability
using get is much easier than using post for most of developers

performance
i run the ab test several times with same results post is faster but get is lighter

performance
i have seen other people asking the same question why get method is faster than post

security
and apart from common misleading information where post is safer than get it is not

security
is post safer than get

usability
is post more compact than get since get requests have to be url-encoded

usability
have a look at this post it is probably easier to get the selected radio button by changing your itemscontrol to use a listbox with the existing datatemplate

usability
i think using post is more elegant and has more options for further development than passing them via get

usability
from a hacker s point of view a get forgery is much easier than post forgery at the first you only post a link at the second you need to point to a malware website with hidden iframe and autosubmit forms but both of them fail if tokens are checked

performance
get is always faster than post

security
use post its safer than get if you use rest

security
post is a little safer than get because the parameters are not stored in browser history or in web server logs. also data is not displayed in the url

performance
get is always faster than post

usability
post is a little more complex than get though

usability
from a hacker s point of view a get forgery is much easier than post forgery at the first you only post a link at the second you need to point to a malware website with hidden iframe and autosubmit forms but both of them fail if tokens are checked

memory
more over it seems that get requests are more lightweight than post under high load

usability
in my opinion the second way to achieve this is better because using get is not thats ecure in my opinion.it s easier than using post

security
when you use post data is a alot more safer than get and you can send large no

performance
the get is usually faster because it has no encapsulation sends data via url usually with a 255 character limit as post exists encapsulation by being sent by the body of the http request

security
i just want to know if i use post method for login api then is it safer than get method

security
however post data are not much safer than get data anyway

usability
get would obviously allow for a user to change the value a lot easier than post

performance
i used get because is faster than post if you need it just to get a list of element for suggestions

usability
sometimes get is a better option in those read-only scenarios because it makes your url scheme richer and avoids these sort of post warnings

performance
get is faster than post

usability
another reason but rather a minor one is that get is easier to exploit that post as there are more ways to trigger get request than to trigger post request

usability
i m sure there s a work around to use get for emails but the alternative post is much more easier and doesn t require any hacks to get around

usability
post gives you more options and dosn t have a limit on parameter query string length like get the only negative is post is slower by a couple of milliseconds to create the request

performance
however a post request is less efficient as a get request - bear that in mind and only use post if you really need to

performance
post has worse performance than get

memory
get requests have smaller limits than post in the specs

security
regarding your question about safety -- the answer is post is absolutely no safer than get

performance
we provide a number of support resources which may get faster response than post on third party sites including the virtuoso users mailing list public support forums and confidential support cases

performance
it is said that get method is faster than post but i don t know why is it

usability
this would make things considerably easier as the android library has native support for json serialization and making http get requests to restful urls is much simpler than http post requests it s not a huge deal but just less stuff you have to worry about

memory
you ll hit problems with larger submissions and file-uploads as the size limit for a get is much smaller than a post

security
post request is a little safer than get because the parameters are not stored in browser history or in web server logs

reliability
characters post is more robust and secure than get

performance
so congratulations - you can pat yourself on the back your avx routine is indeed about a third faster than the sse routine tested on haswell i7 here

performance
i expected avx to be about 1.5x faster than sse

performance
the question is avx scalar is 2.7x faster than sse when i vectorized it the speed up is 3x matrix size is 128x128 for this question

performance
i have code that does the same thing but the avx version is considerably slower than the sse version

performance
for small buffers hot in l1d cache avx can copy significantly faster than sse on cpus like haswell where 256b loads stores really do use a 256b data path to l1d cache instead of splitting into two 128b operations

performance
the question is avx scalar is 2.7x faster than sse when i vectorized it the speed up is 3x matrix size is 128x128 for this question

performance
buf1 buf2 and buf3 is small enough to located in l1 cache and l2 cache l2 cache 1mb .both of sse and avx is band width limited but with the datalen increase why do the avx need more time than sse

performance
i have code that does the same thing but the avx version is considerably slower than the sse version

performance
now for sse is clearly faster and for the smaller values it s nearlly as fast as avx

performance
so the avx version does indeed appear to faster than the sse version both for the original implementations and the optimised implementations

performance
as expected the performance got better with both and avx 2 faster than sse 4.2 but when i profiled the code with papi i found out that the total number of misses mainly l1 and l2 increased a lot

performance
in addition seeing arp being slower than icmp doesn t necessarily mean icmp isn t deprioritized---it might mean bandwidth is insufficient to hit the limiting threshold

memory
the other suggestion keep repeating until x stops changing does not work either because for non-perfect squares x will alternate between the floor and the ceiling of the root â because of integer mathematics the term n x will alternate when x is slightly smaller or slightly larger than sqrt n

usability
timsort is used by python and java for their sort methods and is rather supernaturally fast but it s a more complex algorithm than mergesort which matters if you re working in something like c - so if you just need something that works pretty well and is simple go with mergesort

usability
since you re presenting multiple columns a gridview control is a better alternative to checkboxlist

usability
since you re presenting multiple columns a gridview control is a better alternative to checkboxlist

performance
for reading large csv files you should either use readr read_csv or data.table fread as both are much faster than base read.table

performance
fread performs faster and more efficiently than read.table but read.table produces less no errors on the same data set

performance
fread ... is extremely fast 10 - 100 times faster than read.table ... or read.csv ... for large datasets

performance
interestingly for 1 million rows per file the optimised version of read.csv and read.table take 422 and 430 more time than fread whilst without optimisation this leaps to around 1500 and 1005 longer

performance
you might want to give the data.table package a try check out the fread function which is much faster than read.table

usability
either way gitolite is easier to maintain and more up-to-date than gitosis see how do programs like gitolite work

usability
anyway the most important issue is that web2py is easier than django pylons php and rails

memory
and web2py is more lightweight than django rails whatever on pretty much all counts

memory
to answer klochner both seems quite popular but ruby is not a language that i am familiar with and django seems more heavy and complex to me than web2py

usability
i think you ll find that web2py is even easier to learn and use than rails and django

performance
but i d think bignum subtraction is a little slower than bignum addition

performance
it s possible though that software could mess things up by making subtraction slower than addition - but that s unlikely

memory
i was thinking that there could be an issue if the result from the addition is bigger than what 15 bits can represent 32767 or if i get a negative number in the subtraction

performance
this is a hold over from older compilers and interpreters on old chip architecture that would do addition slightly slower than subtraction

performance
here it is conceivable that subtraction is slower than addition

performance
in my experience btrace overhead is far less noticeable than any profiler depending on activity of course - if you want to trace execution of all methods this will be expensive no matter what

performance
in my experience btrace overhead is far less noticeable than any profiler depending on activity of course - if you want to trace execution of all methods this will be expensive no matter what

performance
2 readability library content is passable slower on average than goose but faster than boilerpipe

usability
phusion passenger 4 enterprise bring many advantages over has more features than puma and rainbows for example it has out of band garbage collection can dynamically adjust the number of processes based on traffic completely automates rolling restarts so you don t need scripting etc

performance
nonetheless i tried to compare the sum of all test speeds and in some cases nunit is faster and in other cases mstest is faster

usability
nunit has better support for parameterized tests than mstest

performance
from my experience mstest is much slower than nunit

performance
the best testdriven.net disables all instrumentation that mstest does so it makes mstest blazing fast - much faster than nunit for example

performance
nunit is faster as compared to mstest

performance
thus i suspect when people say that nunit is much faster than mstest it is because of the loading and updating delays but the actual test execution time appears to be very similar

performance
from my experience mstest is much slower than nunit

usability
sriwantha mstest is a simpler framework than nunit

usability
sriwantha mstest is a simpler framework than nunit

performance
thus i suspect when people say that nunit is much faster than mstest it is because of the loading and updating delays but the actual test execution time appears to be very similar

memory
have a look at sift and surf and at vlfeat which has a good sift implementation and also implements mser and hog and is much smaller than opencv

memory
if a function is static thus not exported anyway and only called once within your code and you never use a pointer to the function chances are good that gcc will decide to inline it automatically as it will have no negative impact the binary won t get bigger by inlining it only once

memory
callee is too large message is printed by c1 when the size in bytecodes of the method being inline is larger than maxinlinesize 35 multiplied by nestedinliningsizeratio 90 on each next level of inlining

performance
a similar argument can be made for inlining functions inline is generally faster but will remain in the same big-o complexity class although there is an additional size tradeoff inlining makes your compiled program larger if the code was being used in many places

usability
ass supports more formatting options but srt is a simpler format and can be modified with the force_style option in the subtitle filter

usability
srt is simpler than ass but lacks features so you may need to use the force_style option in the subtitle filter

usability
ass supports more formatting options but srt is a simpler format and can be modified with the force_style option in the subtitle filter

usability
adfs has more powerful claims transformation capabilities than acs

memory
by the way i would suggest creating rar self-extracting archives instead of zip self-extracting archives as with rar compression the exe file with the right switches for best compression using additionally also solid archive options could be much smaller than with zip compression

memory
i ve heard that rar decompression requires much more memory than zip decompression

memory
i ve heard that rar decompression requires much more memory than zip decompression

usability
i found the production of wmv much better and easier than flv because all windows flv encoders i tried are not really good and stable whereas pretty much every tool can natively output wmv

performance
afaik malloc is not slower than memcpy

performance
afaik malloc is not slower than memcpy

usability
note that lxml is probably a better option than beautifulsoup for this kind of task nowadays for the reasons given by beautifulsoup s author

performance
since you re using lxml why not use it in a more direct manner lxml is believed to be faster than beautifulsoup

performance
lxml is much faster than beautifulsoup and probably the fastest parser available for python

performance
lxml is faster than beautifulsoup i think and has much better functionality while remaining relatively easy to use

performance
lxml is much faster than beautifulsoup and probably the fastest parser available for python

performance
according to the above posts and my own experience lxml is definitely faster than beautifulsoup

performance
note that using the beautifulsoup parser is a lot slower than lxml s default parser

usability
lxml is significantly more powerful and robust than beautifulsoup in my experienced opinion

performance
according to the above posts and my own experience lxml is definitely faster than beautifulsoup

usability
i found a solution to this problem using beautifulsoup at beautifulsoup-where-are-you-putting-my-html because i think it is easier than lxml

performance
i would recommend lxml for html parsing it s simple and considerably faster than beautifulsoup can be as much as two orders of magnitude

usability
lxml also has more features and offers beautifulsoup too

performance
you ll probably find that lxml runs faster than beautifulsoup but in my uses beautifulsoup was very easy to learn and use and handled typical crappy html as found in the wild well enough that i don t have need for anything else

performance
pyquery is based on lxml so it s also much faster than beautifulsoup

performance
speed isn t important here but in other applications it is good to know that regexes are very fast 100 times faster than lxml and 1000 faster than beautifulsoup

performance
edit don t use this for html work use the lxml library it s python based and much faster than beautifulsoup

performance
regarding beautifulsoup lxml is more efficient and in my experience can handle broken html better than beautifulsoup

performance
it s generally accepted that lxml is faster than beautifulsoup ref

performance
i prefere lxml it s a harder to understand but much faster than beautifulsoup

performance
i ve found that even if lxml is faster than beautifulsoup for documents that size it s usually best to try to reduce the size to a few kb via regex or direct stripping and load that into bs as you are doing now

usability
lxml enables you to search for elements using xpath which i think is easier than using beautifulsoup s api

performance
according to some benchmark tests lxml is nearly 100 times faster than beautifulsoup

performance
how can i find all div and span tags with order preserved.with beautifulsoup it is very simple but i switched recently to lxml since it is much faster than beautifulsoup

performance
lxml is also much much faster than beautifulsoup

performance
it uses lxml underneath and is much faster than beautifulsoup

usability
i found a solution to this problem using beautifulsoup at beautifulsoup-where-are-you-putting-my-html because i think it is easier than lxml

performance
alternatively you can use lxml module which is lot faster than beautifulsoup

memory
you might want to look at one of these options if you re running in a vm since xfce is slightly lighter weight than gnome although not all that much lighter these days

memory
you might want to look at one of these options if you re running in a vm since xfce is slightly lighter weight than gnome although not all that much lighter these days

memory
xfce runs much smaller than gnome and is full featured

memory
xfce runs much smaller than gnome and is full featured

memory
you might want to look at one of these options if you re running in a vm since xfce is slightly lighter weight than gnome although not all that much lighter these days

memory
unfortunately i dont understand what you mean by stating ratingbar is smaller than textview

memory
the thing is like ratingbar is smaller than the textview i don t get a correct aligment

performance
qvector will usually give better performance than qlist because qvector always stores its items sequentially in memory where qlist will allocate its items on the heap unless sizeof t sizeof void and t has been declared to be either a q_movable_type or a q_primitive_type using q_declare_typeinfo

performance
in term of speed square rooting is easy a few arithmetical operations for some newton-like method but it is not clear what asin does probably quite costly cos is likely to be one order of magnitude slower than sqrt and thus one square root is likely to be quickier than those two transcendental function calls

usability
webstorm + pycharm + rubymine + phpstorm though to be fair rubymine has more features than radrails atm

usability
which of the two consumes more memory is not defined and depends on the input sequence to be sorted as well as on algorithm tuning parameters see the comments to one of the answers to why quicksort is more popular than radix-sort

security
typically you would not allow a http client to determine the uri of a new resource so a post to blog would be safer than a put to blog article-uri although http does cater for appropriate responses should the server be unable to honour the intended uri

usability
i m very sorry for the long question but i thought instead of dividing the question into several post it is more convenient if they are put into one place

usability
on the php docs link above they say a put request is much simpler than a post request when uploading file along with this advantage what other advantages disadvanatges do the put has got compared to the post

usability
to receive a file in your api i would use a put request simpler than post multipart and fetch the data from the stream php input

usability
on the php docs link above they say a put request is much simpler than a post request when uploading file along with this advantage what other advantages disadvanatges do the put has got compared to the post

usability
side note it looks like you re using the post form of file upload which as the docs say is considerably more complex than put

memory
but keep in mind that the gif color palette is way smaller than png

memory
i m not sure if this matters but the gif is significantly larger than the png files

memory
it might help to reduce your gif file sizes smaller oh and i believe -depth 8 can only be used for png images

memory
since that appears to generate index-color gif files which are smaller than the png files that doxygen generates

usability
the gif format is substantially less capable than png

memory
just press save and give it a name and that photoshop image will be saved into a transparent background png file which presents more colors and it s smaller than a gif file and is as good as a jpg

memory
it will always be a web format which basically comes down to jpg png and gif with gif being very unlikely because of its limitations gif can contain 256 colors at most and is generally larger than png

usability
for example png has better support for transparency than gif or jpeg

memory
but in that regard it is replaced by png which is generally smaller supports alpha transparency where gif pixels are either fully transparent or fully opaque and most importantly gif images are limited to 256 colors

memory
also if i change all to png is not bigger and alos i am using prawn pdf outputting these images so cant use gif

memory
convert it to png 10-30 smaller than gif on average

memory
one thing to note is that gif supports a smaller palette than png - only up to 256 colors

memory
indexed png less than 256 colors is actually always smaller than gif so i use that most of the time

memory
if your png files are coming out larger than equivalent gif files it is almost certainly because your source image has more than 256 colors

memory
icon size indexed png is often smaller than the same gif

memory
i m not sure if this matters but the gif is significantly larger than the png files

memory
a 8-bit png shim is smaller than the same dimension 1 pixel gif and everything will still work as planned

memory
one thing to note is that gif supports a smaller palette than png - only up to 256 colors

memory
if png isn t smaller than gif then your software may be saving it poorly - look for png optimisation progams like pngout and pngnq

memory
gif is smaller because it s based on an colour palette of 256 colours rather than the separate rgb values for each pixel or group of pixels in jpg and png

usability
the gif format is substantially less capable than png

memory
it might help to reduce your gif file sizes smaller oh and i believe -depth 8 can only be used for png images

memory
jpg and png work well for most applications but the files will be larger than gif for very simple graphics

performance
just wanted to add that using strrpos + substr is slightly faster than explode + end

performance
just wanted to add that using strrpos + substr is slightly faster than explode + end

memory
basically it seems like cmmotionmanager is much larger and slower than uiaccelerometer is

performance
basically it seems like cmmotionmanager is much larger and slower than uiaccelerometer is

performance
it s like asking whether sin is faster than sqrt

performance
however i ve seen that object s hasownproperty is much faster than indexof

performance
however i ve seen that object s hasownproperty is much faster than indexof

performance
yes iostream is slower than cstdio

performance
iostream is said to be slower than cstdio but i suggest you use a profiling tool here to find the best set of options here

performance
the quanteda package is faster and more straightforward than tm and works nicely with tidytext as well

performance
mri is faster than jruby

performance
jruby is faster than 1.9 mri matz ruby interpreter the standard in certain areas

performance
lastly if you are frequently finding yourself running long running process i advice you to try jruby which is works much better with long running processes due to jvm lot faster than mri

performance
with these options jruby on rails gives about the same or better performance than mri

performance
jvm hosted languages are generally going to be faster than traditional mri ruby and both java and scala are generally faster than jruby when it comes to raw cpu capabilities

performance
for example jruby is faster than mri jruby 1.7 is faster than jruby 1.6 jruby 1.7 running on hotspot is faster than jruby 1.7 running on j9 jruby 1.7 running on hotspot 1.7 is faster than jruby 1.7 running on hotspot 1.6 jruby 1.7 running on hotspot 1.7 with the c2 compiler is faster than jruby 1.7 running on hotspot 1.7 with the c1 compiler and so on

performance
so it seems like the opposite - mri 2.3 gets 2-5x slower than jruby 9.1

performance
so it seems like the opposite - mri 2.3 gets 2-5x slower than jruby 9.1

performance
does this mean that the old adagio about jruby being faster than mri ruby is gone

performance
mri has a gil so why is it faster than jruby in handling requests

performance
sometimes mri is faster but with the right parameters and warmup jruby was 3 to 3.5 times as fast on my system for this particular

performance
and it sounds strange but jruby scales very well and it s faster than mri with java 7

performance
this really surprised me because i expected mri to be slower than jruby

performance
in my experience xlib via mit-shm extension was significantly faster than sdl surfaces not sure i used sdl in the most optimal way though

usability
one option is to install testdriven.net which makes it easier to run unit tests on any of the major unit testing .net frameworks nunit xunit.net vs tools etc

usability
you could try using c-types with ff which is a regular dll being called by javascript in your add-on this is way better approach that using xpcom because if the interfaces you use in there can change in each ff version indeed you will have to do multiple dlls each for your add-on supported ff versions

performance
it looks like vim is slower than geany

usability
the ansi standard function coalesce is simpler than using nvl and decode which should be obsoleted anyway

performance
coalesce is more efficient than nvl as it only evaluates the second argument if the first is null whereas nvl evaluates both arguments every time

usability
the coalesce function is used here because it is more portable than nvl or ifnull

usability
bitshifts just go easier with hexadecimal than decimal and is often more convenient to read than octal

performance
it is said that phpquery is often faster than querypath because of fewer overall features

memory
if your company s concern is to avoid big unknown libraries which is prefectly understandable i d advise you to stick with lwjgl which is smaller that jogl

usability
i guess the point that the article is trying to make here is that a facade is easier to implement when you already have this command-pattern in place

usability
fortunately model-glue has tight integration with coldspring a popular bean container for cfml and model-glue 3 makes it easier than ever to use coldspring beans in your controllers

performance
at times the get rate is slower than the put rate and we see messages backing up

performance
as i am benchmarking my cluster i discover that for large file my get command is actually slower than put command

performance
i think put and get on ignite cache would likely to be slower than native put and get on my inbuilt key value store

performance
this could mean that put is now slower than get and we have to wait

performance
as i am benchmarking my cluster i discover that for large file my get command is actually slower than put command

performance
since most data-storage mechanisms in-ram in a database etc. get a lot slower as you put more data in them you should ensure you re only timing your http access and not looking at overall crawler throughput including storage

performance
as long as the dataframe is small your assumption that the put process is faster than the get seems true we can fetch all 5 items within one loop of while not q.empty

performance
this could mean that put is now slower than get and we have to wait

performance
at times the get rate is slower than the put rate and we see messages backing up

performance
if anyone has some information on this problem i d really appreciate it - either things you did to make tcpdf faster or just confirmation that it runs slower than fpdf so i can forget about it and just stick with fpdf

performance
tcpdf was always slower than fpdf

performance
your intial hypothesis of toupper being faster than tolower has a logical fallacy

reliability
so yes - toupper is more reliable than tolower

performance
as a side note using toupper is more efficient than using tolower so toupper would be the way to go

performance
you can use string.isnullorempty and toupper method is in general more accurate than tolower

performance
so you can t reject the null hypothesis that tolower is as faster as toupper and thus your experiment has got errors

performance
joe duffy s blog implies using substr is more efficient than strsplit

usability
i was originally using nsscanner because it was easier than nsnumberformatter to use but i ran into the same problem it doesn t parse the entire string just the first number in the string

performance
and now we know that for-loop is faster than while-loop

performance
i have also found that a while-loop is faster than a for-loop

memory
some user-controls s are larger than the tabcontrol and got clipped so i modified its template by wrapping the contentpresenter in a scrollviewer with horizontalscrollbarvisibility and verticalscrollbarvisibility set to auto

performance
deserialization performance is similar with gson over 9x slower than jackson and fastjson about 0.5 faster than jackson

performance
it seems gson is more faster than jackson the average time of gson is about 2ms while jackson is about 16ms does i make mistake when using jackson

performance
gson is faster with smaller documents and jackson is faster with large documents

memory
keep in mind though that jackson is a larger library than gson so depending on your case you might prefer gson to avoid 65k methods limitation

performance
i looked at gson metrics and it seems slower than jackson

performance
according to the performance results at for serialization with databind with strings gson.tojson myobject gson is over 10x slower than jackson

usability
going to go ahead and say that gson is a lot more user friendly albeit less powerful than jackson

performance
gson is not particularly fast but the jackson library can almost compete with most binary serializers jackson is 2-4x faster than gson in most situations and 10-20x faster on utf-8 because it has special code for utf-8

performance
further more gson really seems to be faster than jackson json

performance
in my case i found jackson little faster than gson i used default serialization because so far i don t have a need to customize serialization

performance
also it seems jackson lib has better performance than other packages such as gson which i haven t tried personally

memory
keep in mind though that jackson is a larger library than gson so depending on your case you might prefer gson to avoid 65k methods limitation

usability
gson is simpler jackson is faster

performance
take a look at the jackson json parser it s faster than the one in android and faster than gson and supports streaming

performance
gson 1.6 now includes a low-level streaming api and a new parser which is actually faster than jackson

performance
large objects google gson performs faster than jackson and simple json

performance
gson is not particularly fast but the jackson library can almost compete with most binary serializers jackson is 2-4x faster than gson in most situations and 10-20x faster on utf-8 because it has special code for utf-8

performance
after searched in google found that jackson has better performance than gson i plan to replace gson with jackson in my project but i got a diffrent result when run test code

performance
it seems gson is more faster than jackson the average time of gson is about 2ms while jackson is about 16ms does i make mistake when using jackson

performance
very small object google gson performs faster than jackson and simple json

performance
jackson is faster but the api is 37x more complex than the gson api

performance
under some conditions gson has proven to be a lot faster than jackson there also exists jsonp and json.simple

performance
code looks correct and even at its worst jackson should be no slower than gson

performance
i ve seen questions like this come up before and the general consensus is that jackson is much faster than gson

performance
personally i prefer jackson as according to test benchmarks it s faster than gson

performance
i ve seen questions like this come up before and the general consensus is that jackson is much faster than gson

usability
note also that gson comes with less features out of the box than genson or jackson

memory
unicorn does not use less memory than passenger

memory
also pygtk is lighter than wxpython but i ended up bitting the bullet and using wxpython for the same purpose recently it is heavy but it didn t have any affect on the script performance

memory
of those three ogg would usually be smaller than mp3

performance
ogg vorbis is better quality per meg than mp3 plus no licensing legal issues

memory
of those three ogg would usually be smaller than mp3

usability
i d strongly recommend to go with allegro 5.1.x it s a little bit more difficult than sfml but very functional and easier than sdl it s got nice support and it s compatible with plenty of os

usability
btw why do you want to use fakeiteasy it looks to me less powerful than moq

memory
if you don t need a full dom available and just want to parse and scrape manipulate html elements there is cheerio which is more lightweight than jsdom and still gives you a jquery-like api

performance
i had the same problem with jsdom and switcht to cheerio which is much faster than jsdom and works even after scanning hundreds of sites

usability
i find request + cheerio to be easier than jsdom for tasks like this

performance
if it is unavoidable node.js has good options - try to use the module cheerio which is faster than heavy weight jsdom

performance
i had the same problem with jsdom and switcht to cheerio which is much faster than jsdom and works even after scanning hundreds of sites

memory
by the way if you like minimalistic approach there is also scite editor which is my personal preference for doing small bits of code it s even more lightweight than notepad++

usability
as far as easy goes they are both equivalent in terms of difficulty both provide assembly and c except that the gnu toolchain for avr is more complex than microchip because it requires use of unix command line etc

usability
personally i really like reactiveui which is fairly unusual but does make getting things right an awful lot easier than caliburn

performance
for suitably large examples of each dictionary overcomes the constant factor by which it s slower than std map and will actually do operations like lookup insertion etc

performance
std map though is actually implemented in a way that many operations are slower than dictionary as its size gets large

usability
the immutable dictionary implementation is faster but no less pure in usage than the map implementation

usability
i create new branch add those new features and than i once again made pull request but now the features i implemented in the master branch are also in my new branch so my second pull request has more features than i want to push to the original project

usability
a heartbeat mechanism pull model is definitely easier to implement but a push model is far more efficient

security
tortoise now has an option push new branch that may be safer than force pull or push

usability
dialog makes it easier for you to create a pop-up window with customized contents

usability
generally a pop-up is a better option for a login dialog and a pop-up would allow you to easily navigate to the main page

memory
when typing in the text box the autocomplete pop-up but is bigger than the remaining space in the modal dialog

usability
in the end you have a scheme whose encoder is more complex but whose decoder couldn t be simpler

memory
if the apps versioning number is bigger it s an upgrade and you now need to save that as the last installer versioning

usability
the upgrade sequence is much simpler i have a hard link in the app that points to the latest versioning of the apk the donwload starts and automatically laucnhes the install

usability
using compatibility as the central point in the versioning number makes it easier for users especially if te product is a library to judge whether or not they can expect a smoothe and safe upgrade or not

usability
does anyone know if the upcoming v8 versioning is easier to upgrade or if its easier to upgrade from a certain previous versioning compared to earlier versioning

memory
btw - i went back and did the upgrade again with bigger jumps between versioning actually ran the site after each upgrade and it went perfectly

usability
upgrading a language or service can often have disastrous or unexpected consequences thus sandboxing alternate versioning seems the better approach plus it makes projects immune from os upgrade

usability
itext versioning is 5.5.x but i guess we can upgrade it if the task would be easier with newer versioning

performance
since the upgrade the content authors are complaining that the experience editor performance is much slower than previous versioning

usability
however take some time to consider how you re currently using uialertview and whether you are able to give ios 8 users a better experience by supporting uialertcontroller

usability
there is icefaces which provides more semantic support than richfaces .also you can try nitobi suite which also provides similar kinda solution.if you are not satisfied with any of these i suggest try to write your own part extending the sun faces

usability
for the record jmock as of today supports more complex scenarios than mockito that s why the initial learning curve is steeper

performance
ocaml is faster than racket for most of the benchmarks on languages benchmark game

performance
qtreeview is known for being slower than a qtableview and consume a lot of memory and you are using a plain table model anyways so try with a qtableview

performance
1 i guess dask will be slower than pandas for smaller datasets

performance
when hdf5 storage can be accessed fast than .csv and when dask creates dataframes faster than pandas why is dask from hdf5 slower than dask from csv

usability
pandas is far more flexible for working with data so i often bring parts of dask dataframes into memory manipulate columns and create new ones

performance
nodevalue is a little more confusing to use but faster than innerhtml

usability
if you have a customer who is willing to work with you a bit it might shed some light on the situation to get a crash dump with adplus or maybe simpler with sysinternals procdump when the error message is showing

usability
i looking to use a suite of nlp tools for a personal project and i was wondering whether stanford s stanford-nlp is easier to use or opennlp

usability
i find training in opennlp much easier than in stanford-nlp

performance
but if you will look at the accuracy level stanford-nlp have more accurate detection than opennlp

performance
for that purpose i want to transform the simulink model into a c version and launch it from a matlab script so that the process would be much faster than opening simulink environment

performance
rsa is much faster then ecdsa at verification

memory
if you re interesting in reducing the size of the resulting cookies you should consider using ecdsa rather than rsa to produce the signatures - ecdsa signatures are considerably smaller than rsa signatures of an equivalent security factor

performance
rsa is much faster then ecdsa at verification

performance
ecdsa is much faster than rsa for private key operations so it should definitely be preferred over rsa when high efficiency is required unless rsa is still fast enough something that may very well be the case

performance
ecdsa is much faster than rsa for private key operations so it should definitely be preferred over rsa when high efficiency is required unless rsa is still fast enough something that may very well be the case

performance
it will wrap the original stream in a bufferedoutputstream which is more efficient which is then wrapped into a dataoutputstream which offers additional nice features like writeint writelong and so on

usability
i had worked on jboss for a year and on weblogic for more than a year now my experience with the web logic is good compared to jboss weblogic is more stable and robust it can handle more than 3000 concurrent requests without throwing a single exception where jboss failed to do so and admin console for the weblogic is excellent but i think weblogic is more complex then jboss

reliability
i had worked on jboss for a year and on weblogic for more than a year now my experience with the web logic is good compared to jboss weblogic is more stable and robust it can handle more than 3000 concurrent requests without throwing a single exception where jboss failed to do so and admin console for the weblogic is excellent but i think weblogic is more complex then jboss

performance
if you don t mind the libc allocation functions realloc is even more efficient it wont copy the data on a shrink just mark the extra memory as free and if you grow the memory and there is memory free after it will mark the needed memory as used and not copy either

usability
dynamic memory management on an small embedded system is tricky to begin with but realloc is no more complicated than a free and malloc of course that s not what it does

performance
a fairer comparison would be comparing stringstream to the printf sscanf line of functions which would be slower than strtod but still faster than stringstream

performance
the reason why the vpn is slow is well because your vpn is likely 50 to 100 times slower than your lan local area network

usability
i would advise you to try wicket it is very easy to learn much easier than jsf and it let s you re-use many existing components as well

performance
i m in the hate it part so anything i said is biased plus in our test prototypes developing in wicket was faster than jsf

memory
owing to the fact that the screens density on the tablet is smaller android therefore uses the images in the mdpi folder for the tablet and the slightly bigger ones in the hdpi folder for the phone

memory
owing to the fact that the screens density on the tablet is smaller android therefore uses the images in the mdpi folder for the tablet and the slightly bigger ones in the hdpi folder for the phone

performance
objectdatasource also allows for more efficient paging than a simple sqldatasource i m assuming that s what you re using

performance
1 is comparison via gethashcode check if the hashcode of both objects are the same faster than equals

usability
in the equals method only if you re certain the ensuing equals implementation is much more expensive than gethashcode which is not vast majority of cases

usability
in the equals method only if you re certain the ensuing equals implementation is much more expensive than gethashcode which is not vast majority of cases

performance
if you do not implement gethashcode union will call equals which will work but is slower than gethashcode

performance
and that is for performance reasons assuming that a gethashcode implementation should always be much faster than an equals implementation

performance
even though gethashcode itself should be fast it s not mostly faster than equivalent equals

performance
it is clear without any performance tests that native javascript for-loop is faster but there is no big difference for small arrays like 10-20 small items

performance
i am just starting to learn about the streams and parallel in java and i was wondering why a normal for-loop takes less time than intstream paralleled at adding items to an arrays

performance
the for-loop is faster than the foreach-loop if the arrays must only be accessed once per iteration

performance
use a for-each loops to go through a range it s not as fast as using a variant arrays but keeps things simple and offers better speed than a for-loop

performance
running a quick benchmark it seems that the for-loop is 4x faster even in the worst case where you have to replace every single time and you construct a new arrays to hold the replacements

performance
would an arrays be faster than a for-loop in this case

performance
it returns a byte arrays of all the pixels which can be iterated much faster than a for-loop with a call to getpixel inside nested inside another for-loop

performance
when you know both objects are arrays method is a faster way to check equality than for-loop

performance
when summing an arrays over a specific axis the dedicated arrays method array.sum ax may actually be slower than a for-loop

memory
to use this in a loops you can write a simple for-loop which always checks if the index stil is smaller than the arrays length

performance
for example sometimes a for-loop is faster than the built-in arrays methods in some browsers

memory
as mentioned above as you remove items the arrays gets smaller so a for-loop is probably not the best solution

reliability
i ve used it for convenience a for-loop is much more reliable for converting an htmlcollection to an arrays

performance
the for-loop is faster than the foreach-loop if the arrays must only be

performance
iterating pair-wise you d normally do something like but iterating over an arrays is faster than using a c-style for-loop

usability
with one arrays one can do which is easier than a for-loop

performance
the for-loop here is more efficient for 2 reasons a you don t have to construct a temporary arrays of tuples like with zip and b it returns false as soon as a non-match is found

usability
note that you should check if index is within arrays bounds in such cases and that system.arraycopy is more efficient and arguably simpler than a for-loop for copying arrays

performance
running a quick benchmark it seems that the for-loop is 4x faster even in the worst case where you have to replace every single time and you construct a new arrays to hold the replacements

performance
thus the for-loop is faster than the foreach-loop if the arrays must

memory
it turns out i had a hard coded maximum index in my for-loop which was bigger than the arrays i was trying to assign to

performance
this is the reason why working with the higher-dimensional arrays ends up being so much faster than the for-loop -based code

memory
in such a simple arrays you shouldn t be concerned about memory usage but the for-loop consumes less memory than foreach because foreach uses an internal copy of the arrays

performance
i completely failed to check that assertion and just jumped into the analysis of how the enhanced for-loop is faster on arrays than lists

performance
when you know both objects are arrays method is a faster way to check equality than for-loop

performance
in this case instead of generating two large matrices with the row and column indices you can use a for-loop on the rows of your arrays it s slower but not as slow as a double for-loop

memory
above is a simplified version of my actual code where the c arrays is much larger so i have to use a for-loop to get every index

performance
i tried this code with my the big arrays it is around 10 to 20 times faster than a for-loop solution and around 200 times fast than the old code

performance
the only way to copy arrays that is more efficient than for-loop coding is system.arraycopy

performance
edit as willeke has pointed out accessing a properties directly is technically faster than doing so via an accessor via self

usability
i recomend to use dtmilano tool androidviewclient that is easier to use than monkeyrunner

performance
i need to perform several device.touch events as fast as possible however androidviewclient seems to achieve those significantly slower than monkeyrunner

usability
networkx is much easier to deal with and usually performance is good enough but for large brute force algorithms like this igraph will probably be at least an order of magnitude faster

performance
i probably feel fseek might be bit faster than fread as fseek changes the pointer position to the new address space that you have mentioned and there is no date read is happening

performance
so i guess fseek should be much faster than fread

performance
use a dawg which is more efficient than a trie in terms of space waste

memory
a dawg has better memory performance if the strings have many common suffixes but they are more expensive and difficult to build and update so start with a trie

performance
it is a structure similar to but twice as space-efficient as the dawg that is more efficient than the trie which only compresses prefixes

performance
ie s vml is slower than other browser s svg

performance
division is performed by repeated subtraction therefore needs more level of subtract logic making division slower than addition

performance
i need to find out that how much division operation is faster than addition operation in a gpu

performance
performing addition on this slightly larger type will pretty much always be faster than doing division or modulo on the type itself

performance
so if your code has tough data dependency problems addition is about 12 times faster than division

usability
knuth writes that fibonacci search is preferable on some computers because it involves only addition and subtraction not division by 2. but almost all computers use binary arithmetic in which division by 2 is simpler than addition and subtraction

performance
it is true that division and modulo a division operation is slower than addition

memory
and division has larger complexity than addition

performance
it could be done via division which is much slower than addition or it could be translated into a bitwise and operation as well and end up being just as fast as the version

performance
for example an addition is typically much faster than a division

memory
and division has larger complexity than addition

performance
it is true that division and modulo a division operation is slower than addition

performance
an addition is faster than a division and a multiplication

performance
2.the division by 2 can be done by bit - shift operation is it really slower than addition

usability
as far as i know the division is more complex and slower than other operations like addition so is my code incorrect then

performance
it could be done via division which is much slower than addition or it could be translated into a bitwise and operation as well and end up being just as fast as the version

performance
with careful optimization however you can make addition 61 times faster than division

performance
i remember it says something like division takes much much more time than addition

performance
for example on most 32 bit systems 64-bit addition is faster than 32-bit division modulo

performance
i am new to laravel it s good for coding but it is not much faster than codeigniter

performance
in my personal benchmarks laravel is undeniably faster than codeigniter due to lazy loading

performance
in my personal benchmarks laravel is undeniably faster than codeigniter due to lazy loading

performance
google-chrome or safari on a mac could be much faster than firefox on a pc especially with newer apis

performance
i just tested geolocation on firefox 3.6 and iphone safari os 3.1.3 the result is interesting firefox is more accurate than safari

performance
in safari we found that the dom level 0 took twice the time off the dom level 2 but was still four times faster than either firefox case

memory
small in firefox is smaller then small in safari so never ever use them

performance
on safari everything is slower than on firefox still the object property access is more than two times faster

performance
on safari everything is slower than on firefox still the object property access is more than two times faster

memory
that i gave to every link in the set of links home about us products contact and it seems that firefox is making that 1px margin much bigger than safari or google-chrome and distorting it

memory
small in firefox is smaller then small in safari so never ever use them

usability
in general it is nicer in c to have the caller allocate memory not the callee - hence why strcpy is a nicer function in my opinion than strdup

performance
the compiler is free to choose a method that is more efficient than memmove

reliability
aside from obejctive-c convention and best practices nserror is much more robust and flexibly than nsexception and allows the caller to effectively ignore the problem if they want to

performance
i am interested in this because the factor oracle is easy to construct with 30 lines of c++ suffix-array needs about 60 and suffix-tree needs 150 and it runs faster than suffix-array and suffix-tree

security
strncpy is not safer than strcpy it just trades one type of bugs with another

security
myth 3 strncpy is a safer version of strcpy

security
strncpy is not safer than strcpy it just trades one type of bugs with another

security
strncpy is not safer method to use as strcpy

security
myth 3 strncpy is a safer version of strcpy

security
strncpy is safer than strcpy

security
in general strncpy is a safer alternative to strcpy

security
strcpy is notoriously unsafe as are it s cousins strcpy_s and strncpy although they are mildly safer than strcpy

security
strncpy is not safer method to use as strcpy

security
in general strncpy is a safer alternative to strcpy

security
you should use strcpy or strncpy safer than strcpy to copy the string stored in the array between arrays

security
i was exploring around with c regarding strncpy since most people says that it is safer than strcpy additional parameter length to avoid buffer overflows

memory
if in java code the values would be in pixels so 50px on mdpi screens will look larger than on hdpi screens

usability
you can use a bezier path either in a custom uiview w drawrect or easier with a cashapelayer whose curvature can be controlled via its control points

usability
instead of figuring out the individual positions for each image button it is easier to simply right-align them by modifying the anchorpoint to 1.0f 0.5f and then position the images button at exactly the screen width and variable screen height position screen width 100

performance
probably you can take a look at rythm template engine which is much faster than freemarker and velocity also much easier to use

usability
the theory is that someone extending your class with protected access knows more about what they are doing than someone who is merely using it with public access

usability
what is the true rationale behind all the private and protected stuff when we can just make our life as a programmer easier by using public for everything

performance
the math.floor ceil method being marginally faster than parseint and mod

usability
mutation is typically easier to do this with than crossover

memory
there are at least n m+1 2 elements no larger than the maximum hi of these median and at least n m+1 2 no smaller than the minimum lo

memory
specifically jscrollpane have height bigger than jinternalframe

memory
my solution to the range part feels clunky over complicated and doesn t check if the max range value is bigger than the min range value doesn t check if 10 2

memory
my solution to the range part feels clunky over complicated and doesn t check if the max range value is bigger than the min range value doesn t check if 10 2

memory
for ease of debugging i pass the value of to reactive values and print the first date range s value to the console rendered to check whether the it is smaller or bigger than the min and max of the corresponding date column as i did in the lapply function

memory
if i resize the window and a widget with a highcharts is bigger than the window i want to resize it to make it smaller and gridster should recalculate the positions of the others

performance
i read in a blog article that buildr a ruby based build tool was two times faster than maven for a simple build

performance
and even though everybody says ruby is slow buildr was 2-6x faster than maven

performance
however naive multiplication will get slower and slower as the exponent increases

performance
the misunderstanding is that incrementing the exponent is not faster than doing a multiplication

usability
multiplication is even easier as you dont have to line up the decimal points you just do the math on the significant digits and simply add the exponent

performance
this is analogous to the way you can compute exponent using successive squaring much faster than by repeated multiplication

memory
as int exponent gets larger taking powers might be faster than multiplication

performance
however with really very small parameter 2 in your case exponent is faster than multiplication

performance
doing a single printf and strdup is faster and simpler than doing 2-3 printf calls

performance
if not multiple fgets calls will still be faster than multiple fgetc calls because the overhead of the latter will be greater

usability
fgetc is a function to read a single char simpler than using fgets

memory
it seems like if the uiimage is slightly larger the ciimage is double the size whereas if the uiimage is slightly smaller this isn t the case

reliability
in general try-catch is more robust does not require you to define an exact position of where to test could be a block and provides info about the exception-handling

performance
try-catch is actually slower if there really is an exception-handling thrown

usability
the later version of jmock makes things easier by integrating with the junit lifecycle as a runner

performance
basically imagemagick was only slightly slower than libjpeg

performance
in case if updatepanel takes more time to process set asyncpostbacktimeout property of your scriptmanager

usability
but i read in this post that group by on union are not possible yet it mean that cypher is less powerful than gremlin

performance
neo4j and cypher is still faster and obviously this has no effect on the gremlin queries on neo4j but that might be just a issue with the gremlin implementation for neo4j

performance
recently we noticed that cypher queries run faster than gremlin so we decided to convert our queries

performance
general consensus including the php docs is that metaphone is much more accurate than soundex when dealing with the english language

performance
general consensus including the php docs is that metaphone is much more accurate than soundex when dealing with the english language

performance
in php you should use metaphone it is more accurate than soundex

usability
in other words instead of mis-using stderr like this - look into ways to gain more control over stdout

performance
i m using xamarin.android to write c# but the native java rsa key generator is much faster than the mono one

usability
vbscript is much more convenient than creating an activex on vb6 or c# vb.net

usability
it is written in tcl which is a language somewhat simpler than perl but broadly in the same family and not difficult to learn

reliability
wan is less stable than lan

usability
i find fireworks has an easier time dealing with vectors because they re first class objects while in photoshop they re actually a combination of a vector mask and a colour fill

usability
i find fireworks has an easier time dealing with vectors because they re first class objects while in photoshop they re actually a combination of a vector mask and a colour fill

usability
you might want to use r markdown and knitr which is easier than using latex and r as also zhaoy suggested

usability
dotnetzip is much easier to use than sharpziplib example of zipping all files in folder

usability
dotnetzip offers native support and has a quite friendly api and is my opinion more flexible than sharpziplib

usability
and dbcontext is much simpler to use than objectcontext and will serve the most common development needs

performance
when it comes to deletion it even gets worse when saving at the end of all entity removals dbcontext is around 18 times slower than objectcontext

usability
dbcontext is much simpler to use than objectcontext and will serve the most common development needs

usability
besides the dbcontext api is easier to use than objectcontext

memory
you just need to connect using the entity framework driver and if you develop in any of technologies that uses dbcontext includes code first model first and data base first but is lighter than objectcontext you can use the list below

performance
if adding 2000 entities and saving the changes at the end dbcontext is 3 to 5 times slower than objectcontext btw. i know that adding a large amount of entities would be better using sqlbulkcopy but that s not the point

usability
dbcontext api is easier to work with than objectcontext but both approaches use the former

usability
edit as mentioned by chandresh using the ng-show directive with a true false value would be a better option than using ng-class

performance
this tiny overhead on add is vastly outweighed by the savings on lookups since all programmers should know and understand that case-insensitive compares are vastly slower than case-sensitive especially with unicode - the cpu can t just do a block compare of data but must check each pair of characters specially even using a table look-up this is vastly slower

performance
btw a case-sensitive search done with removing i is much faster than a case-insensitive search

reliability
quote from the third link - the altitude error is much greater because it is a satellite based system

performance
i use tokudb on tables of up to 18 billion rows and nothing else comes close it s at least 100 times faster than innodb for random inserts on big tables

memory
the panels itself is larger than the form and is scrollable autoscroll true

memory
i am trying to create a jpanel that is resizable scrollable and contains x smaller inner panels

memory
i am trying to create a jpanel that is resizable scrollable and contains x smaller inner panels

performance
if almost all elements fail the filtering then it s considerably slower than just sorting everything since you ll end up selecting thousands of times

performance
in terms of your speed query i d propose that your pseudomedian filtering is faster because it doesn t involve sorting

usability
considering sorting is more complicated than summation median filtering will cost longer time

performance
you d still have to filtering to get a range though it ought to be faster than sorting at least

performance
so decide what you want to use direct3d is significaly faster than gdi

performance
so decide what you want to use direct3d is significaly faster than gdi

performance
note also that using nsmutablestring is more efficient than creating a new nsstring each time a letter is added

performance
posting qevents to qobject is faster than using signal-slot invocations because there are no copy constructors called and there s no marshalling done except directly by you upon construction of a qevent

usability
xna is more popular and has more tutorials then libgdx

usability
a quadtree is a simpler data structure than the r-tree

performance
quadtree indexes are created faster than r-tree

performance
r-tree are much faster than quadtree for nearest neighbours queries

performance
r-tree are substantially faster than quadtree for window queries like inside contains covers etc

usability
a quadtree is a simpler data structure than the r-tree

usability
because copying text result from jtextfield is always easier than retyping it from jlabel note that jlabel is not focusable

performance
also take a look at silex as this has lower overhead than symfony and works with symfony forms

memory
to prevent children divs to become larger than the parent you have to set an overflow

usability
i would prefer the 1st one since maintaining 1 value of parent is easier efficient than maintaining list of all children

memory
in a heap when there is any change in the heap insert delete update then the heap is restructured in a way such that the common priniciple is maintained in above case the parent remains always smaller than its children

memory
assuming that the parent has a smaller id than any of its children and that the default value of the parent column is null could you order them this way

memory
of course there are a few other small details to take care of such as make sure the children width is smaller than the parent make sure the left and right margins and paddings are equal etc...

memory
children smaller than parent

memory
where the parent node is a smaller value than that of its children

memory
i want to prevent the two divs to be placed under another if the parent width becomes smaller than the children combinded width

memory
then i thought of putting each integer from s into a binary search tree and searching for first occurence where one of children is smaller than query and parent is bigger than query but i don t know if this will work

memory
my children views may be a different width but it not be bigger than parent view

memory
when the browser window is smaller than the min-width the child elements are the correct width but the parent keeps getting smaller causing the children to overflow

memory
max heap in which parent node is always larger than its children

memory
in min heap a single insertion is o logn in the worst case as that cost is only incurred if the heap property that the parent value should be smaller than the children is violated

memory
here a number of methods are described to fix the parent which collapses to smaller than its floating children

memory
if you have children that have a smaller height than their parent floats will bring them to the top whereas inline-block will screw up sometimes

memory
here s what it looks like if the parent is bigger than the children

memory
pushing and popping any item on a heap simply updates the elements in it in such a way that there is no node where its children are larger than the parent for max heap

memory
you need to just change the siftdown function so that the parent is always the smaller than the children

memory
again if the parent view is not larger than its children the expansion suffix does not make any difference as well

performance
children is faster than find for example just like parent is faster than parent

reliability
this really helps keeps parent branch more stable than children

memory
what if both children are equal and smaller than the parent

memory
the naming of parent and child classes sometimes is counter intuitive as we often think as children as being smaller than the parent but in programming the child is the same as the parent but with extra funtionality

memory
ok if we say that the parent is always bigger than the children because it is above them we write

memory
so the problem i have now that the parent div height is larger than his children s height

memory
i understand the heap is a structure that the parent node is always larger or smaller than its children nodes

memory
in case 1 the node at which we stop is the local min because i it s smaller than both of its children and ii it s smaller than its parent which is the precondition of our deciding to check this node

memory
your fixheap2 fails to consider the case where both children are valid but have keys smaller than the parent s

memory
the table can contain two or more headers where the parent header gets a bigger colspan and the bottom header conforms by giving the equivalent amount of columns i.e index 4 has two children indexed 1 and 2

memory
if the parent becomes smaller than the total width of the children as numbers 1 2 3 and 4 dictate the children should shrink to stay within the new parent width

memory
specifically you compare the new root with the left and right children and keep swapping if the parent is larger than at least one of the children until the heap property is satisfied

memory
make sure that the parent container has a width and that this width is at least larger than the children elements

memory
if the parent however is not larger then its children you won t notice any difference between those alignments

memory
as a general rule of thumb i keep the parent bigger than the children

memory
the table can contain two or more headers where the parent header gets a bigger colspan and the bottom header conforms by giving the equivalent amount of columns i.e index 4 has two children indexed 1 and 2

memory
min heap in which parent node is always smaller than its children

memory
new h i is guaranteed to be the smallest of the old h i s children which is still larger than old h i s parent

usability
i would prefer the 1st one since maintaining 1 value of parent is easier efficient than maintaining list of all children

memory
as long as each parent is smaller than its children - it will work

memory
for some reason the second children class .main-body lightseagreen color of a column-layouted flexbox container .content-main plum color has a bigger height than its parent which i do not want it to

memory
as you are always swapping it with the larger of the two heap property means that the parent is always larger than its children

memory
when the children s line-height is smaller than parent s it looks like the children s line-height is ignored because parent s line-height will hold up the line box when the children s line-height is smaller

memory
ok if we say that the parent is always bigger than the children because it is above them we write

memory
when you zoom in google chrome some zoom levels cause the children elements to be larger than the parent element

memory
how can i achieve that my container will adjust the height accordingly of the children items when the height of the children elements is larger then configured minheight of their parent element

memory
suffix expand if the parent view is larger than the combined size of all its children additional space is available then the space is proportioned amongst child views with that suffix

memory
i want to prevent the two divs to be placed under another if the parent width becomes smaller than the children combinded width

performance
as harypyon suggests storing the children is a more efficient way of viewing this problem than storing the parent and then computing the children

memory
whenever a top parent reply tile goes out of the viewport it is disposed as expected but when trying to bring it back into view it scrolls right to the top and looks very jumpy even worse whenever a bigger thread with multiple children tries to come back into view it doesn t scroll at all

memory
how can i achieve that my container will adjust the height accordingly of the children items when the height of the children elements is larger then configured minheight of their parent element

memory
insertng in search binary tree you need to keep track that children are stored in the specific order child smaller than parent on the left and greater or equal on the right and parent has at most 2 children

memory
i was expecting the parent widget to have a little larger sizehint than the children layout

memory
i understand the heap is a structure that the parent node is always larger or smaller than its children nodes

memory
the result you are getting is also a valid heap - each parent is bigger than its children

memory
of course there are a few other small details to take care of such as make sure the children width is smaller than the parent make sure the left and right margins and paddings are equal etc...

memory
my children views have their height set to wrap_content i know that the behavior of wrap_content is to fit the content size unless its bigger than the parent

memory
ok so your parent are fixed width the children are bigger than the parent element also min-width 150px

memory
and the reason why the subtree isn t reached is because you only call heapifyhelper for the children if one of the children is smaller than the parent but when you call heapifyhelper 1 the two children of the node 5 are 9 and 11 both larger than the root value

memory
if a node has two children then the left child has a smaller value than the parent and the right child has a bigger value

memory
max heap in which parent node is always larger than its children

memory
assuming that the binary tree follows that all left children are smaller than their parent and all right children are larger than their parent you could use this property of the tree to reduce the amount you need to search through

memory
by the properties of the binary search tree you already know that all children have to be larger than the parent 15 therefore using one of them instead of the 25 is valid

memory
where the parent node is a smaller value than that of its children

memory
assuming that the parent has a smaller id than any of its children and that the default value of the parent column is null could you order them this way

memory
if still not then think of it as a min heap represented in array guarantees that parent is smaller than its child but says nothing about are all children arranged in sorted order left to right

memory
are the nodes in order like in your example where the children have a larger id than the parent

memory
also it seems this is only the problem when there are a lot of duplicates the heap doesn t seem completely capable of staying in order the parent is smaller than the children

memory
min heap in which parent node is always smaller than its children

memory
edit in other words if the parent is larger than the total width of the children that s fine

memory
i ve thought in using a pairing function but that makes children exponentially bigger than parent so after a few splits there is an integer overflow

memory
this assumes that the id of the parent is smaller than the id of the children as is the case with the sample data in the question.

memory
assuming that the binary tree follows that all left children are smaller than their parent and all right children are larger than their parent you could use this property of the tree to reduce the amount you need to search through

memory
if the parent however is not larger then its children you won t notice any difference between those alignments

memory
again if the parent view is not larger than its children the expansion suffix does not make any difference as well

memory
the children iframe will always be bigger than parent div and parent div overflow will be hidden

memory
the widths of the children is often larger than the width of the parent

memory
in a heap when there is any change in the heap insert delete update then the heap is restructured in a way such that the common priniciple is maintained in above case the parent remains always smaller than its children

memory
as you are always swapping it with the larger of the two heap property means that the parent is always larger than its children

memory
why is the parent smaller than the children on narrow screens

memory
note that children nodes have value larger than the parent

performance
my understanding is the requestfactory is more efficient and recommended over gwt-rpc but it s more of a data entity persistence framework than a request-response framework like rpc

usability
the consensus seems to be that corona is easier to use but that cocos2d-x has the advantages that come from being open source easy to customize merge with other code community etc

performance
using getfrontbufferdata in directx method is slower than gdi itself

performance
directx is in general much faster than gdi due to the fact that it has full acceleration on most video cards

performance
using getfrontbufferdata in directx method is slower than gdi itself

memory
if you are talking about someone else s there is no promise that they will render larger than the screen since would be wise to clip their painting to what is visible and they may be further constrained by other factors such as the size of a directx surface which is smaller than the gdi limit

performance
to say directx is faster than gdi is also something of a simplification - wpf and gdi-based rendering technologies just have different performance characteristics

performance
speed is usually faster than gdi and slower than directx and depends greatly on how you do things seen something to work 60 times faster after rewriting in a sensible way

performance
directx is way faster than gdi

usability
xcb is simpler to use has a better response to a multithread environment but lacks documentation while xlib is a more dated complex tool better documented and fully implemented

performance
this makes for example javassist or proxetta significantly slower than cglib which simply reads the methods via the reflection api and overrides them

performance
note that javassist is significantly slower then for example cglib because it reads in class files directly instead of using reflective access in order to avoid class loading

performance
note that javassist is significantly slower then for example cglib because it reads in class files directly instead of using reflective access in order to avoid class loading

performance
also javassist is recognized to be slower than cglib

usability
both a renderscript and opengl are used for getting high performance graphics and animation s.but still opengl is the best option to get high performance graphics because it is well documented and you will have more control over the glsurfaceview .but in renderscript some of the classes are depreciated in the current versions .its almost not possible to make a rssurfaceview to transparent

usability
i used ppm pgm files as they are simpler to write and more portable than bmp

performance
if this is an issue you could try sd stream diff which doesn t require sorting like comm does nor process substitution like the above examples is orders or magnitude faster than grep -f and supports infinite streams

performance
i rather prefer grep since it s much faster than comm and also does not require the input to be sorted

performance
also on implementations like jython or ironpython could be a lot slower than with cpython

performance
it s possible that jython and ironpython are much faster than cpython as well as they are backed by heavily optimized virtual machines jvm and .net clr

performance
it seems ironpython is just slower than cpython for reading text files

performance
i m not sure exactly how you re drawing the conclusion that ironpython is faster than cpython

performance
if there s any heavy application logic as opposed to all of the work being networking files database ironpython is much faster than cpython at a few things and much slower at a few others so you probably need to profile and perf-test before you go too far down either path

performance
if there s any heavy application logic as opposed to all of the work being networking files database ironpython is much faster than cpython at a few things and much slower at a few others so you probably need to profile and perf-test before you go too far down either path

performance
it seems ironpython is just slower than cpython for reading text files

usability
my understanding was it was written in vanilla python cpython but if you are more comfortable with ironpython it shouldn t be hard to translate

performance
ironpython is faster than c# in certain areas but not faster than cpython however you can link ironpython to any language thus over coming problems but then again you can do the same with cpython

performance
consequently ironpython is potentially faster than cpython is especially for multithreading scenarios

performance
consequently ironpython is potentially faster than cpython is especially for multithreading scenarios

performance
ironpython and jython are also jit-compiled although using the more generic jvm and .net jits so they tend to be faster than cpython for this kind of work as well

performance
but if you are allowed to store whole tree into memory you can use lxml.html which is faster than beautifulsoup

performance
in the first example sqldf is 3x slower than data.table and in the second its 200x faster than plyr and 100 times faster than data.table

performance
in the first example sqldf is 3x slower than data.table and in the second its 200x faster than plyr and 100 times faster than data.table

performance
i d like to add that couchbase is a faster and more scalable option than couchdb the 2.0 version introduces views at a high level it s a distributed memcached membase server merged with couchdb but of course more sophisticated than just mashing them together

usability
i d like to add that couchbase is a faster and more scalable option than couchdb the 2.0 version introduces views at a high level it s a distributed memcached membase server merged with couchdb but of course more sophisticated than just mashing them together

performance
couchbase btw also uses binary replication mechanism which will be more efficient than couchdb as long as the couchdb protocol is not utilized for bidirectional data exchange and conflict resolution

performance
you could always use https that will work both on http and https websites but loading a https resource is slower than loading a http resource because of the encryption and ssl handshakes

usability
https is more flexible than ssl an application can configure the level of security it needs

security
as last resort resolution i don t suggest this for security issues using ssl is always safer switch your registry to use http instead of https

security
as last resort resolution i don t suggest this for security issues using ssl is always safer switch your registry to use http instead of https

performance
no practically floyd-warshall is faster than dijkstra s for all pair shortest path generally

performance
short answer floyd-warshall is more efficient in this case than naive application of dijkstra s

performance
i confirmed that in debug mode the getline version is slower about 130 âµs vs 60 âµs for the fgetc version

performance
the fact that using getline with iostreams is faster than fgetc at least in release mode runs counter to the reasoning that copying all that data must be slower than not copying it so i m not sure what all optimization is able to avoid and i didn t really look to find any explanation but it d be interesting to understand what s being optimized away

memory
so the t 7n 10 is the part of continuing the equation with the max segment of numbers that is larger smaller than the median of medians..

memory
so the t 7n 10 is the part of continuing the equation with the max segment of numbers that is larger smaller than the median of medians..

usability
achartengine is easy to use mpandroidchart has more option but is less easy to use than achartengine

usability
glut is much more easier while many of people use sdl or sfml they re more flexible and feature-full than glut

memory
the g++ version is a little larger than the gcc version but not 100x larger

usability
the only thing i can suggest is that you use ppm format which is even easier than bmp for you to read from

performance
the ssd disks are from 4 to 8 times faster than a sata hdd depending on the model

memory
i m working on a wildfly swarm project using wildfly swarm version 2017.8.1 maven 3.5.0 openjdk 1.8.0_141 where users will often upload files way bigger than undertow s default 10485760 bytes 10mb max-post-size setting

performance
memcpy will always be faster than strncpy for any real world situation even in the corner case i spoke before look page_copy_fwd_maybe

performance
even if underlying implementation is not so different memcpy is much faster because it does not have to check what it s copying strncpy will stop when it ll copy the end of string character null

performance
but for the example you give it doesn t matter - if it s going to fail it will be in the initial strlen so strncpy doesn t buy you anything in terms of safety and presumbly strncpy is slower as it has to both check bounds and for nul and any difference between memcpy and strcpy isn t worth changing code for speculatively

performance
which is more efficient is up for debate but based on cpu bulk instructions which can copy an entire block of memory in one instruction memcpy is probably faster as strncpy would check each copied byte for a nul character

usability
the memcpy version is not more complex or more dangerous than the strncpy version

usability
wxpython is probably easier than pyqt or tkinter i don t want to start a framework war

usability
wxpython is probably easier than pyqt or tkinter i don t want to start a framework war

usability
two words of warning against wxpython it is not possible to install it via the popular fink package manager on mac os x currently which makes it far less portable than pyqt and tkinter

performance
i am using a sparse format but suggestions are welcome on other formats too i am able to use the data with weka in a dense format using the function names as variables and it works just muuch slower than with libsvm

memory
i already know that ember.js is a more heavy weight approach in contrast to backbone.js

usability
ember.js would make things even simpler than backbone.js

memory
ember.js is larger than backbone.js but thanks to expires cache-control this only matters on the the first load

reliability
i have solved it in the past very successfully using robocopy it s much more robust than xcopy

usability
you might want look at robocopy as it has many more options than xcopy

performance
that would theoretically cut the time in half but it seems that robocopy is much faster than xcopy at least for this use so it took way less time

usability
use robocopy it s much more powerful than xcopy

usability
if your batch file only needs to run on windows vista or later you can use robocopy instead which is an even more powerful tool than xcopy and is now built into the operating system

usability
use robocopy it s much more powerful than xcopy

performance
that would theoretically cut the time in half but it seems that robocopy is much faster than xcopy at least for this use so it took way less time

reliability
i have solved it in the past very successfully using robocopy it s much more robust than xcopy

usability
since you tagged this with python you might find rdflib more useful than jena but the real question here should be about how to do the conversion not the library request since library requests are off topic for stack overflow

usability
be aware that the bourne shell in freebsd is more capable than on linux

usability
as wuliwong said sinatra and padrino are way less complex than ruby-on-rails

performance
sinatra and padrino are not automatically faster than ruby-on-rails

performance
but in general you will find that lxml is faster more effective and has an api which adheres closely to a python standard the elementtree which comes with the python standard library

performance
lxml is faster than elementtree but i ve never found an application where the speed boost paid for the hassles of distribution

performance
but in general you will find that lxml is faster more effective and has an api which adheres closely to a python standard the elementtree which comes with the python standard library

performance
but in general you will find that lxml is faster more effective and has an api which adheres closely to a python standard the elementtree which comes with the python standard library

usability
you should check out losswise it has a plugin for keras that s easier to use than tensorboard and has some nice extra features

usability
headline qqmlapplicationengine is newer and more powerful than qquickview

performance
jackson xml module faster than xstream

