### 1. Extract comparative relations

**730** tech pairs: [recordings.txt](https://github.com/hy3440/diffSimilarTech/blob/master/out/tech_v6/recordings.txt)

**6857** [comparative sentences](https://github.com/hy3440/diffSimilarTech/blob/master/out/tech_v6/sentences_.txt)/ **596765** sentences containing similar techs

Post ID from 0 to **12,900,000**

| No   | Pattern           |
| ---- | ----------------- |
| 0    | JJR * CIN * TECH  |
| 8    | RBR JJ * CIN TECH |
| 7    | TECH * VBZ * JJR  |
| 10   | TECH * VBZ * RBR  |

**Tech1** is **JJR** than **Tech2**

**Tech1** is **more JJ** than **Tech2**

**Tech1** VBZ (e.g. uses, has) **more NN** than **Tech2**

**Example**:

46614

post	get

pattern10		pattern8

**post** is also **more secure** than **get** because you aren t sticking information into a url

**Problems**:

1. *compared to* and several similar tech pairs

853042

ienumerable	icollection	ienumerable	ilist	ilist	icollection

pattern7

compared to **ienumerable** and **icollection** **ilist** performs much **better** for large or dynamic **lists** because it provides an indexer allowing us quick random access

2. several aspects

2336560

gif	png

pattern7

compared to **gif** **png** offers **better compression** **larger pallette** and **more features** including transparency

3. extract aspect

34338

phpunit	simpletest

pattern0		

i found **simpletest** was even **easier** than **phpunit** to *set up*

| No   | Pattern         |
| ---- | --------------- |
| 2    | CV * CIN * TECH |
| 3    | CV VBG TECH     |
| 4    | CV TECH         |

**Examples**

1. 74992

bash	zsh

pattern4		pattern2		

i prefer **zsh** over **bash** because of its support for very powerful file globbing variable expansion modifiers and faster tab completion

2. 330657

post	get

pattern3	

security wise i prefer using **post** than **get** as it gives at least some opaqueness as to what is being passed as a parameter and not anyone can just edit the url and play around

3. 475026

crypt	hash

pattern4		

also instead of using **crypt** you may prefer **hash** because this allows you to keep the string setting for the hash algorithm elsewhere

### 2. Train word embedding

`model = gensim.models.Word2Vec(sentences, min_count=20, size=200, workers=8)`

```
2018-03-07 23:08:43,529 : INFO : collected 13001639 word types from a corpus of 2834329535 raw words and 222847980 sentences
2018-03-07 23:08:43,529 : INFO : Loading a fresh vocabulary
2018-03-07 23:08:51,788 : INFO : min_count=20 retains 495435 unique words (3% of original 13001639, drops 12506204)
2018-03-07 23:08:51,788 : INFO : min_count=20 leaves 2807781034 word corpus (99% of original 2834329535, drops 26548501)
2018-03-07 23:08:52,986 : INFO : deleting the raw counts dictionary of 13001639 items
2018-03-07 23:08:54,005 : INFO : sample=0.001 downsamples 54 most-common words
2018-03-07 23:08:54,005 : INFO : downsampling leaves estimated 2064316439 word corpus (73.5% of prior 2807781034)
2018-03-07 23:08:55,763 : INFO : estimated required memory for 495435 words and 200 dimensions: 1040413500 bytes
2018-03-07 23:08:55,763 : INFO : resetting layer weights
2018-03-07 23:09:00,243 : INFO : training model with 8 workers on 495435 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
Killed
```




